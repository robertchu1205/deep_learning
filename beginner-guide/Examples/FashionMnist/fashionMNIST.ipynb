{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 05:55:59.549443 139674573018880 deprecation.py:323] From <ipython-input-1-4dceece8a4ae>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0725 05:55:59.550169 139674573018880 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0725 05:55:59.550886 139674573018880 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist-data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 05:55:59.775290 139674573018880 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0725 05:55:59.816499 139674573018880 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist-data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist-data/\")\n",
    "train_img, train_label = mnist.train.images, mnist.train.labels\n",
    "test_img, test_label = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_img.shape)\n",
    "print(train_label.shape)\n",
    "print(test_img.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import online dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# export proxy for downloading dataset online \n",
    "# dataset from Internet is much better than local ones\n",
    "# However, still could use the local dataset if proxy doesnt work\n",
    "os.environ[\"http_proxy\"] = '10.41.69.79:13128'\n",
    "os.environ[\"https_proxy\"] = '10.41.69.79:13128'\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n",
      "[4 0 7 ... 3 0 5]\n"
     ]
    }
   ],
   "source": [
    "train_img = train_img.reshape(-1, 28, 28).astype('float32')\n",
    "test_img = test_img.reshape(-1, 28, 28).astype('float32')\n",
    "label_dict={0:'T-shirt/top',1:'Trouser',2:'Pullover',3:'Dress',4:'Coat',5:'Sandal',6:'Shirt',7:'Sneaker',8:'Bag',9:'Ankle boot'}\n",
    "print(train_img.shape)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(train_img[0])\n",
    "#plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "print(train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_label_prediction(images, labels, prediction,idx,num=10):\n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(12,12)\n",
    "    if num>25: num=25\n",
    "    for i in range(0, num):\n",
    "        ax = plt.subplot(5,5, 1+i)\n",
    "        ax.imshow(images[idx],cmap='binary')\n",
    "        \n",
    "        title=label_dict[labels[idx]]\n",
    "        #show predicted outcome in order to where the model should improve\n",
    "        if(len(prediction)>0):\n",
    "            title+='->'+label_dict[prediction[i]]\n",
    "        ax.set_title(title,fontsize=10)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        idx+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plot_image_label_prediction(train_img.reshape(train_img.shape[0],28,28),train_label,[],50500,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning( VGG )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "os.environ[\"http_proxy\"] = '10.41.69.79:13128'\n",
    "os.environ[\"https_proxy\"] = '10.41.69.79:13128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image shape to VGG's minimum (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 32, 32, 1)\n",
      "(10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "trainimg32321 = []\n",
    "for i in range(train_img.shape[0]):\n",
    "    newarray = np.pad(train_img[i],(0,4),mode='constant',constant_values=0)\n",
    "    trainimg32321.append(newarray)\n",
    "trainimg32321 = np.asarray(trainimg32321,dtype=np.float32)\n",
    "\n",
    "testimg32321 = []\n",
    "for i in range(test_img.shape[0]):\n",
    "    newarray = np.pad(test_img[i],(0,4),mode='constant',constant_values=0)\n",
    "    testimg32321.append(newarray)\n",
    "testimg32321 = np.asarray(testimg32321,dtype=np.float32)\n",
    "\n",
    "trainimg32321 = trainimg32321.reshape(trainimg32321.shape[0],32,32,1)\n",
    "testimg32321 = testimg32321.reshape(testimg32321.shape[0],32,32,1)\n",
    "print(trainimg32321.shape)\n",
    "print(testimg32321.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "trainimg32323 = []\n",
    "for i in range(train_img.shape[0]):\n",
    "    newarray = np.pad(train_img[i],(0,4),mode='constant',constant_values=0)\n",
    "    trainimg32323.append(newarray)\n",
    "trainimg32323 = np.asarray(trainimg32323,dtype=np.float32)\n",
    "\n",
    "testimg32323 = []\n",
    "for i in range(test_img.shape[0]):\n",
    "    newarray = np.pad(test_img[i],(0,4),mode='constant',constant_values=0)\n",
    "    testimg32323.append(newarray)\n",
    "testimg32323 = np.asarray(testimg32323,dtype=np.float32)\n",
    "\n",
    "trainimg32323 = np.stack((trainimg32323,)*3,axis=-1)\n",
    "testimg32323 = np.stack((testimg32323,)*3,axis=-1)\n",
    "print(trainimg32323.shape)\n",
    "print(testimg32323.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- Tunnel connection failed: 503 Service Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             raise OSError(\"Tunnel connection failed: %d %s\" % (code,\n\u001b[0;32m--> 832\u001b[0;31m                                                                message.strip()))\n\u001b[0m\u001b[1;32m    833\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Tunnel connection failed: 503 Service Unavailable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    483\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 484\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1297\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error Tunnel connection failed: 503 Service Unavailable>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cdcab05974d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'owninputtensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#imports the VGG16 model and discards the neuron layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from keras.engine import InputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mWEIGHTS_PATH_NO_TOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 file_hash='6d6bbae143d832006294945121d1f1fc')\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: URL fetch failure on https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- Tunnel connection failed: 503 Service Unavailable"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(32,32,3),name='owninputtensor')\n",
    "base_model=VGG16(weights='imagenet',input_tensor=input_tensor,include_top=False) \n",
    "#imports the VGG16 model and discards the neuron layer.\n",
    "#from keras.engine import InputLayer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "#x=base_model.layers[-5].output\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D(name='GlobalAveragePooling2D')(x)\n",
    "#x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "#It's bad to use Dropout, because why should we trained some neural but not use it\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(10, activation='softmax', name='predictions')(x)\n",
    "modelvgg1=Model(inputs=base_model.input,outputs=[preds, x])\n",
    "modelvgg1.summary()\n",
    "# for i,layer in enumerate(model.layers):\n",
    "#     print(i,layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/500\n",
      "44000/44000 [==============================] - 13s 302us/step - loss: 0.6316 - acc: 0.7769 - val_loss: 0.4660 - val_acc: 0.8318\n",
      "Epoch 2/500\n",
      "44000/44000 [==============================] - 6s 146us/step - loss: 0.4058 - acc: 0.8508 - val_loss: 0.4087 - val_acc: 0.8491\n",
      "Epoch 3/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.3607 - acc: 0.8661 - val_loss: 0.3735 - val_acc: 0.8635\n",
      "Epoch 4/500\n",
      "44000/44000 [==============================] - 7s 148us/step - loss: 0.3397 - acc: 0.8742 - val_loss: 0.4008 - val_acc: 0.8534\n",
      "Epoch 5/500\n",
      "44000/44000 [==============================] - 6s 147us/step - loss: 0.3211 - acc: 0.8799 - val_loss: 0.4114 - val_acc: 0.8495\n",
      "Epoch 6/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.3021 - acc: 0.8871 - val_loss: 0.4048 - val_acc: 0.8516\n",
      "Epoch 7/500\n",
      "44000/44000 [==============================] - 6s 146us/step - loss: 0.2844 - acc: 0.8938 - val_loss: 0.3693 - val_acc: 0.8625\n",
      "Epoch 8/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.2737 - acc: 0.8980 - val_loss: 0.3730 - val_acc: 0.8642\n",
      "Epoch 9/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.2677 - acc: 0.9003 - val_loss: 0.3837 - val_acc: 0.8614\n",
      "Epoch 10/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.2536 - acc: 0.9048 - val_loss: 0.3622 - val_acc: 0.8732\n",
      "Epoch 11/500\n",
      "44000/44000 [==============================] - 7s 152us/step - loss: 0.2456 - acc: 0.9070 - val_loss: 0.3670 - val_acc: 0.8715\n",
      "Epoch 12/500\n",
      "44000/44000 [==============================] - 7s 148us/step - loss: 0.2309 - acc: 0.9113 - val_loss: 0.3605 - val_acc: 0.8734\n",
      "Epoch 13/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.2249 - acc: 0.9156 - val_loss: 0.3771 - val_acc: 0.8720\n",
      "Epoch 14/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.2150 - acc: 0.9184 - val_loss: 0.3612 - val_acc: 0.8802\n",
      "Epoch 15/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.2016 - acc: 0.9233 - val_loss: 0.3603 - val_acc: 0.8822\n",
      "Epoch 16/500\n",
      "44000/44000 [==============================] - 7s 152us/step - loss: 0.1969 - acc: 0.9243 - val_loss: 0.3745 - val_acc: 0.8731\n",
      "Epoch 17/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.1876 - acc: 0.9285 - val_loss: 0.3821 - val_acc: 0.8744\n",
      "Epoch 18/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.1804 - acc: 0.9310 - val_loss: 0.4002 - val_acc: 0.8788\n",
      "Epoch 19/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.1751 - acc: 0.9332 - val_loss: 0.3924 - val_acc: 0.8769\n",
      "Epoch 20/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.1652 - acc: 0.9377 - val_loss: 0.4368 - val_acc: 0.8725\n",
      "Epoch 21/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.1637 - acc: 0.9379 - val_loss: 0.4062 - val_acc: 0.8773\n",
      "Epoch 22/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.1513 - acc: 0.9430 - val_loss: 0.4311 - val_acc: 0.8805\n",
      "Epoch 23/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.1502 - acc: 0.9428 - val_loss: 0.4268 - val_acc: 0.8766\n",
      "Epoch 24/500\n",
      "44000/44000 [==============================] - 7s 153us/step - loss: 0.1424 - acc: 0.9450 - val_loss: 0.4437 - val_acc: 0.8767\n",
      "Epoch 25/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.1364 - acc: 0.9476 - val_loss: 0.4565 - val_acc: 0.8743\n",
      "Epoch 26/500\n",
      "44000/44000 [==============================] - 6s 146us/step - loss: 0.1338 - acc: 0.9502 - val_loss: 0.4559 - val_acc: 0.8760\n",
      "Epoch 27/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.1253 - acc: 0.9524 - val_loss: 0.4665 - val_acc: 0.8818\n",
      "Epoch 28/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.1280 - acc: 0.9512 - val_loss: 0.4577 - val_acc: 0.8760\n",
      "Epoch 29/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.1153 - acc: 0.9563 - val_loss: 0.4773 - val_acc: 0.8746\n",
      "Epoch 30/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.1068 - acc: 0.9592 - val_loss: 0.5154 - val_acc: 0.8745\n",
      "Epoch 31/500\n",
      "44000/44000 [==============================] - 6s 146us/step - loss: 0.1043 - acc: 0.9603 - val_loss: 0.5291 - val_acc: 0.8792\n",
      "Epoch 32/500\n",
      "44000/44000 [==============================] - 7s 148us/step - loss: 0.1038 - acc: 0.9605 - val_loss: 0.5160 - val_acc: 0.8768\n",
      "Epoch 33/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.1035 - acc: 0.9602 - val_loss: 0.4994 - val_acc: 0.8784\n",
      "Epoch 34/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.0932 - acc: 0.9642 - val_loss: 0.5321 - val_acc: 0.8754\n",
      "Epoch 35/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.0890 - acc: 0.9663 - val_loss: 0.5414 - val_acc: 0.8785\n",
      "Epoch 36/500\n",
      "44000/44000 [==============================] - 6s 147us/step - loss: 0.0851 - acc: 0.9676 - val_loss: 0.5890 - val_acc: 0.8720\n",
      "Epoch 37/500\n",
      "44000/44000 [==============================] - 6s 147us/step - loss: 0.0846 - acc: 0.9679 - val_loss: 0.5713 - val_acc: 0.8695\n",
      "Epoch 38/500\n",
      "44000/44000 [==============================] - 7s 149us/step - loss: 0.0747 - acc: 0.9725 - val_loss: 0.5742 - val_acc: 0.8789\n",
      "Epoch 39/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.0755 - acc: 0.9715 - val_loss: 0.6302 - val_acc: 0.8704\n",
      "Epoch 40/500\n",
      "44000/44000 [==============================] - 7s 148us/step - loss: 0.0738 - acc: 0.9720 - val_loss: 0.6141 - val_acc: 0.8786\n",
      "Epoch 41/500\n",
      "44000/44000 [==============================] - 7s 150us/step - loss: 0.0728 - acc: 0.9726 - val_loss: 0.6381 - val_acc: 0.8700\n",
      "Epoch 42/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.0711 - acc: 0.9736 - val_loss: 0.6136 - val_acc: 0.8765\n",
      "Epoch 43/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.0652 - acc: 0.9754 - val_loss: 0.6202 - val_acc: 0.8766\n",
      "Epoch 44/500\n",
      "44000/44000 [==============================] - 7s 151us/step - loss: 0.0663 - acc: 0.9752 - val_loss: 0.6365 - val_acc: 0.8712\n",
      "Epoch 45/500\n",
      "44000/44000 [==============================] - 6s 144us/step - loss: 0.0679 - acc: 0.9739 - val_loss: 0.6657 - val_acc: 0.8712\n",
      "Epoch 00045: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_acc',mode='max',verbose=1,patience=30)\n",
    "modelvgg1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = modelvgg1.fit(x=trainimg32323,y=train_label,validation_split=0.2, epochs=500, batch_size=300,verbose=1,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 244us/step\n",
      "Accuracy:  0.8732\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelvgg1.evaluate(testimg32323, test_label)\n",
    "print(\"Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model with downloaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictgray(model, img):\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.mean(x, axis=2)\n",
    "    plt.figure()\n",
    "    plt.imshow(image.array_to_img(x.reshape(x.shape[0],x.shape[1],1).astype('float32')))\n",
    "    x = x.reshape(1,x.shape[0],x.shape[1],1).astype('float32')\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    print(preds)\n",
    "    print(np.argmax(preds))\n",
    "    #print(np.int_(np.argmax(preds),dtype=np.uint8))\n",
    "    return preds\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predictrgb(model, img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    x = image.img_to_array(img)\n",
    "    #x = np.mean(x, axis=2)\n",
    "    x = x.reshape(1,x.shape[0],x.shape[1],3).astype('float32')\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    print(preds)\n",
    "    print(np.argmax(preds))\n",
    "    #print(np.int_(np.argmax(preds),dtype=np.uint8))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 T-shirt/top\n",
      "1 Trouser\n",
      "2 Pullover\n",
      "3 Dress\n",
      "4 Coat\n",
      "5 Sandal\n",
      "6 Shirt\n",
      "7 Sneaker\n",
      "8 Bag\n",
      "9 Ankle boot\n",
      "\n",
      "\n",
      "bag.jpeg\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "sneaker.jpeg\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0\n",
      "coat.jpeg\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "4\n",
      "dress.png\n",
      "[[0.         0.         0.         0.         0.07557413 0.\n",
      "  0.         0.         0.92442584 0.        ]]\n",
      "8\n",
      "dress2.png\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "2\n",
      "\n",
      "\n",
      "9\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFlBJREFUeJzt3XtwXPV1B/Dv2Zdell9obRTbQQSchyHFuBoPbdyUksJQJq1h2hLIDPVMKAYKTKChHePMgNOSAdoaBkjHxIDBaQFDAgxOhoEYl9alnbGRiTEGk9hxbLCQZckv2ZL12N3TP/Y6I9zf+WmtfVn6fT8zHq/u0d17dKWzV3uPfr+fqCqIKDyxaidARNXB4icKFIufKFAsfqJAsfiJAsXiJwoUi58oUCx+okCx+IkClShmZxG5HMDDAOIAnlDV+32f39TUpC0tLcUckkZg/cFm34e/MvcZ6DtmxhJiXx/qkg1mLH7+bOf2mJi7UAns3r0b3d3dBZ3lURe/iMQB/CuASwHsBfC2iKxV1Q+sfVpaWtDW1jbaQ1IBBgbc27f8wWXmPjs2bzBj01J2gZ93ZqsZm7rxdef2uqIuNzSS1lb7e3KyYn7tnw9gp6ruUtVBAGsALCzi+Yiogoop/hkAPh728d5oGxGNAWW/4Scii0WkTUTaurq6yn04IipQMcXfDmDWsI9nRts+RVVXqmqrqram0+kiDkdEpVRM8b8NYLaInC0iKQDXAFhbmrSIqNxGfe9VVTMiciuA15Fv9a1S1fdLllngRjvJSscXft+5/a0975r7HEvYx9ox0GvG3vjoTTN258Tzndvrjr1n7sM+YGUV1XhR1VcBvFqiXIiogvgXfkSBYvETBYrFTxQoFj9RoFj8RIHiMIsy688aI20A5OJ2TKTGjPUlLjJjsUk55/aPkDX3qc/aLbak2rEuHTJjR2rc7cPu+JnmPnMGOs1Yf8oM4WjfQTOWrp9q7xg4XvmJAsXiJwoUi58oUCx+okCx+IkCxbv9peAZgzOgR83Yo/IZM7YU88zYwWSPGTtWO925vQFxc5+UJ/+Yp0uQSk40Y/Ux9/E+nlJv7rNl2hfM2P/2/r/R4r/1N8ftOQjN7w3HEPHKTxQqFj9RoFj8RIFi8RMFisVPFCgWP1Gg2OorgYynbbSm6Twzdu3EFjP2eo89191t0mfGWj7vbpelDyTNfaZkzBD6Enar71DKfs4bv+QewLPtY7uveONH28zYnza4l/8CgGeT9jfgG8ZciHbjMxy88hMFisVPFCgWP1GgWPxEgWLxEwWKxU8UqKJafSKyG8BRAFkAGVVtLUVSY00Wdq8scdye5649Yc/hl55oj/hb1rPPjO2cMdO5/a7GL5n73D64x4zV5erM2D/GP2vG/njP287td3fYrb5pOMOM7R2yR0dmE/Y8ffE+43j1HNZXij7/H6lqdwmeh4gqiL/2EwWq2OJXAD8Xkc0isrgUCRFRZRT7a/8CVW0XkWkA1onIh6q6YfgnRC8KiwHgs5+13yMSUWUVdeVX1fbo//0AXgYw3/E5K1W1VVVb0+l0MYcjohIadfGLSIOINJ54DOAyAPbIDCI6rRTza/90AC+LyInneVZVXytJVmNMyjPJZW/ObgN2DtoTT86CPTnmtFo7tuA//tu5vT1rf6uHEnbbK3vsuBnrjh02Y7cdbnRuP1Ps9mZD3B5r1679ZizmXqEszzPiL3SjLn5V3QXgghLmQkQVxFYfUaBY/ESBYvETBYrFTxQoFj9RoDiBZykcsNfOi3nWwetWuw04ccgeDfhIar8Zu69vkjuPrN2y+740mbGeRK8ZO5K1W5yfj7t/tAbUzuOI2G25QTMCpGKea1i/ca6S0zzPGAZe+YkCxeInChSLnyhQLH6iQLH4iQLFu/0l8NQt3zZjE3L262u72HfLJw/Zg37+PDnZjH1y/Ihz+4xYys4jbi//1ZOy2xUKe5DOoax7Ka8JsO/o+wbv9HjmSZyZqzFjax94xLn9z+6919wnFLzyEwWKxU8UKBY/UaBY/ESBYvETBYrFTxQotvpK4IPnXzFjc2DPS/ehZ5BLc3yCGWvst9tv62vcz7lhRq25z6qd9lJYKbGP9a16+8fn/ow7j+Owny+Zc7cHAeAjtXOcmbRbfevuu8+5na0+XvmJgsXiJwoUi58oUCx+okCx+IkCxeInCtSIrT4RWQXg6wD2q+r50bapAJ4H0AJgN4CrVfVQ+dI8Pai621QNntFt8Zh72SoA6PQsM9WXs0f85Yw8AODijLuld96eA+Y+N537ZTP2yM4dZuyx43Yembi7bfcJ7PbmsZTd3owN2kuD1dinCi25eud263sJAOKZS3A8KeTK/zSAy0/atgTAelWdDWB99DERjSEjFr+qbgBw8KTNCwGsjh6vBnBlifMiojIb7Xv+6araET3eh/yKvUQ0hhR9w0/zb57MN1AislhE2kSkraurq9jDEVGJjLb4O0WkGQCi/81VJFR1paq2qmprOp0e5eGIqNRGW/xrASyKHi8CYI9sIaLTUiGtvucAXAygSUT2ArgHwP0AXhCR6wHsAXB1OZM83fXB7jWlYnbbqMbTzhtUT//KMzLOMj1WZ8b+bs8vzdim1U+asWOLvmnG5sTdLc6M52seGPzIjNVNtJcUy/Xa5yNnnMdczu6zxuP2SMzxZMTiV9VrjdDXSpwLEVUQ/8KPKFAsfqJAsfiJAsXiJwoUi58oUJzAswSSYr+G1nkm8LTHtwEZz8uy7xW7Lzvkfj7PSLUpWTvHmkXfMGM3zbJ/fH7a7m6xDXhamBPNCLD7SLcdTJxhhprFbnGGjld+okCx+IkCxeInChSLnyhQLH6iQLH4iQLFVt8psCZ2TIs9SSdydovNPbVk3u3ZI2bscZlqxg5Jxrn9rqZJ5j6rPuk1Yzd7GpIXHrcn3OwX96i5jGcE5M1GmxIAbjMmBAUAVfsc9xnnY8Azgafv+zKe8MpPFCgWP1GgWPxEgWLxEwWKxU8UKN7tPwW96r6DPTFmn0bfTHw5tV97U0P23e2jcXu/tHET+5F99h39XzQ1mLFFzXPM2NDObWbscMx9l13FPlfHBu2z1Vdnn49cvz0fX8y4q1/vOfeh4BkgChSLnyhQLH6iQLH4iQLF4icKFIufKFCFLNe1CsDXAexX1fOjbcsA3ADgxLK7S1X11XIlebpIDrjbRpms3aLKxu0BJAdht6jg7pTlnzPbY8ZqjUE/NZ4lqDpr7DbaG8ljZuwHQ7VmrCdnDKjxND93bdpkxhJnX2jG5MMddgzuQT+ZpH3dC6X/XciV/2kAlzu2P6Sqc6N/477wicabEYtfVTcAOFiBXIiogop5z3+riGwVkVUiMqVkGRFRRYy2+FcAOAfAXAAdAJZbnygii0WkTUTaurq6rE8jogobVfGraqeqZlU1B+BxAPM9n7tSVVtVtTWdTo82TyIqsVEVv4g0D/vwKgD2CA8iOi0V0up7DsDFAJpEZC+AewBcLCJzASiA3QBuLGOOp41Uwt2+qvPML3c8Z89Lt/gflpmxHy65w4wdPsOzBNhB9/EGMgPmPv2e2Fl6phk75mlVDhmxoZx9rJeeeMKMLVn3nBn7nxmtZixuTO+XOOJZLG1SGEt8jVj8qnqtY/OTZciFiCqIf+FHFCgWP1GgWPxEgWLxEwWKxU8UqFAGMJXED+++27m9JmOPVMsk7Nhf37XUjP1zrf0X018Wu/02Oelu9b1//c3mPheveNCM3Tm4x4y9eabdclzQPujcXmPuAUz892fN2NlPr7bzgN1OjcGd46Ivnmvus7qj3YyNJ7zyEwWKxU8UKBY/UaBY/ESBYvETBYrFTxQotvpOksvZI9V6H3SPOkuKPdtmn2dUX9YzGvCMjN1G2w93Gw0AmlLu1/PZKx4192lI1puxpw7Zo/ASvXYsF3c/Zyxpn9+6mD0h6FHPZSqbsM9VzOi0zjtkj+qzp1yFMR3o2MQrP1GgWPxEgWLxEwWKxU8UKBY/UaB4t/8UdMZ7nduniH2XOuF5fX33P39qxhbXNpqxFf0HzFguO8m5vT5pD6kRte/AJ5N2RwJqx2LGPfNEzP66Hl0wz4xtqrfn1WvO2vfnkzH3ft25fnOfQbWfr0bGz/1+XvmJAsXiJwoUi58oUCx+okCx+IkCxeInClQhy3XNAvAjANORH/OwUlUfFpGpAJ4H0IL8kl1Xq+qh8qVaGbGY/XoYj7kHq2TVHthzoM5uG7228FtmbG7cHngyCe52HgDkrE6UJ0dRu33lG+jUl7TnJ5w86G4tyqA9KCmx7jUz9pmc3U7dN8UePHXWIXeOMfvLAsTO0T8L4dhSyJU/A+A7qjoHwEUAbhGROQCWAFivqrMBrI8+JqIxYsTiV9UOVX0nenwUwHYAMwAsBHBiStXVAK4sV5JEVHqn9J5fRFoAXAhgI4DpqtoRhfYh/7aAiMaIgotfRCYAeBHA7araMzymqgpjDgQRWSwibSLS1tXVVVSyRFQ6BRW/iCSRL/xnVPWlaHOniDRH8WYA+137qupKVW1V1dZ0Ol2KnImoBEYsfhERAE8C2K6qw5d2WQtgUfR4EYBXSp8eEZVLIaP6vgLgOgDviciWaNtSAPcDeEFErgewB8DV5Unx9JHot9tllsE+e/RYLGX3m+5Qe166I4k+M1YLez6+UhPPCLfBUfwFyaUJ+3xMGLRjMaOtmOdutdapL0H73I8nIxa/qr4Fe97Cr5U2HSKqFP6FH1GgWPxEgWLxEwWKxU8UKBY/UaA4gedJskN2O68x524bxT1to56E3Yba45kLckrGDqY860nl4u5RbDd4upTPJO0n/MEk+0ekrdH+ur//m4PO7ZPEnsBz5tBEM3YHDpuxS47bObZIg3N7jdi512Q9ZTGOuoC88hMFisVPFCgWP1GgWPxEgWLxEwWKxU8UKLb6TjLgGVmWMl4rEwn7NK7L9Jixb2ZSZqxWPGvkeWSNMViP1di9vgHY6+D9fZ+dR9/Bo2ZsA9wtx9/1tEWHPO23Oz2jFT/4y0vNWOKF/3Ju9y65553dc/xcL8fPV0JEp4TFTxQoFj9RoFj8RIFi8RMFinf7T1Iv9h34m4Y6ndtTnjvzVwzYg2Yer5tgxqzOAgD0w74bnVP38ZJZ++vKir3c1cGsHcvW2LfMhwbd50TFzj0j9rlKmOuQAcufecqMNa5xL2024Bk4lfG0AsZTwfDKTxQoFj9RoFj8RIFi8RMFisVPFCgWP1GgRuxciMgsAD9CfgluBbBSVR8WkWUAbgBwYundpar6arkSPR3UxGpPeZ8drz1rxrKewSVxzyCXeO7U22XJuH0wydottpyn7VU/ZJ+PpLp/tBT2ACNV++vyDXNaft4fmrHvfbjVub12PPXsRqmQU5AB8B1VfUdEGgFsFpF1UewhVf2X8qVHROVSyFp9HQA6osdHRWQ7gBnlToyIyuuU3vOLSAuACwFsjDbdKiJbRWSViEwpcW5EVEYFF7+ITADwIoDbVbUHwAoA5wCYi/xvBsuN/RaLSJuItHV1dbk+hYiqoKDiF5Ek8oX/jKq+BACq2qmqWc3fpXkcwHzXvqq6UlVbVbU1nU6XKm8iKtKIxS8iAuBJANtV9cFh25uHfdpVALaVPj0iKpdC7vZ/BcB1AN4TkS3RtqUArhWRuci3/3YDuLEsGY4BaoykA4AfX/VXZmwq7FZZIma/Lvtesa1uWc4zmk6Nef8Af4utB4Nm7GfT3C29C7o9X5f6RtPZ62Q1/GaXGcsaJ8TXSg1FIXf73wKcPx3juqdPNN7x5Y8oUCx+okCx+IkCxeInChSLnyhQHNtUCr4JH+M1ZqwmZ7evfMtJxWJ2cFDdLbaUZ5ks8UwIOmR3MeHpzGHvZPfwj9wB9ySoAJCI2wfLetqptZ7JSSHuZcN43eMZIAoWi58oUCx+okCx+IkCxeInChSLnyhQbPWVgAzYsVzOnrCyxtMrU2MCTABIetat6zcm8PR00ZDxXAIk5+v12aHs3m7n9pxn8tGYZ3LPAc/XnDHbeQC6jbUGm3zjFcPAKz9RoFj8RIFi8RMFisVPFCgWP1GgWPxEgWKrrxRSnlbTaeI47BzjnnZe3DO5p4/RcfSKx+1Rjt48PO1Ubao/9UQCwSs/UaBY/ESBYvETBYrFTxQoFj9RoEa82y8itQA2AKiJPv8nqnqPiJwNYA2AMwBsBnCdqtrrN41j6plwL6eeTkDMnnsu5lmuyydlzMeX88yB51+6yv7aUmLfnc9Ndceyn4zuR8QzrgeDnvSP9vY6t09paBhVHuNJIT9hAwAuUdULkF+O+3IRuQjAAwAeUtVzARwCcH350iSiUhux+DXvWPRhMvqnAC4B8JNo+2oAV5YlQyIqi4J+txSReLRC734A6wD8GsBh1d/OE70XgHuuZiI6LRVU/KqaVdW5AGYCmA/gi4UeQEQWi0ibiLR1dXWNMk0iKrVTuqukqocBvAng9wBMFpETNwxnAmg39lmpqq2q2ppOp4tKlohKZ8TiF5G0iEyOHtcBuBTAduRfBP4i+rRFAF4pV5JEVHqFDOxpBrBaROLIv1i8oKo/E5EPAKwRkXsB/ALAk2XM87QmntfQ5Rl70EkmdtDer/FcMxbvtScNnGy05g575serj3vms/Muk2X33777sXuZsvbp08x9/vaTzWYsk6k1Y5Kyz79nIa/gjVj8qroVwIWO7buQf/9PRGMQ/8KPKFAsfqJAsfiJAsXiJwoUi58oUKKeVk7JDybSBWBP9GETAPeaTpXFPD6NeXzaWMvjLFUt6K/pKlr8nzqwSJuqtlbl4MyDeTAP/tpPFCoWP1Ggqln8K6t47OGYx6cxj08bt3lU7T0/EVUXf+0nClRVil9ELheRX4rIThFZUo0cojx2i8h7IrJFRNoqeNxVIrJfRLYN2zZVRNaJyI7o/ylVymOZiLRH52SLiFxRgTxmicibIvKBiLwvIt+Otlf0nHjyqOg5EZFaEdkkIu9GeXwv2n62iGyM6uZ5ESlu0KKqVvQfgDjy04B9DvkRl+8CmFPpPKJcdgNoqsJxvwpgHoBtw7b9E4Al0eMlAB6oUh7LANxZ4fPRDGBe9LgRwK8AzKn0OfHkUdFzgvyUyROix0kAGwFcBOAFANdE2x8DcHMxx6nGlX8+gJ2qukvzU32vAbCwCnlUjapuAHDyYP6FyE+EClRoQlQjj4pT1Q5VfSd6fBT5yWJmoMLnxJNHRWle2SfNrUbxzwDw8bCPqzn5pwL4uYhsFpHFVcrhhOmq2hE93gdgehVzuVVEtkZvC8r+9mM4EWlBfv6IjajiOTkpD6DC56QSk+aGfsNvgarOA/AnAG4Rka9WOyEg/8qP/AtTNawAcA7yazR0AFheqQOLyAQALwK4XVV7hscqeU4ceVT8nGgRk+YWqhrF3w5g1rCPzck/y01V26P/9wN4GdWdmahTRJoBIPp/fzWSUNXO6AcvB+BxVOiciEgS+YJ7RlVfijZX/Jy48qjWOYmOfcqT5haqGsX/NoDZ0Z3LFIBrAKytdBIi0iAijSceA7gMwDb/XmW1FvmJUIEqToh6otgiV6EC50REBPk5ILer6oPDQhU9J1YelT4nFZs0t1J3ME+6m3kF8ndSfw3gu1XK4XPIdxreBfB+JfMA8Bzyvz4OIf/e7Xrk1zxcD2AHgDcATK1SHv8G4D0AW5EvvuYK5LEA+V/ptwLYEv27otLnxJNHRc8JgN9BflLcrci/0Nw97Gd2E4CdAH4MoKaY4/Av/IgCFfoNP6JgsfiJAsXiJwoUi58oUCx+okCx+IkCxeInChSLnyhQ/weWQA97MpIa/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEvJJREFUeJzt3XuMXOV5x/Hvs+tdL8YmYA+YlbG52YibEptuHaIgSkm5NqqhiQikJVZLcRqFtqiUCoEUqJRKkAYokSIqE0hMxTVcAm1pgFikJqg1rImxDQ7XYsAYmwWDbWzvemef/jHH7do979nxmTNnZnl/H8ny7PvM2Xl2dn97ds475z3m7ohIfDpa3YCItIbCLxIphV8kUgq/SKQUfpFIKfwikVL4RSKl8ItESuEXidSERjY2s7OBW4BO4Efufn3W/SuVis+aNauRhxSRDG+99RYDAwNWz31zh9/MOoEfAmcA7wDPmdmj7v5SaJtZs2axbNmyvA8pDTAL/zxk1bLe/q23hrefU089te77NvJn/3zgNXd/w92HgHuBBQ18PhEpUSPhnwG8Perjd5IxERkHmn7Az8wWmVm/mfUPDAw0++FEpE6NhH89MHPUx4clY3tw98Xu3ufufZVKpYGHE5EiNRL+54A5ZnakmXUDFwKPFtOWiDRb7qP97j5sZpcBj1Ob6rvD3V8srDPJpaczffz0zx4X3OaDzvDR/iv+7FvB2h/9xRXB2q5dg8FajLJmRrJmW5qpoXl+d38MeKygXkSkRHqHn0ikFH6RSCn8IpFS+EUipfCLRKqho/3SPHlPmpk399jU8R8tPDu4zZEnnx6sfbBuVbB24fyTgrU7n3kuddwYDm6TVztOo+2tXfoYTXt+kUgp/CKRUvhFIqXwi0RK4ReJVJRH+8fD0eEs1Wo1WOv6ZFvq+PaeycFtNq8LrryGHTAzWFu3/f+dwf2/Pnz/vdTxaQcXf1p33mXI8ny+TxPt+UUipfCLRErhF4mUwi8SKYVfJFIKv0ikopzqGw9TOYOD4TXwslZB3kH6NODc2eGTcFY/8HiwNudr04K17QMfB2uHH3546vi27Z8Et2mGMr/X420KWXt+kUgp/CKRUvhFIqXwi0RK4ReJlMIvEqmGpvrM7E1gK1AFht29r4imBHp6eoK1bdvSz9wDmHd0+hp+p1+6KLjNkr//62Ct/5f/EawtOO8rwdrH29Kn9DrHwe4m7/qJ7Tidl6WIef7fdXdde1tknBkHv4dFpBkaDb8DT5jZCjML/10pIm2n0T/7T3H39WZ2CPCkmf3G3ZeNvkPyS2ERwMyZ4VVhRKRcDe353X198v8m4GFgfsp9Frt7n7v3Zb0nXUTKlTv8Zra/mU3ZfRs4E1hTVGMi0lyN/Nk/HXg4md6YANzt7j8vpKtIdHSEf/du2fVusDZ1yuxg7Wdvn5g6/vO/nBvcZsaM3mDtvXfeDta+9+Jxwdo/nvuz1PGhlx8JbrP1v38crJUp75TdeDurL3f43f0N4HMF9iIiJdJUn0ikFH6RSCn8IpFS+EUipfCLRCrKBTzbxchIuNb79WeCtU7+M1irzj41dfyQ6WuD2wxsDJ+XtXnwsGDN9g9P9Q117kwd7zxrQXCbMjVjWq5dFgutl/b8IpFS+EUipfCLRErhF4mUwi8SKR3t30ueo6h5j/JOnjgpWHv7d/49WDv6iTOCterE9LX/jlt6TnCb134/fBLRha8cFKx1+I5g7ZAJs1LHl//hU8Ftylw7rx1PtNkXRfSvPb9IpBR+kUgp/CKRUvhFIqXwi0RK4ReJlKb69lLmFNDH2z8O1l4eOjRYu2jkuWDt7u4zU8eHhz4KbjP7of2CNUg/QWcsw89cmDr+yQV/EtxmWpucGDPepwHrpT2/SKQUfpFIKfwikVL4RSKl8ItESuEXidSYU31mdgfwZWCTu5+YjE0F7gOOAN4ELnD3zY00UubZdGXK+rqq3Z3B2sjIJ8HalupL4c+567dSxzsmHhzcJv96cOHtvnpmYC3Banvsb8bDz06z1fOd+Alw9l5jVwFL3X0OsDT5WETGkTHD7+7LgA/3Gl4ALEluLwHOK7gvEWmyvH+DTXf3Dcnt96hdsVdExpGGX4B57QVj8MWfmS0ys34z6x8YCK8PLyLlyhv+jWbWC5D8vyl0R3df7O597t5XqVRyPpyIFC1v+B8FFia3FwKPFNOOiJSlnqm+e4DTgIqZvQNcC1wP3G9mlwDrgAsabeTTOvWS9XVNHQpvd/TsY4O1/X6xOljzrmnp4xnXBvOOnJen6ghPVfpH21LHJ37mqFyPVaas79lIxvM43n6Gxwy/u18UKH2p4F5EpETt8Y4LESmdwi8SKYVfJFIKv0ikFH6RSGkBzxb62MNTQy+9ui5Ye/2QPwh/0mrozZbFT0M54Wmv4cH0933tqm4MbtPdcEfFiGVxT+35RSKl8ItESuEXiZTCLxIphV8kUgq/SKQ01ddCHV3hKaVj2Bqs/brj/PAnre77OqodOdfvzDjBjXnnnJM6PjwxfCZgu0z1xUJ7fpFIKfwikVL4RSKl8ItESuEXiZSO9rfQ1kk7g7Url4YPwQ8d+n6wZjm+pbkv19UZ3ndcdvk1qePrH/xhvseSwmnPLxIphV8kUgq/SKQUfpFIKfwikVL4RSJVz+W67gC+DGxy9xOTseuAS4Hdc05Xu/tjzWqy3eWdKtv//fBU378cdFaw1jkU/raNBJaYa8bac1lf9uadw6njOzJOPPpMow3JPqlnz/8T4OyU8ZvdfW7yL9rgi4xXY4bf3ZcBH5bQi4iUqJHX/JeZ2Sozu8PMDiqsIxEpRd7w3wocDcwFNgA3hu5oZovMrN/M+gcGBnI+nIgULVf43X2ju1fdfQS4DZifcd/F7t7n7n2VSiVvnyJSsFzhN7PeUR+eD6wpph0RKUs9U333AKcBFTN7B7gWOM3M5gIOvAl8s4k9liprSmwksGhd3mm03zz4g2Cte2ROsDbcvX+wZtWhQCG8dl5oenAsWV/300//NHX82OoB+R6sRHmnbsfbpbzGDL+7X5QyfHsTehGREukdfiKRUvhFIqXwi0RK4ReJlMIvEikt4Nlk1QmTgrXDjp0drP3ghHODtT///r+FHzDwTmsbqYa3ITxF1dER3j9kTYg9+w+3pI4fc/HXM7aSMmnPLxIphV8kUgq/SKQUfpFIKfwikVL4RSKlqb69ZJ3Rleesrc7h7cHatC/8cbA298EfB2uTtoTPjNs+JX1KzzvCZ/VlTdplnuCW8Tm/+1h/6vi24W0Zn7A9jLez8/LSnl8kUgq/SKQUfpFIKfwikVL4RSKlo/0tNDycviYgwPwvfSVYm3D3PcHapOrU1PFdO/cLbrNrv/A+oMPDR76rHt5u89CO1PGuNtndZB3Rz7uGX155Hq+IGYk2+VaISNkUfpFIKfwikVL4RSKl8ItESuEXiVQ9l+uaCdwJTKd2Bshid7/FzKYC9wFHULtk1wXuvrl5re6bok/QaYasHnfu3xOsPX76K8Haf/1yRer4n973VHCbqy+5Mlhb8UH61CHAixP7grWujqw1A1uv7Om8LK36eaxnzz8MXOHuxwMnA982s+OBq4Cl7j4HWJp8LCLjxJjhd/cN7v58cnsrsBaYASwAliR3WwKc16wmRaR4+/Sa38yOAOYBy4Hp7r4hKb1H7WWBiIwTdYffzCYDDwKXu/uW0TWvvYBKfRFlZovMrN/M+gcGBhpqVkSKU1f4zayLWvDvcveHkuGNZtab1HuBTWnbuvtid+9z975KpVJEzyJSgDHDb7VDkbcDa939plGlR4GFye2FwCPFtycizVLPWX1fBC4GVpvZymTsauB64H4zuwRYB1xQzwOGpjWKnnppl+m8LFk97vDwt+YA3xWszTlqZup4h3cHt7n4t4Ml/rZ3YrB20CnHhTcs0XiY1m1HY4bf3X9F+GJuXyq2HREpi97hJxIphV8kUgq/SKQUfpFIKfwikSp9Ac92OpuqnXV0h8/qcwsv/PnW2++mFyaEz7KrhmcO2T68JVib0XtMeLtdn4Q/qewhlImOjvC+uYgcac8vEimFXyRSCr9IpBR+kUgp/CKRUvhFIqVr9bWpQXYGa9WeycHatAPTr8m3oxo+u21wMDxt9PGGcK3DPgzWIHw2YNF05l4+2vOLRErhF4mUwi8SKYVfJFIKv0ikdLS/TfUMDQZrm5kUrHnncOp4d0/46Hvn1HBtwmD4CmwvP70sWJvx+TOCNdlTWeta7k17fpFIKfwikVL4RSKl8ItESuEXiZTCLxKpMaf6zGwmcCe1S3A7sNjdbzGz64BLgfeTu17t7o81q9EijYfLOxnhy2vN+8Y1wdrygUWp4wd0hKcOp00IL+K3JeMEnWNP/r1gbURLNba9eub5h4Er3P15M5sCrDCzJ5Paze7+/ea1JyLNUs+1+jYAG5LbW81sLTCj2Y2JSHPt02t+MzsCmAcsT4YuM7NVZnaHmR1UcG8i0kR1h9/MJgMPApe7+xbgVuBoYC61vwxuDGy3yMz6zax/YGCggJZFpAh1hd/MuqgF/y53fwjA3Te6e9XdR4DbgPlp27r7Ynfvc/e+SqVSVN8i0qAxw2+1w9+3A2vd/aZR472j7nY+sKb49kSkWeo52v9F4GJgtZmtTMauBi4ys7nUpv/eBL7ZlA4jlXWppqGhoWBt6uTA+n6bw5fdWrl+e7A289DwoZxPLH29QID9PLwGobSHeo72/wpIm/weF3P6IpJO7/ATiZTCLxIphV8kUgq/SKQUfpFIRbmAZ7ucuZdlZGQkWJswIfxtW7+lK3V86/IngtscecIJwVrnh1uDtUkTw334jmBJ2oT2/CKRUvhFIqXwi0RK4ReJlMIvEimFXyRSUU71jQd5pyM/f+UNqeOv3PCN4DYr302fHgQ462unBWsTdoXPBgwvCSrtQnt+kUgp/CKRUvhFIqXwi0RK4ReJlMIvEqnSp/pC18lrlzPtsq7jl0e1Ws213fDwcK7tOrvTF9Xs+87DwW2mv/FKsDYyIXytvp2D+z6hl7UwaV7t8rOTV56fuSK+Zu35RSKl8ItESuEXiZTCLxIphV8kUmMe7TezHmAZMDG5/wPufq2ZHQncC0wDVgAXu3v4OlL/9/ka67gAWUdXiz7an3V0O+uxstbpy1rfj+HB1OGP3g9fruuAA8OX5OrqCp/00y5adbS8KK3qpZ49/yBwurt/jtrluM82s5OBG4Cb3X02sBm4pHltikjRxgy/12xLPuxK/jlwOvBAMr4EOK8pHYpIU9T1mt/MOpMr9G4CngReBz5y993vRHkHmNGcFkWkGeoKv7tX3X0ucBgwHzi23gcws0Vm1m9m/QMDAznbFJGi7dPRfnf/CHgK+AJwoJntPip1GLA+sM1id+9z975KpdJQsyJSnDHDb2YHm9mBye39gDOAtdR+CXw1udtC4JFmNSkixavnxJ5eYImZdVL7ZXG/u/+rmb0E3Gtm3wV+DdzexD5TFT0t92nggVmj6kj4JJwpPT3B2tBQ+tQhwMQpk4O1vCcmFS3PNFrWz1Xeqdt2NGb43X0VMC9l/A1qr/9FZBzSO/xEIqXwi0RK4ReJlMIvEimFXyRSVub0hJm9D6xLPqwA7fCWP/WxJ/Wxp/HWx+HufnA9n7DU8O/xwGb97t7XkgdXH+pDfejPfpFYKfwikWpl+Be38LFHUx97Uh97+tT20bLX/CLSWvqzXyRSLQm/mZ1tZi+b2WtmdlUrekj6eNPMVpvZSjPrL/Fx7zCzTWa2ZtTYVDN70sxeTf4Pr6rZ3D6uM7P1yXOy0szOLaGPmWb2lJm9ZGYvmtlfJeOlPicZfZT6nJhZj5k9a2YvJH38XTJ+pJktT3Jzn5l1N/RA7l7qP6CT2jJgRwHdwAvA8WX3kfTyJlBpweOeCpwErBk19j3gquT2VcANLerjOuBvSn4+eoGTkttTgFeA48t+TjL6KPU5AQyYnNzuApYDJwP3Axcm4/8EfKuRx2nFnn8+8Jq7v+G1pb7vBRa0oI+WcfdlwId7DS+gthAqlLQgaqCP0rn7Bnd/Prm9ldpiMTMo+TnJ6KNUXtP0RXNbEf4ZwNujPm7l4p8OPGFmK8xsUYt62G26u29Ibr8HTG9hL5eZ2arkZUHTX36MZmZHUFs/YjktfE726gNKfk7KWDQ39gN+p7j7ScA5wLfN7NRWNwS13/zUfjG1wq3A0dSu0bABuLGsBzazycCDwOXuvsdVRsp8TlL6KP058QYWza1XK8K/Hpg56uPg4p/N5u7rk/83AQ/T2pWJNppZL0Dy/6ZWNOHuG5MfvBHgNkp6Tsysi1rg7nL3h5Lh0p+TtD5a9Zwkj73Pi+bWqxXhfw6Ykxy57AYuBB4tuwkz29/Mpuy+DZwJrMneqqkepbYQKrRwQdTdYUucTwnPidUW2rsdWOvuN40qlfqchPoo+zkpbdHcso5g7nU081xqR1JfB65pUQ9HUZtpeAF4scw+gHuo/fm4i9prt0uoXfNwKfAq8Atgaov6+GdgNbCKWvh6S+jjFGp/0q8CVib/zi37Ocnoo9TnBPgstUVxV1H7RfOdUT+zzwKvAT8FJjbyOHqHn0ikYj/gJxIthV8kUgq/SKQUfpFIKfwikVL4RSKl8ItESuEXidT/AOMWJ/B+rsESAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(label_dict)):\n",
    "    print(i,label_dict[i])\n",
    "print('\\n')\n",
    "\n",
    "for root,dirs,files in os.walk('./fashion_test/'):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        img = image.load_img(os.path.join(root,file), target_size=(32, 32))\n",
    "        #img_rgb = image.img_to_array(img)\n",
    "        #img_gray = np.mean(img_rgb, axis=2)\n",
    "        #img_gray = img_gray.reshape(1,32,32,1).astype('float32')\n",
    "        #print(img_gray.shape)\n",
    "        predictrgb(modelvgg1, img)\n",
    "\n",
    "print('\\n')\n",
    "print(np.argmax(modelvgg1.predict(testimg32323[0].reshape(1,32,32,3).astype('float32'))))\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Model of VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,Conv2D,Flatten,Dropout,MaxPooling2D\n",
    "from keras.models import Model\n",
    "def vgg_fm(input_shape):\n",
    "    input_tensor=Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Classification block\n",
    "    #x = Flatten(name='flatten')(x)\n",
    "    x = GlobalAveragePooling2D(name='GlobalAveragePooling2D')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "    return Model(inputs=[input_tensor],outputs=[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "GlobalAveragePooling2D (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 26,557,642\n",
      "Trainable params: 26,557,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trainimg28281 = train_img.reshape(train_img.shape[0], 28, 28,1).astype('float32')\n",
    "testimg28281 = test_img.reshape(test_img.shape[0], 28, 28,1).astype('float32')\n",
    "input_shape = trainimg28281.shape[1:]\n",
    "modelvgg2 = vgg_fm(input_shape)\n",
    "print(trainimg28281.shape)\n",
    "print(modelvgg2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/1000\n",
      " - 11s - loss: 1.2032 - acc: 0.5275 - val_loss: 0.5642 - val_acc: 0.7901\n",
      "Epoch 2/1000\n",
      " - 9s - loss: 0.4716 - acc: 0.8234 - val_loss: 0.3810 - val_acc: 0.8580\n",
      "Epoch 3/1000\n",
      " - 9s - loss: 0.3510 - acc: 0.8688 - val_loss: 0.3250 - val_acc: 0.8799\n",
      "Epoch 4/1000\n",
      " - 9s - loss: 0.3032 - acc: 0.8892 - val_loss: 0.2839 - val_acc: 0.8960\n",
      "Epoch 5/1000\n",
      " - 9s - loss: 0.2661 - acc: 0.9034 - val_loss: 0.2918 - val_acc: 0.8927\n",
      "Epoch 6/1000\n",
      " - 9s - loss: 0.2348 - acc: 0.9140 - val_loss: 0.2605 - val_acc: 0.9098\n",
      "Epoch 7/1000\n",
      " - 9s - loss: 0.2092 - acc: 0.9237 - val_loss: 0.2446 - val_acc: 0.9127\n",
      "Epoch 8/1000\n",
      " - 9s - loss: 0.1993 - acc: 0.9276 - val_loss: 0.2421 - val_acc: 0.9165\n",
      "Epoch 9/1000\n",
      " - 9s - loss: 0.1880 - acc: 0.9323 - val_loss: 0.2401 - val_acc: 0.9185\n",
      "Epoch 10/1000\n",
      " - 9s - loss: 0.1693 - acc: 0.9385 - val_loss: 0.2467 - val_acc: 0.9155\n",
      "Epoch 11/1000\n",
      " - 9s - loss: 0.1492 - acc: 0.9475 - val_loss: 0.2356 - val_acc: 0.9232\n",
      "Epoch 12/1000\n",
      " - 9s - loss: 0.1440 - acc: 0.9479 - val_loss: 0.2440 - val_acc: 0.9200\n",
      "Epoch 13/1000\n",
      " - 9s - loss: 0.1300 - acc: 0.9536 - val_loss: 0.2344 - val_acc: 0.9255\n",
      "Epoch 14/1000\n",
      " - 9s - loss: 0.1194 - acc: 0.9581 - val_loss: 0.2458 - val_acc: 0.9248\n",
      "Epoch 15/1000\n",
      " - 9s - loss: 0.1058 - acc: 0.9617 - val_loss: 0.2574 - val_acc: 0.9187\n",
      "Epoch 16/1000\n",
      " - 9s - loss: 0.1012 - acc: 0.9649 - val_loss: 0.2784 - val_acc: 0.9169\n",
      "Epoch 17/1000\n",
      " - 9s - loss: 0.0982 - acc: 0.9649 - val_loss: 0.3201 - val_acc: 0.9147\n",
      "Epoch 18/1000\n",
      " - 9s - loss: 0.0883 - acc: 0.9692 - val_loss: 0.2745 - val_acc: 0.9188\n",
      "Epoch 19/1000\n",
      " - 9s - loss: 0.0858 - acc: 0.9695 - val_loss: 0.3267 - val_acc: 0.9205\n",
      "Epoch 20/1000\n",
      " - 9s - loss: 0.0683 - acc: 0.9765 - val_loss: 0.3339 - val_acc: 0.9247\n",
      "Epoch 21/1000\n",
      " - 9s - loss: 0.0613 - acc: 0.9795 - val_loss: 0.3297 - val_acc: 0.9199\n",
      "Epoch 22/1000\n",
      " - 9s - loss: 0.0667 - acc: 0.9773 - val_loss: 0.3093 - val_acc: 0.9225\n",
      "Epoch 23/1000\n",
      " - 9s - loss: 0.0582 - acc: 0.9812 - val_loss: 0.3145 - val_acc: 0.9245\n",
      "Epoch 24/1000\n",
      " - 9s - loss: 0.0554 - acc: 0.9820 - val_loss: 0.3401 - val_acc: 0.9245\n",
      "Epoch 25/1000\n",
      " - 9s - loss: 0.0516 - acc: 0.9828 - val_loss: 0.3451 - val_acc: 0.9245\n",
      "Epoch 26/1000\n",
      " - 9s - loss: 0.0489 - acc: 0.9840 - val_loss: 0.3831 - val_acc: 0.9218\n",
      "Epoch 27/1000\n",
      " - 9s - loss: 0.0472 - acc: 0.9850 - val_loss: 0.3756 - val_acc: 0.9199\n",
      "Epoch 28/1000\n",
      " - 9s - loss: 0.0607 - acc: 0.9805 - val_loss: 0.3106 - val_acc: 0.9241\n",
      "Epoch 29/1000\n",
      " - 9s - loss: 0.0461 - acc: 0.9848 - val_loss: 0.3456 - val_acc: 0.9220\n",
      "Epoch 30/1000\n",
      " - 9s - loss: 0.0493 - acc: 0.9843 - val_loss: 0.3956 - val_acc: 0.9248\n",
      "Epoch 31/1000\n",
      " - 9s - loss: 0.0408 - acc: 0.9874 - val_loss: 0.3669 - val_acc: 0.9121\n",
      "Epoch 32/1000\n",
      " - 9s - loss: 0.0515 - acc: 0.9835 - val_loss: 0.4025 - val_acc: 0.9215\n",
      "Epoch 33/1000\n",
      " - 9s - loss: 0.0294 - acc: 0.9911 - val_loss: 0.4063 - val_acc: 0.9255\n",
      "Epoch 34/1000\n",
      " - 9s - loss: 0.0399 - acc: 0.9880 - val_loss: 0.4308 - val_acc: 0.9266\n",
      "Epoch 35/1000\n",
      " - 9s - loss: 0.0291 - acc: 0.9905 - val_loss: 0.4177 - val_acc: 0.9227\n",
      "Epoch 36/1000\n",
      " - 9s - loss: 0.0341 - acc: 0.9887 - val_loss: 0.4088 - val_acc: 0.9270\n",
      "Epoch 37/1000\n",
      " - 9s - loss: 0.0296 - acc: 0.9911 - val_loss: 0.3870 - val_acc: 0.9237\n",
      "Epoch 38/1000\n",
      " - 9s - loss: 0.0338 - acc: 0.9895 - val_loss: 0.4648 - val_acc: 0.9209\n",
      "Epoch 39/1000\n",
      " - 9s - loss: 0.0304 - acc: 0.9910 - val_loss: 0.3790 - val_acc: 0.9263\n",
      "Epoch 40/1000\n",
      " - 9s - loss: 0.0307 - acc: 0.9905 - val_loss: 0.4133 - val_acc: 0.9205\n",
      "Epoch 41/1000\n",
      " - 9s - loss: 0.0263 - acc: 0.9919 - val_loss: 0.4141 - val_acc: 0.9258\n",
      "Epoch 42/1000\n",
      " - 9s - loss: 0.0271 - acc: 0.9913 - val_loss: 0.4685 - val_acc: 0.9230\n",
      "Epoch 43/1000\n",
      " - 9s - loss: 0.0291 - acc: 0.9906 - val_loss: 0.4883 - val_acc: 0.9221\n",
      "Epoch 44/1000\n",
      " - 9s - loss: 0.0260 - acc: 0.9924 - val_loss: 0.4250 - val_acc: 0.9268\n",
      "Epoch 45/1000\n",
      " - 9s - loss: 0.0314 - acc: 0.9912 - val_loss: 0.4099 - val_acc: 0.9255\n",
      "Epoch 46/1000\n",
      " - 9s - loss: 0.0372 - acc: 0.9891 - val_loss: 0.4159 - val_acc: 0.9244\n",
      "Epoch 47/1000\n",
      " - 9s - loss: 0.0313 - acc: 0.9905 - val_loss: 0.4148 - val_acc: 0.9229\n",
      "Epoch 48/1000\n",
      " - 9s - loss: 0.0238 - acc: 0.9928 - val_loss: 0.4404 - val_acc: 0.9233\n",
      "Epoch 49/1000\n",
      " - 9s - loss: 0.0238 - acc: 0.9932 - val_loss: 0.4537 - val_acc: 0.9240\n",
      "Epoch 50/1000\n",
      " - 9s - loss: 0.0224 - acc: 0.9929 - val_loss: 0.5022 - val_acc: 0.9231\n",
      "Epoch 51/1000\n",
      " - 9s - loss: 0.0370 - acc: 0.9887 - val_loss: 0.3959 - val_acc: 0.9219\n",
      "Epoch 52/1000\n",
      " - 9s - loss: 0.0274 - acc: 0.9918 - val_loss: 0.4629 - val_acc: 0.9233\n",
      "Epoch 53/1000\n",
      " - 9s - loss: 0.0301 - acc: 0.9906 - val_loss: 0.5015 - val_acc: 0.9240\n",
      "Epoch 54/1000\n",
      " - 9s - loss: 0.0233 - acc: 0.9934 - val_loss: 0.4886 - val_acc: 0.9246\n",
      "Epoch 55/1000\n",
      " - 9s - loss: 0.0199 - acc: 0.9938 - val_loss: 0.5255 - val_acc: 0.9236\n",
      "Epoch 56/1000\n",
      " - 9s - loss: 0.0177 - acc: 0.9951 - val_loss: 0.5255 - val_acc: 0.9060\n",
      "Epoch 57/1000\n",
      " - 9s - loss: 0.0355 - acc: 0.9907 - val_loss: 0.4385 - val_acc: 0.9220\n",
      "Epoch 58/1000\n",
      " - 9s - loss: 0.0273 - acc: 0.9922 - val_loss: 0.4094 - val_acc: 0.9255\n",
      "Epoch 59/1000\n",
      " - 9s - loss: 0.0207 - acc: 0.9938 - val_loss: 0.4195 - val_acc: 0.9227\n",
      "Epoch 60/1000\n",
      " - 9s - loss: 0.0199 - acc: 0.9942 - val_loss: 0.4643 - val_acc: 0.9230\n",
      "Epoch 61/1000\n",
      " - 9s - loss: 0.0170 - acc: 0.9950 - val_loss: 0.5022 - val_acc: 0.9244\n",
      "Epoch 62/1000\n",
      " - 9s - loss: 0.0226 - acc: 0.9940 - val_loss: 0.4673 - val_acc: 0.9251\n",
      "Epoch 63/1000\n",
      " - 9s - loss: 0.0324 - acc: 0.9918 - val_loss: 0.5009 - val_acc: 0.9255\n",
      "Epoch 64/1000\n",
      " - 9s - loss: 0.0288 - acc: 0.9917 - val_loss: 0.4371 - val_acc: 0.9253\n",
      "Epoch 65/1000\n",
      " - 9s - loss: 0.0201 - acc: 0.9934 - val_loss: 0.4537 - val_acc: 0.9262\n",
      "Epoch 66/1000\n",
      " - 9s - loss: 0.0159 - acc: 0.9950 - val_loss: 0.5287 - val_acc: 0.9245\n",
      "Epoch 67/1000\n",
      " - 9s - loss: 0.0162 - acc: 0.9952 - val_loss: 0.5469 - val_acc: 0.9263\n",
      "Epoch 68/1000\n",
      " - 9s - loss: 0.0259 - acc: 0.9925 - val_loss: 0.4649 - val_acc: 0.9238\n",
      "Epoch 69/1000\n",
      " - 9s - loss: 0.0229 - acc: 0.9937 - val_loss: 0.4883 - val_acc: 0.9196\n",
      "Epoch 70/1000\n",
      " - 9s - loss: 0.0224 - acc: 0.9935 - val_loss: 0.5051 - val_acc: 0.9198\n",
      "Epoch 71/1000\n",
      " - 9s - loss: 0.0212 - acc: 0.9937 - val_loss: 0.3816 - val_acc: 0.9155\n",
      "Epoch 72/1000\n",
      " - 9s - loss: 0.0451 - acc: 0.9870 - val_loss: 0.4938 - val_acc: 0.9244\n",
      "Epoch 73/1000\n",
      " - 9s - loss: 0.0171 - acc: 0.9950 - val_loss: 0.4646 - val_acc: 0.9260\n",
      "Epoch 74/1000\n",
      " - 9s - loss: 0.0274 - acc: 0.9922 - val_loss: 0.4949 - val_acc: 0.9248\n",
      "Epoch 75/1000\n",
      " - 9s - loss: 0.0224 - acc: 0.9935 - val_loss: 0.5996 - val_acc: 0.9258\n",
      "Epoch 76/1000\n",
      " - 9s - loss: 0.0463 - acc: 0.9875 - val_loss: 0.5120 - val_acc: 0.9249\n",
      "Epoch 77/1000\n",
      " - 9s - loss: 0.0253 - acc: 0.9928 - val_loss: 0.4895 - val_acc: 0.9264\n",
      "Epoch 78/1000\n",
      " - 9s - loss: 0.0176 - acc: 0.9947 - val_loss: 0.5136 - val_acc: 0.9262\n",
      "Epoch 79/1000\n",
      " - 9s - loss: 0.0237 - acc: 0.9935 - val_loss: 0.5619 - val_acc: 0.9263\n",
      "Epoch 80/1000\n",
      " - 9s - loss: 0.0130 - acc: 0.9967 - val_loss: 0.4871 - val_acc: 0.9299\n",
      "Epoch 81/1000\n",
      " - 9s - loss: 0.0130 - acc: 0.9964 - val_loss: 0.5291 - val_acc: 0.9225\n",
      "Epoch 82/1000\n",
      " - 9s - loss: 0.0304 - acc: 0.9922 - val_loss: 0.4849 - val_acc: 0.9210\n",
      "Epoch 83/1000\n",
      " - 9s - loss: 0.0189 - acc: 0.9946 - val_loss: 0.5563 - val_acc: 0.9247\n",
      "Epoch 84/1000\n",
      " - 9s - loss: 0.0152 - acc: 0.9952 - val_loss: 0.4897 - val_acc: 0.9285\n",
      "Epoch 85/1000\n",
      " - 9s - loss: 0.0137 - acc: 0.9962 - val_loss: 0.5294 - val_acc: 0.9146\n",
      "Epoch 86/1000\n",
      " - 9s - loss: 0.0231 - acc: 0.9936 - val_loss: 0.5324 - val_acc: 0.9235\n",
      "Epoch 87/1000\n",
      " - 9s - loss: 0.0219 - acc: 0.9944 - val_loss: 0.4398 - val_acc: 0.9131\n",
      "Epoch 88/1000\n",
      " - 9s - loss: 0.0218 - acc: 0.9938 - val_loss: 0.5096 - val_acc: 0.9191\n",
      "Epoch 89/1000\n",
      " - 9s - loss: 0.0173 - acc: 0.9954 - val_loss: 0.5110 - val_acc: 0.9240\n",
      "Epoch 90/1000\n",
      " - 9s - loss: 0.0265 - acc: 0.9945 - val_loss: 0.5187 - val_acc: 0.9205\n",
      "Epoch 91/1000\n",
      " - 9s - loss: 0.0205 - acc: 0.9939 - val_loss: 0.5684 - val_acc: 0.9215\n",
      "Epoch 92/1000\n",
      " - 9s - loss: 0.0139 - acc: 0.9960 - val_loss: 0.5620 - val_acc: 0.9255\n",
      "Epoch 93/1000\n",
      " - 9s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.5652 - val_acc: 0.9261\n",
      "Epoch 94/1000\n",
      " - 9s - loss: 0.0114 - acc: 0.9964 - val_loss: 0.5517 - val_acc: 0.9254\n",
      "Epoch 95/1000\n",
      " - 9s - loss: 0.0101 - acc: 0.9979 - val_loss: 0.6419 - val_acc: 0.9186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      " - 9s - loss: 0.0234 - acc: 0.9935 - val_loss: 0.6220 - val_acc: 0.9265\n",
      "Epoch 97/1000\n",
      " - 9s - loss: 0.0107 - acc: 0.9971 - val_loss: 0.5831 - val_acc: 0.9275\n",
      "Epoch 98/1000\n",
      " - 9s - loss: 0.0239 - acc: 0.9937 - val_loss: 0.5709 - val_acc: 0.9285\n",
      "Epoch 99/1000\n",
      " - 9s - loss: 0.0334 - acc: 0.9910 - val_loss: 0.4767 - val_acc: 0.9234\n",
      "Epoch 100/1000\n",
      " - 9s - loss: 0.0216 - acc: 0.9932 - val_loss: 0.4992 - val_acc: 0.9265\n",
      "Epoch 101/1000\n",
      " - 9s - loss: 0.0115 - acc: 0.9967 - val_loss: 0.5753 - val_acc: 0.9240\n",
      "Epoch 102/1000\n",
      " - 9s - loss: 0.0239 - acc: 0.9930 - val_loss: 0.5285 - val_acc: 0.9214\n",
      "Epoch 103/1000\n",
      " - 9s - loss: 0.0137 - acc: 0.9958 - val_loss: 0.5508 - val_acc: 0.9274\n",
      "Epoch 104/1000\n",
      " - 9s - loss: 0.0272 - acc: 0.9927 - val_loss: 0.5120 - val_acc: 0.9232\n",
      "Epoch 105/1000\n",
      " - 9s - loss: 0.0185 - acc: 0.9954 - val_loss: 0.5550 - val_acc: 0.9272\n",
      "Epoch 106/1000\n",
      " - 9s - loss: 0.0359 - acc: 0.9913 - val_loss: 0.5746 - val_acc: 0.9210\n",
      "Epoch 107/1000\n",
      " - 9s - loss: 0.0199 - acc: 0.9942 - val_loss: 0.5414 - val_acc: 0.9262\n",
      "Epoch 108/1000\n",
      " - 9s - loss: 0.0103 - acc: 0.9973 - val_loss: 0.6560 - val_acc: 0.9218\n",
      "Epoch 109/1000\n",
      " - 9s - loss: 0.0149 - acc: 0.9955 - val_loss: 0.5547 - val_acc: 0.9156\n",
      "Epoch 110/1000\n",
      " - 9s - loss: 0.0235 - acc: 0.9938 - val_loss: 0.6116 - val_acc: 0.9210\n",
      "Epoch 111/1000\n",
      " - 9s - loss: 0.0272 - acc: 0.9936 - val_loss: 0.5443 - val_acc: 0.9206\n",
      "Epoch 112/1000\n",
      " - 9s - loss: 0.0230 - acc: 0.9943 - val_loss: 0.5515 - val_acc: 0.9253\n",
      "Epoch 113/1000\n",
      " - 9s - loss: 0.0163 - acc: 0.9964 - val_loss: 0.5100 - val_acc: 0.9145\n",
      "Epoch 114/1000\n",
      " - 9s - loss: 0.0300 - acc: 0.9921 - val_loss: 0.4226 - val_acc: 0.9116\n",
      "Epoch 115/1000\n",
      " - 9s - loss: 0.0413 - acc: 0.9890 - val_loss: 0.4150 - val_acc: 0.9202\n",
      "Epoch 116/1000\n",
      " - 9s - loss: 0.0235 - acc: 0.9943 - val_loss: 0.5033 - val_acc: 0.9274\n",
      "Epoch 117/1000\n",
      " - 9s - loss: 0.0144 - acc: 0.9962 - val_loss: 0.5736 - val_acc: 0.9252\n",
      "Epoch 118/1000\n",
      " - 9s - loss: 0.0141 - acc: 0.9962 - val_loss: 0.6279 - val_acc: 0.9270\n",
      "Epoch 119/1000\n",
      " - 9s - loss: 0.0051 - acc: 0.9986 - val_loss: 0.6880 - val_acc: 0.9287\n",
      "Epoch 120/1000\n",
      " - 9s - loss: 0.0158 - acc: 0.9964 - val_loss: 0.4848 - val_acc: 0.9229\n",
      "Epoch 121/1000\n",
      " - 9s - loss: 0.0198 - acc: 0.9950 - val_loss: 0.5920 - val_acc: 0.9232\n",
      "Epoch 122/1000\n",
      " - 9s - loss: 0.0417 - acc: 0.9890 - val_loss: 0.5053 - val_acc: 0.9205\n",
      "Epoch 123/1000\n",
      " - 9s - loss: 0.0194 - acc: 0.9943 - val_loss: 0.6051 - val_acc: 0.9249\n",
      "Epoch 124/1000\n",
      " - 9s - loss: 0.0085 - acc: 0.9978 - val_loss: 0.6307 - val_acc: 0.9251\n",
      "Epoch 125/1000\n",
      " - 9s - loss: 0.0109 - acc: 0.9973 - val_loss: 0.5514 - val_acc: 0.9268\n",
      "Epoch 126/1000\n",
      " - 9s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.5843 - val_acc: 0.9255\n",
      "Epoch 127/1000\n",
      " - 9s - loss: 0.0200 - acc: 0.9951 - val_loss: 0.4742 - val_acc: 0.9235\n",
      "Epoch 128/1000\n",
      " - 9s - loss: 0.0107 - acc: 0.9972 - val_loss: 0.5626 - val_acc: 0.9275\n",
      "Epoch 129/1000\n",
      " - 9s - loss: 0.0028 - acc: 0.9992 - val_loss: 0.6429 - val_acc: 0.9275\n",
      "Epoch 130/1000\n",
      " - 9s - loss: 0.0214 - acc: 0.9949 - val_loss: 0.4703 - val_acc: 0.9198\n",
      "Epoch 00130: early stopping\n"
     ]
    }
   ],
   "source": [
    "#from keras.callbacks import EarlyStopping\n",
    "#es = EarlyStopping(monitor='val_acc',mode='max',verbose=1, patience=50)\n",
    "modelvgg2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = modelvgg2.fit(x=trainimg28281,y=train_label,validation_split=0.2, epochs=1000, batch_size=250,verbose=2,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 134us/step\n",
      "Test accuracy: 0.9132\n",
      "Test Loss: 0.5152208694465574\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelvgg2.evaluate(testimg28281, test_label)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test Loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 T-shirt/top\n",
      "1 Trouser\n",
      "2 Pullover\n",
      "3 Dress\n",
      "4 Coat\n",
      "5 Sandal\n",
      "6 Shirt\n",
      "7 Sneaker\n",
      "8 Bag\n",
      "9 Ankle boot\n",
      "\n",
      "\n",
      "bag.jpeg\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "sneaker.jpeg\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1\n",
      "coat.jpeg\n",
      "[[1.0000000e+00 5.3077029e-37 1.2484874e-35 2.5097726e-31 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 4.5814644e-37 0.0000000e+00 0.0000000e+00]]\n",
      "0\n",
      "dress.png\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "6\n",
      "dress2.png\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0\n",
      "\n",
      "\n",
      "9\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAADsZJREFUeJzt3V+MXOV5x/Hfg//Jsg3Y9WIWG3dNhCoBF041sioFIVdpIgcFGwvJxLKCi1AdpIAayUg19KJcIoQT5QIiObWJA6kTi8TCF9CGWpUgqIoYEAUcSk2jjWKz9q5FTDB//PfpxR7Tjdl53/GcM3Nm9/l+pNXOnmfOzrMHfp4/7znva+4uAPFcVncDAOpB+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBDWzlw+2ePFiHxoa6uVDAqEMDw/r+PHj1s59S4XfzNZI+r6kGZL+2d0fSd1/aGhIzWazzEMCSGg0Gm3ft+OX/WY2Q9Ljkr4m6QZJG83shk5/H4DeKvOef5Wkd939t+5+WtJPJa2rpi0A3VYm/Esl/X7Cz4eLbX/CzLaYWdPMmmNjYyUeDkCVuv5pv7vvcPeGuzcGBga6/XAA2lQm/EckXTvh52XFNgBTQJnwvyLpejNbYWazJX1D0v5q2gLQbR0P9bn7WTO7T9K/aXyob5e7H6ysMwBdVWqc392fk/RcRb0A6CFO7wWCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoUqv0mtmwpA8lnZN01t0bVTQ13bh7qf3vv//+ZH1kZKRlbe/evcl9L7us3L//Z8+eTdZPnjzZsrZt27ZSj/34448n6zNnlvrfe9qr4uj8tbsfr+D3AOghXvYDQZUNv0v6pZm9amZbqmgIQG+Ufdl/s7sfMbOrJL1gZv/t7i9OvEPxj8IWSVq+fHnJhwNQlVLP/O5+pPg+KmmfpFWT3GeHuzfcvTEwMFDm4QBUqOPwm9k8M1tw4bakr0p6q6rGAHRXmZf9SyTtM7MLv+df3P1fK+kKQNdZ2THoS9FoNLzZbPbs8frF6tWrk/WhoaFk/dy5c8n6+fPnW9ZyY925//4zZsxI1nPnCaTqqXMAJKl4Ymlpzpw5yfrOnTs76msqazQaajab6QNXmJ5HAEAW4QeCIvxAUIQfCIrwA0ERfiAornmsQO6y1muuuSZZP3HiRLI+b968S+7pgjJDcVVIDdflhurOnDmTrB88eDBZ37RpU8vanj17kvtGwDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8F1q5dm6wvWrQoWZ8/f36y/sknnyTrqct2c+P4uUt+U5cLt/P7Z82a1bKWG+fPXW583XXXJeupv+3o0aPJfa+++upkfTrgmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcv02pMefcOP7s2bOT9dxYe2767NT+p0+fTu6bG6fPTRueq6eu589NzT137txkPXe9f2oehEcffTS57/bt25P1XO9TAc/8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUdpzfzHZJ+rqkUXe/qdi2SNLPJA1JGpa0wd3/0L0265ca13366aeT+546dSpZv/fee5P1Mte9584xyPWWG8/OnYOQ+v25cwxycwk8+eSTyXrqb58O4/RltfPM/yNJay7atk3SAXe/XtKB4mcAU0g2/O7+oqT3L9q8TtLu4vZuSbdX3BeALuv0Pf8Sdx8pbh+VtKSifgD0SOkP/Hz8DWfLN51mtsXMmmbWHBsbK/twACrSafiPmdmgJBXfR1vd0d13uHvD3RsDAwMdPhyAqnUa/v2SNhe3N0t6tpp2APRKNvxmtkfSf0r6CzM7bGb3SHpE0lfM7JCkvyl+BjCFZMf53X1ji9KXK+5l2sqN0+fGq3Nj8Rs2bGhZW7x4cXLf3Dh96pp4Sdq3b1+yfsstt7SsvfTSS8l933vvvWQd5XCGHxAU4QeCIvxAUIQfCIrwA0ERfiAopu6eAnJDhS+//HLLWmqJbElauHBhsn7ixIlkfXS05cmdktK95S7ZRXfxzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHO3wdy49133nlnsr5mzcWTK/+/3NTduSmsc0twP/PMM8n6jTfe2LJ26NCh5L47d+5M1u++++5kPTc1eHQcHSAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+PvDggw8m6/Pnz0/WU9Nv56bmTi3vLeXPA0hNGy6l5xNYvnx5ct/c1N533XVXss44fxpHBwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCyo7zm9kuSV+XNOruNxXbHpb0d5LGirs95O7PdavJqS43lv7OO+8k65dffnmynrtmv4zcOH9Oaq6C3Dj83Llzk/W1a9cm688//3yyHl07z/w/kjTZbBHfc/eVxRfBB6aYbPjd/UVJ7/egFwA9VOY9/31m9oaZ7TKz9JpPAPpOp+H/gaQvSFopaUTS9lZ3NLMtZtY0s+bY2FiruwHosY7C7+7H3P2cu5+X9ENJqxL33eHuDXdvDAwMdNongIp1FH4zG5zw43pJb1XTDoBeaWeob4+k1ZIWm9lhSf8kabWZrZTkkoYlfauLPQLogmz43X3jJJvTE6oHk5vb/o477kjWP/3002T9qquuStZz5xGk5NYMyP1tuXpqLD/Xd663K6+8Mlk/c+ZMy1pqnoEoOMMPCIrwA0ERfiAowg8ERfiBoAg/EBRTd1cgNaQkSWfPnk3WV6xYUWr/MsNpZYbqJOnUqVPJempILddbrr5gwYJkffPmzS1rTz31VHLf3JTn0wHP/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8bUqN5a9fvz657xVXXNHx75by02fnLn1NKTvOP3Nm+n+h1Fh92XH+nNT+uWPGOD+AaYvwA0ERfiAowg8ERfiBoAg/EBThB4JinL9Nt912W8vavHnzkvvmltguc018Ttnpscv+/tRcBLm/K3cOQk5q6fJNmzYl9927d2+px54KeOYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCy4/xmdq2kH0taIskl7XD375vZIkk/kzQkaVjSBnf/Q/da7a7cePdHH33UsjY4ONjxvlJ6PLodqd5zcwHk5hKYM2dOsl7mPIIycwG0IzUXQe645M4xmA7X+7fzzH9W0lZ3v0HSX0n6tpndIGmbpAPufr2kA8XPAKaIbPjdfcTdXytufyjpbUlLJa2TtLu4225Jt3erSQDVu6T3/GY2JOmLkn4taYm7jxSloxp/WwBgimg7/GY2X9LPJX3H3f84sebjb84mfYNmZlvMrGlmzbGxsVLNAqhOW+E3s1kaD/5P3P0XxeZjZjZY1AcljU62r7vvcPeGuzcGBgaq6BlABbLht/GPRXdKetvdvzuhtF/ShWVQN0t6tvr2AHRLO5f0fknSNyW9aWavF9sekvSIpL1mdo+k30na0J0WeyM39JMaziu7DHZOmeG03NTbH3/8cbKeWwY7J/W3545LN49b7nLi3HGbDrLhd/dfSWqVjC9X2w6AXpn+/7wBmBThB4Ii/EBQhB8IivADQRF+ICim7i7kxvnLTOWcG6c/ePBgsv7AAw8k68uWLWtZy/1dc+fOTda3bt2arI+OTnpi52eeeOKJlrUPPvggue/SpUuT9cceeyxZz/1t0fHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBWdnpkS9Fo9HwZrPZs8cDomk0Gmo2m+mTOwo88wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ2fCb2bVm9h9m9hszO2hmf19sf9jMjpjZ68XXrd1vF0BV2lm046ykre7+mpktkPSqmb1Q1L7n7umVEwD0pWz43X1E0khx+0Mze1tSeikVAH3vkt7zm9mQpC9K+nWx6T4ze8PMdpnZwhb7bDGzppk1x8bGSjULoDpth9/M5kv6uaTvuPsfJf1A0hckrdT4K4Ptk+3n7jvcveHujYGBgQpaBlCFtsJvZrM0HvyfuPsvJMndj7n7OXc/L+mHklZ1r00AVWvn036TtFPS2+7+3QnbByfcbb2kt6pvD0C3tPNp/5ckfVPSm2b2erHtIUkbzWylJJc0LOlbXekQQFe082n/ryRNNg/4c9W3A6BXOMMPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl77x7MbEzS7yZsWizpeM8auDT92lu/9iXRW6eq7O3P3b2t+fJ6Gv7PPbhZ090btTWQ0K+99WtfEr11qq7eeNkPBEX4gaDqDv+Omh8/pV9769e+JHrrVC291fqeH0B96n7mB1CTWsJvZmvM7B0ze9fMttXRQytmNmxmbxYrDzdr7mWXmY2a2VsTti0ysxfM7FDxfdJl0mrqrS9Wbk6sLF3rseu3Fa97/rLfzGZI+h9JX5F0WNIrkja6+2962kgLZjYsqeHutY8Jm9ktkk5K+rG731Rse1TS++7+SPEP50J3/4c+6e1hSSfrXrm5WFBmcOLK0pJul/S3qvHYJfraoBqOWx3P/Kskvevuv3X305J+KmldDX30PXd/UdL7F21eJ2l3cXu3xv/n6bkWvfUFdx9x99eK2x9KurCydK3HLtFXLeoI/1JJv5/w82H115LfLumXZvaqmW2pu5lJLCmWTZeko5KW1NnMJLIrN/fSRStL982x62TF66rxgd/n3ezufynpa5K+Xby87Us+/p6tn4Zr2lq5uVcmWVn6M3Ueu05XvK5aHeE/IunaCT8vK7b1BXc/UnwflbRP/bf68LELi6QW30dr7ucz/bRy82QrS6sPjl0/rXhdR/hfkXS9ma0ws9mSviFpfw19fI6ZzSs+iJGZzZP0VfXf6sP7JW0ubm+W9GyNvfyJflm5udXK0qr52PXditfu3vMvSbdq/BP//5X0j3X00KKv6yT9V/F1sO7eJO3R+MvAMxr/bOQeSX8m6YCkQ5L+XdKiPurtKUlvSnpD40EbrKm3mzX+kv4NSa8XX7fWfewSfdVy3DjDDwiKD/yAoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwT1f9NU0icdWgIQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(label_dict)):\n",
    "    print(i,label_dict[i])\n",
    "print('\\n')\n",
    "\n",
    "for root,dirs,files in os.walk('./fashion_test/'):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        img = image.load_img(os.path.join(root,file), target_size=(28, 28))\n",
    "        #img_rgb = image.img_to_array(img)\n",
    "        #img_gray = np.mean(img_rgb, axis=2)\n",
    "        #img_gray = img_gray.reshape(1,32,32,1).astype('float32')\n",
    "        #print(img_gray.shape)\n",
    "        predictgray(modelvgg2, img)\n",
    "\n",
    "print('\\n')\n",
    "print(np.argmax(modelvgg2.predict(testimg28281[0].reshape(1,28,28,1).astype('float32'))))\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 ... 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "predict_class = []\n",
    "prediction = modelvgg2.predict(testimg28281)\n",
    "for index in range (len(test_label)):\n",
    "    predict_class.append(np.argmax(prediction[index]))\n",
    "predict_class = np.int_(predict_class,dtype=np.uint8)\n",
    "#print(len(predict_class))\n",
    "print(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>980</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>894</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>886</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict    0    1    2    3    4    5    6    7    8    9\n",
       "label                                                    \n",
       "0        892    0   15   10    4    0   75    0    4    0\n",
       "1          4  980    4    7    3    0    1    0    1    0\n",
       "2         24    1  894    7   40    0   34    0    0    0\n",
       "3         45    8   11  886   18    0   32    0    0    0\n",
       "4          2    0   52   26  866    0   54    0    0    0\n",
       "5          1    0    0    0    0  982    0   12    0    5\n",
       "6        136    0   74   12   59    1  715    0    3    0\n",
       "7          2    0    0    0    0    4    0  983    0   11\n",
       "8          5    1    3    2    3    4    8    1  973    0\n",
       "9          0    0    1    0    0    5    0   33    0  961"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#print(test_label)\n",
    "pd.crosstab(test_label, predict_class, rownames=['label'], colnames=['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning( ResNet50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "owninputtensor (InputLayer)     (None, 28, 28, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 34, 34, 3)    0           owninputtensor[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 14, 14, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 14, 14, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 14, 14, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 16, 16, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 7, 7, 64)     4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 7, 7, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 7, 7, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 7, 7, 64)     36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 7, 7, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7, 7, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 7, 7, 256)    16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 7, 7, 256)    16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 7, 7, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 7, 7, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 7, 7, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7, 7, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 7, 7, 64)     16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 7, 7, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7, 7, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 7, 7, 64)     36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 7, 7, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7, 7, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 7, 7, 256)    16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 7, 7, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 7, 7, 64)     16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 7, 7, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 7, 7, 64)     36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 7, 7, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 7, 7, 256)    16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 7, 7, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"http_proxy\"] = '10.41.69.79:13128'\n",
    "os.environ[\"https_proxy\"] = '10.41.69.79:13128'\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D,Input,Flatten\n",
    "\n",
    "input_tensor = Input(shape=(28,28,3),name='owninputtensor')\n",
    "base_model=ResNet50(weights=None,input_tensor=input_tensor,include_top=False) \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False \n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "owninputtensor (InputLayer)     (None, 28, 28, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 34, 34, 3)    0           owninputtensor[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 14, 14, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 14, 14, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 14, 14, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 16, 16, 64)   0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 7, 7, 64)     4160        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 7, 7, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 7, 7, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 7, 7, 64)     36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 7, 7, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 7, 7, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 7, 7, 256)    16640       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 7, 7, 256)    16640       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 7, 7, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 7, 7, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 7, 7, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 7, 7, 256)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 7, 7, 64)     16448       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 7, 7, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 7, 7, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 7, 7, 64)     36928       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 7, 7, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 7, 7, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 7, 7, 256)    16640       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 7, 7, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 7, 7, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 7, 7, 256)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 7, 7, 64)     16448       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 7, 7, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 7, 7, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 7, 7, 64)     36928       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 7, 7, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 7, 7, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 7, 7, 256)    16640       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 7, 7, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 7, 7, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 7, 7, 256)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 512)    0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 512)    0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 4, 4, 512)    0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 4, 4, 512)    0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 2, 2, 1024)   0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 2, 2, 1024)   0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 2, 2, 1024)   0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 2, 2, 1024)   0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 2, 2, 1024)   0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 2, 2, 1024)   0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 1, 1, 2048)   0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 1, 1, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 1, 1, 2048)   0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Dense512 (Dense)                (None, 512)          1049088     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           Dense512[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           5130        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,641,930\n",
      "Trainable params: 1,054,218\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#x=base_model.layers[-10].output\n",
    "x = base_model.output\n",
    "#x=GlobalAveragePooling2D(name='GlobalAveragePooling2D')(x)\n",
    "# Classification block\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(512, activation='relu', name='Dense512')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(10, activation='softmax', name='predictions')(x)\n",
    "Res50Model1=Model(inputs=base_model.input,outputs=preds)\n",
    "print(Res50Model1.summary())\n",
    "#Res50Model.summary()\n",
    "# for i,layer in enumerate(model.layers):\n",
    "#     print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainimg28283 = np.stack((train_img,)*3, axis=-1)\n",
    "testimg28283 = np.stack((test_img,)*3, axis=-1)\n",
    "trainimg28283.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1f935eb320>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image.array_to_img(trainimg28283[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/1000\n",
      " - 9s - loss: 2.4220 - acc: 0.1581 - val_loss: 6.3287 - val_acc: 0.1011\n",
      "Epoch 2/1000\n",
      " - 5s - loss: 2.0254 - acc: 0.2331 - val_loss: 7.0436 - val_acc: 0.1020\n",
      "Epoch 3/1000\n",
      " - 5s - loss: 1.9485 - acc: 0.2610 - val_loss: 5.3779 - val_acc: 0.0746\n",
      "Epoch 4/1000\n",
      " - 5s - loss: 1.9098 - acc: 0.2757 - val_loss: 4.9797 - val_acc: 0.0709\n",
      "Epoch 5/1000\n",
      " - 5s - loss: 1.8885 - acc: 0.2840 - val_loss: 5.7842 - val_acc: 0.1034\n",
      "Epoch 6/1000\n",
      " - 5s - loss: 1.8615 - acc: 0.2940 - val_loss: 6.7199 - val_acc: 0.0974\n",
      "Epoch 7/1000\n",
      " - 5s - loss: 1.8517 - acc: 0.2965 - val_loss: 4.6537 - val_acc: 0.1024\n",
      "Epoch 8/1000\n",
      " - 5s - loss: 1.8443 - acc: 0.3034 - val_loss: 8.4019 - val_acc: 0.1020\n",
      "Epoch 9/1000\n",
      " - 5s - loss: 1.8180 - acc: 0.3131 - val_loss: 8.8457 - val_acc: 0.0992\n",
      "Epoch 10/1000\n",
      " - 5s - loss: 1.8169 - acc: 0.3121 - val_loss: 5.8657 - val_acc: 0.0727\n",
      "Epoch 11/1000\n",
      " - 5s - loss: 1.8079 - acc: 0.3183 - val_loss: 7.8491 - val_acc: 0.1021\n",
      "Epoch 12/1000\n",
      " - 5s - loss: 1.8058 - acc: 0.3205 - val_loss: 9.4138 - val_acc: 0.1025\n",
      "Epoch 13/1000\n",
      " - 5s - loss: 1.8013 - acc: 0.3224 - val_loss: 10.8111 - val_acc: 0.1025\n",
      "Epoch 14/1000\n",
      " - 5s - loss: 1.7993 - acc: 0.3256 - val_loss: 7.2549 - val_acc: 0.0897\n",
      "Epoch 15/1000\n",
      " - 5s - loss: 1.7932 - acc: 0.3249 - val_loss: 8.2518 - val_acc: 0.1040\n",
      "Epoch 16/1000\n",
      " - 5s - loss: 1.7853 - acc: 0.3305 - val_loss: 7.4227 - val_acc: 0.1020\n",
      "Epoch 17/1000\n",
      " - 5s - loss: 1.7927 - acc: 0.3215 - val_loss: 7.3740 - val_acc: 0.0994\n",
      "Epoch 18/1000\n",
      " - 5s - loss: 1.7846 - acc: 0.3290 - val_loss: 6.4361 - val_acc: 0.0926\n",
      "Epoch 19/1000\n",
      " - 5s - loss: 1.7854 - acc: 0.3262 - val_loss: 7.5484 - val_acc: 0.1095\n",
      "Epoch 20/1000\n",
      " - 5s - loss: 1.7840 - acc: 0.3293 - val_loss: 7.6879 - val_acc: 0.1307\n",
      "Epoch 21/1000\n",
      " - 5s - loss: 1.7758 - acc: 0.3301 - val_loss: 8.9833 - val_acc: 0.1037\n",
      "Epoch 22/1000\n",
      " - 5s - loss: 1.7820 - acc: 0.3279 - val_loss: 7.2929 - val_acc: 0.1019\n",
      "Epoch 23/1000\n",
      " - 5s - loss: 1.7743 - acc: 0.3303 - val_loss: 7.6476 - val_acc: 0.1024\n",
      "Epoch 24/1000\n",
      " - 5s - loss: 1.7699 - acc: 0.3340 - val_loss: 7.7915 - val_acc: 0.1022\n",
      "Epoch 25/1000\n",
      " - 5s - loss: 1.7759 - acc: 0.3300 - val_loss: 9.6039 - val_acc: 0.1023\n",
      "Epoch 26/1000\n",
      " - 5s - loss: 1.7681 - acc: 0.3359 - val_loss: 8.2125 - val_acc: 0.1483\n",
      "Epoch 27/1000\n",
      " - 5s - loss: 1.7672 - acc: 0.3352 - val_loss: 7.8027 - val_acc: 0.1032\n",
      "Epoch 28/1000\n",
      " - 5s - loss: 1.7642 - acc: 0.3356 - val_loss: 6.7991 - val_acc: 0.1017\n",
      "Epoch 29/1000\n",
      " - 5s - loss: 1.7615 - acc: 0.3355 - val_loss: 7.5843 - val_acc: 0.0981\n",
      "Epoch 30/1000\n",
      " - 5s - loss: 1.7718 - acc: 0.3331 - val_loss: 7.0463 - val_acc: 0.1075\n",
      "Epoch 31/1000\n",
      " - 5s - loss: 1.7702 - acc: 0.3333 - val_loss: 6.4283 - val_acc: 0.0869\n",
      "Epoch 32/1000\n",
      " - 5s - loss: 1.7630 - acc: 0.3333 - val_loss: 7.1091 - val_acc: 0.1038\n",
      "Epoch 33/1000\n",
      " - 5s - loss: 1.7565 - acc: 0.3368 - val_loss: 8.0623 - val_acc: 0.1059\n",
      "Epoch 34/1000\n",
      " - 5s - loss: 1.7656 - acc: 0.3311 - val_loss: 6.8230 - val_acc: 0.1244\n",
      "Epoch 35/1000\n",
      " - 5s - loss: 1.7581 - acc: 0.3394 - val_loss: 9.0876 - val_acc: 0.1402\n",
      "Epoch 36/1000\n",
      " - 5s - loss: 1.7643 - acc: 0.3368 - val_loss: 7.1165 - val_acc: 0.0995\n",
      "Epoch 37/1000\n",
      " - 5s - loss: 1.7533 - acc: 0.3388 - val_loss: 8.0222 - val_acc: 0.1020\n",
      "Epoch 38/1000\n",
      " - 5s - loss: 1.7555 - acc: 0.3367 - val_loss: 7.1377 - val_acc: 0.1321\n",
      "Epoch 39/1000\n",
      " - 5s - loss: 1.7570 - acc: 0.3409 - val_loss: 7.1728 - val_acc: 0.1190\n",
      "Epoch 40/1000\n",
      " - 5s - loss: 1.7587 - acc: 0.3371 - val_loss: 7.7997 - val_acc: 0.1119\n",
      "Epoch 41/1000\n",
      " - 5s - loss: 1.7533 - acc: 0.3451 - val_loss: 7.5487 - val_acc: 0.1023\n",
      "Epoch 42/1000\n",
      " - 5s - loss: 1.7540 - acc: 0.3413 - val_loss: 7.5283 - val_acc: 0.1252\n",
      "Epoch 43/1000\n",
      " - 5s - loss: 1.7547 - acc: 0.3395 - val_loss: 6.7408 - val_acc: 0.1278\n",
      "Epoch 44/1000\n",
      " - 5s - loss: 1.7574 - acc: 0.3390 - val_loss: 7.8108 - val_acc: 0.1215\n",
      "Epoch 45/1000\n",
      " - 5s - loss: 1.7547 - acc: 0.3402 - val_loss: 8.6759 - val_acc: 0.1009\n",
      "Epoch 46/1000\n",
      " - 5s - loss: 1.7539 - acc: 0.3371 - val_loss: 6.9457 - val_acc: 0.1089\n",
      "Epoch 47/1000\n",
      " - 5s - loss: 1.7616 - acc: 0.3365 - val_loss: 5.9627 - val_acc: 0.1010\n",
      "Epoch 48/1000\n",
      " - 5s - loss: 1.7564 - acc: 0.3402 - val_loss: 7.3660 - val_acc: 0.1169\n",
      "Epoch 49/1000\n",
      " - 5s - loss: 1.7479 - acc: 0.3418 - val_loss: 6.7412 - val_acc: 0.1021\n",
      "Epoch 50/1000\n",
      " - 5s - loss: 1.7529 - acc: 0.3395 - val_loss: 7.2973 - val_acc: 0.1033\n",
      "Epoch 51/1000\n",
      " - 5s - loss: 1.7544 - acc: 0.3401 - val_loss: 7.4160 - val_acc: 0.0968\n",
      "Epoch 52/1000\n",
      " - 5s - loss: 1.7527 - acc: 0.3411 - val_loss: 6.1351 - val_acc: 0.1308\n",
      "Epoch 53/1000\n",
      " - 5s - loss: 1.7521 - acc: 0.3399 - val_loss: 7.8632 - val_acc: 0.1096\n",
      "Epoch 54/1000\n",
      " - 5s - loss: 1.7509 - acc: 0.3406 - val_loss: 6.8255 - val_acc: 0.1085\n",
      "Epoch 55/1000\n",
      " - 5s - loss: 1.7564 - acc: 0.3356 - val_loss: 7.0876 - val_acc: 0.1175\n",
      "Epoch 56/1000\n",
      " - 5s - loss: 1.7450 - acc: 0.3415 - val_loss: 7.6680 - val_acc: 0.1041\n",
      "Epoch 57/1000\n",
      " - 5s - loss: 1.7464 - acc: 0.3406 - val_loss: 7.5895 - val_acc: 0.1108\n",
      "Epoch 58/1000\n",
      " - 5s - loss: 1.7385 - acc: 0.3430 - val_loss: 7.3557 - val_acc: 0.1063\n",
      "Epoch 59/1000\n",
      " - 5s - loss: 1.7515 - acc: 0.3411 - val_loss: 7.0961 - val_acc: 0.1195\n",
      "Epoch 60/1000\n",
      " - 5s - loss: 1.7461 - acc: 0.3433 - val_loss: 9.1672 - val_acc: 0.1028\n",
      "Epoch 61/1000\n",
      " - 5s - loss: 1.7444 - acc: 0.3410 - val_loss: 7.2072 - val_acc: 0.1367\n",
      "Epoch 62/1000\n",
      " - 5s - loss: 1.7447 - acc: 0.3427 - val_loss: 8.1673 - val_acc: 0.1020\n",
      "Epoch 63/1000\n",
      " - 5s - loss: 1.7474 - acc: 0.3446 - val_loss: 6.5347 - val_acc: 0.1483\n",
      "Epoch 64/1000\n",
      " - 5s - loss: 1.7491 - acc: 0.3402 - val_loss: 7.2589 - val_acc: 0.1401\n",
      "Epoch 65/1000\n",
      " - 5s - loss: 1.7481 - acc: 0.3407 - val_loss: 5.9790 - val_acc: 0.1029\n",
      "Epoch 66/1000\n",
      " - 5s - loss: 1.7406 - acc: 0.3449 - val_loss: 5.4033 - val_acc: 0.1351\n",
      "Epoch 67/1000\n",
      " - 5s - loss: 1.7480 - acc: 0.3449 - val_loss: 6.7470 - val_acc: 0.1639\n",
      "Epoch 68/1000\n",
      " - 5s - loss: 1.7488 - acc: 0.3439 - val_loss: 7.8254 - val_acc: 0.1170\n",
      "Epoch 69/1000\n",
      " - 5s - loss: 1.7465 - acc: 0.3413 - val_loss: 5.3708 - val_acc: 0.1993\n",
      "Epoch 70/1000\n",
      " - 5s - loss: 1.7426 - acc: 0.3417 - val_loss: 4.7354 - val_acc: 0.1463\n",
      "Epoch 71/1000\n",
      " - 5s - loss: 1.7486 - acc: 0.3414 - val_loss: 6.4232 - val_acc: 0.1525\n",
      "Epoch 72/1000\n",
      " - 5s - loss: 1.7458 - acc: 0.3406 - val_loss: 7.3456 - val_acc: 0.1871\n",
      "Epoch 73/1000\n",
      " - 5s - loss: 1.7450 - acc: 0.3408 - val_loss: 5.6308 - val_acc: 0.1825\n",
      "Epoch 74/1000\n",
      " - 5s - loss: 1.7444 - acc: 0.3444 - val_loss: 6.8742 - val_acc: 0.1151\n",
      "Epoch 75/1000\n",
      " - 5s - loss: 1.7446 - acc: 0.3458 - val_loss: 6.9781 - val_acc: 0.1120\n",
      "Epoch 76/1000\n",
      " - 5s - loss: 1.7405 - acc: 0.3466 - val_loss: 7.7034 - val_acc: 0.1091\n",
      "Epoch 77/1000\n",
      " - 5s - loss: 1.7464 - acc: 0.3423 - val_loss: 6.0839 - val_acc: 0.1716\n",
      "Epoch 78/1000\n",
      " - 5s - loss: 1.7443 - acc: 0.3433 - val_loss: 7.5247 - val_acc: 0.1038\n",
      "Epoch 79/1000\n",
      " - 5s - loss: 1.7409 - acc: 0.3443 - val_loss: 7.4697 - val_acc: 0.1065\n",
      "Epoch 80/1000\n",
      " - 5s - loss: 1.7384 - acc: 0.3457 - val_loss: 6.8988 - val_acc: 0.1334\n",
      "Epoch 81/1000\n",
      " - 5s - loss: 1.7439 - acc: 0.3458 - val_loss: 6.5777 - val_acc: 0.0989\n",
      "Epoch 82/1000\n",
      " - 5s - loss: 1.7483 - acc: 0.3414 - val_loss: 6.7282 - val_acc: 0.1319\n",
      "Epoch 83/1000\n",
      " - 5s - loss: 1.7406 - acc: 0.3444 - val_loss: 7.0947 - val_acc: 0.1106\n",
      "Epoch 84/1000\n",
      " - 5s - loss: 1.7408 - acc: 0.3435 - val_loss: 6.6545 - val_acc: 0.1006\n",
      "Epoch 85/1000\n",
      " - 5s - loss: 1.7427 - acc: 0.3443 - val_loss: 6.8952 - val_acc: 0.1023\n",
      "Epoch 86/1000\n",
      " - 5s - loss: 1.7424 - acc: 0.3418 - val_loss: 6.7084 - val_acc: 0.1671\n",
      "Epoch 87/1000\n",
      " - 5s - loss: 1.7397 - acc: 0.3425 - val_loss: 7.8767 - val_acc: 0.1186\n",
      "Epoch 88/1000\n",
      " - 5s - loss: 1.7461 - acc: 0.3431 - val_loss: 6.7625 - val_acc: 0.1165\n",
      "Epoch 89/1000\n",
      " - 5s - loss: 1.7437 - acc: 0.3442 - val_loss: 7.2155 - val_acc: 0.1598\n",
      "Epoch 90/1000\n",
      " - 5s - loss: 1.7388 - acc: 0.3472 - val_loss: 6.4079 - val_acc: 0.1427\n",
      "Epoch 91/1000\n",
      " - 5s - loss: 1.7493 - acc: 0.3415 - val_loss: 6.4153 - val_acc: 0.1204\n",
      "Epoch 92/1000\n",
      " - 5s - loss: 1.7368 - acc: 0.3460 - val_loss: 6.2091 - val_acc: 0.1277\n",
      "Epoch 93/1000\n",
      " - 5s - loss: 1.7366 - acc: 0.3429 - val_loss: 6.6900 - val_acc: 0.1369\n",
      "Epoch 94/1000\n",
      " - 5s - loss: 1.7383 - acc: 0.3465 - val_loss: 6.5772 - val_acc: 0.1354\n",
      "Epoch 95/1000\n",
      " - 5s - loss: 1.7422 - acc: 0.3428 - val_loss: 6.4427 - val_acc: 0.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      " - 5s - loss: 1.7389 - acc: 0.3440 - val_loss: 7.3995 - val_acc: 0.0918\n",
      "Epoch 97/1000\n",
      " - 5s - loss: 1.7421 - acc: 0.3421 - val_loss: 6.0738 - val_acc: 0.1235\n",
      "Epoch 98/1000\n",
      " - 5s - loss: 1.7464 - acc: 0.3423 - val_loss: 7.1611 - val_acc: 0.1276\n",
      "Epoch 99/1000\n",
      " - 5s - loss: 1.7493 - acc: 0.3455 - val_loss: 7.2624 - val_acc: 0.1213\n",
      "Epoch 100/1000\n",
      " - 5s - loss: 1.7408 - acc: 0.3469 - val_loss: 7.1255 - val_acc: 0.1154\n",
      "Epoch 101/1000\n",
      " - 5s - loss: 1.7374 - acc: 0.3469 - val_loss: 7.4836 - val_acc: 0.1233\n",
      "Epoch 102/1000\n",
      " - 5s - loss: 1.7444 - acc: 0.3433 - val_loss: 7.0442 - val_acc: 0.1285\n",
      "Epoch 103/1000\n",
      " - 5s - loss: 1.7411 - acc: 0.3435 - val_loss: 6.5158 - val_acc: 0.1207\n",
      "Epoch 104/1000\n",
      " - 5s - loss: 1.7374 - acc: 0.3456 - val_loss: 6.9038 - val_acc: 0.1291\n",
      "Epoch 105/1000\n",
      " - 5s - loss: 1.7427 - acc: 0.3426 - val_loss: 7.6755 - val_acc: 0.1020\n",
      "Epoch 106/1000\n",
      " - 5s - loss: 1.7389 - acc: 0.3423 - val_loss: 6.4635 - val_acc: 0.1042\n",
      "Epoch 107/1000\n",
      " - 5s - loss: 1.7419 - acc: 0.3431 - val_loss: 6.9360 - val_acc: 0.1294\n",
      "Epoch 108/1000\n",
      " - 5s - loss: 1.7350 - acc: 0.3468 - val_loss: 6.9621 - val_acc: 0.1261\n",
      "Epoch 109/1000\n",
      " - 5s - loss: 1.7426 - acc: 0.3433 - val_loss: 7.3086 - val_acc: 0.1755\n",
      "Epoch 110/1000\n",
      " - 5s - loss: 1.7378 - acc: 0.3468 - val_loss: 6.4078 - val_acc: 0.1299\n",
      "Epoch 111/1000\n",
      " - 5s - loss: 1.7351 - acc: 0.3494 - val_loss: 7.0729 - val_acc: 0.1059\n",
      "Epoch 112/1000\n",
      " - 5s - loss: 1.7379 - acc: 0.3454 - val_loss: 6.9245 - val_acc: 0.1178\n",
      "Epoch 113/1000\n",
      " - 5s - loss: 1.7292 - acc: 0.3449 - val_loss: 7.8778 - val_acc: 0.1030\n",
      "Epoch 114/1000\n",
      " - 5s - loss: 1.7361 - acc: 0.3412 - val_loss: 6.7004 - val_acc: 0.1389\n",
      "Epoch 115/1000\n",
      " - 5s - loss: 1.7384 - acc: 0.3457 - val_loss: 6.9185 - val_acc: 0.1451\n",
      "Epoch 116/1000\n",
      " - 5s - loss: 1.7339 - acc: 0.3473 - val_loss: 7.3648 - val_acc: 0.1137\n",
      "Epoch 117/1000\n",
      " - 5s - loss: 1.7330 - acc: 0.3455 - val_loss: 7.1575 - val_acc: 0.0989\n",
      "Epoch 118/1000\n",
      " - 5s - loss: 1.7366 - acc: 0.3441 - val_loss: 6.6065 - val_acc: 0.1349\n",
      "Epoch 119/1000\n",
      " - 5s - loss: 1.7360 - acc: 0.3468 - val_loss: 5.9837 - val_acc: 0.1094\n",
      "Epoch 00119: early stopping\n"
     ]
    }
   ],
   "source": [
    "#from keras.callbacks import EarlyStopping\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "Res50Model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "history = Res50Model1.fit(x=trainimg28283,y=train_label,validation_split=0.2,epochs=1000,batch_size=250,verbose=2,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten,Dropout,BatchNormalization,GlobalAveragePooling2D,concatenate,Input, concatenate,Add\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#Define convolution with batchnromalization\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1),name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=3,name=bn_name)(x)\n",
    "    return x\n",
    "  \n",
    "#Define Residual Block for ResNet34(2 convolution layers)\n",
    "def Residual_Block(input_model,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut =False):\n",
    "    x = Conv2d_BN(input_model,nb_filter=nb_filter,kernel_size=kernel_size,strides=strides,padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=nb_filter, kernel_size=kernel_size,padding='same')\n",
    "    \n",
    "    #need convolution on shortcut for add different channel\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(input_model,nb_filter=nb_filter,strides=strides,kernel_size=kernel_size)\n",
    "        #x = add([x,shortcut])\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        #x = add([x,input_model])\n",
    "        x = Add()([x, input_model])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built ResNet34\n",
    "def ResNet34(input_shape):\n",
    "    \n",
    "    input_tensor=Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2d_BN(input_tensor,64,(3,3),strides=(2,2),padding='same')\n",
    "    x = MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x)  \n",
    "\n",
    "    #Residual conv2_x ouput 56x56x64 \n",
    "    x = Residual_Block(x,nb_filter=64,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=64,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=64,kernel_size=(3,3))\n",
    "    \n",
    "    #Residual conv3_x ouput 28x28x128 \n",
    "    x = Residual_Block(x,nb_filter=128,kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)# need do convolution to add different channel\n",
    "    x = Residual_Block(x,nb_filter=128,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=128,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=128,kernel_size=(3,3))\n",
    "    \n",
    "    #Residual conv4_x ouput 14x14x256\n",
    "    x = Residual_Block(x,nb_filter=256,kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)# need do convolution to add different channel\n",
    "    x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=256,kernel_size=(3,3))\n",
    "    \n",
    "    #Residual conv5_x ouput 7x7x512\n",
    "    x = Residual_Block(x,nb_filter=512,kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)\n",
    "    x = Residual_Block(x,nb_filter=512,kernel_size=(3,3))\n",
    "    x = Residual_Block(x,nb_filter=512,kernel_size=(3,3))\n",
    "\n",
    "\n",
    "    #Using AveragePooling replace flatten\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10,activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=[input_tensor],outputs=[x]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary & Accuracy of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   640         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 64)     36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 64)     36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 7, 7, 64)     0           batch_normalization_3[0][0]      \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 64)     36928       add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 64)     36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 7, 7, 64)     0           batch_normalization_5[0][0]      \n",
      "                                                                 add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 64)     36928       add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 64)     36928       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 7, 7, 64)     0           batch_normalization_7[0][0]      \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    73856       add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    147584      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 128)    73856       add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 4, 4, 128)    0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 128)    147584      add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 128)    147584      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 4, 4, 128)    0           batch_normalization_12[0][0]     \n",
      "                                                                 add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 128)    147584      add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 128)    147584      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "                                                                 add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 128)    147584      add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 128)    147584      batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 128)    512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 4, 4, 128)    0           batch_normalization_16[0][0]     \n",
      "                                                                 add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 256)    295168      add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 2, 2, 256)    1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 2, 256)    590080      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 256)    295168      add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 2, 2, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 2, 2, 256)    1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 2, 2, 256)    0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 256)    590080      add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 2, 2, 256)    1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 2, 256)    590080      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2, 2, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 2, 2, 256)    0           batch_normalization_21[0][0]     \n",
      "                                                                 add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 2, 2, 256)    590080      add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2, 2, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 2, 256)    590080      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2, 2, 256)    1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 2, 2, 256)    0           batch_normalization_23[0][0]     \n",
      "                                                                 add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 2, 2, 256)    590080      add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 2, 2, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 2, 2, 256)    590080      batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 2, 2, 256)    1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 2, 2, 256)    0           batch_normalization_25[0][0]     \n",
      "                                                                 add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 2, 2, 256)    590080      add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 2, 2, 256)    1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 2, 2, 256)    590080      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 2, 2, 256)    1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 2, 2, 256)    0           batch_normalization_27[0][0]     \n",
      "                                                                 add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 256)    590080      add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2, 2, 256)    1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 2, 2, 256)    590080      batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2, 2, 256)    1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 2, 2, 256)    0           batch_normalization_29[0][0]     \n",
      "                                                                 add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 1, 1, 512)    1180160     add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1, 1, 512)    2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 1, 1, 512)    2359808     batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 1, 1, 512)    1180160     add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1, 1, 512)    2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1, 1, 512)    2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 1, 1, 512)    0           batch_normalization_31[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 1, 1, 512)    2359808     add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1, 1, 512)    2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 1, 1, 512)    2359808     batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1, 1, 512)    2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 1, 1, 512)    0           batch_normalization_34[0][0]     \n",
      "                                                                 add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1, 1, 512)    2359808     add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1, 1, 512)    2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 1, 1, 512)    2359808     batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 1, 512)    2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 1, 1, 512)    0           batch_normalization_36[0][0]     \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 22,682,762\n",
      "Trainable params: 22,665,738\n",
      "Non-trainable params: 17,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = trainimg28281.shape[1:]\n",
    "Res34Model1 = ResNet34(input_shape)\n",
    "print(Res34Model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/1000\n",
      " - 21s - loss: 0.6337 - acc: 0.8070 - val_loss: 0.4280 - val_acc: 0.8611\n",
      "Epoch 2/1000\n",
      " - 14s - loss: 0.3243 - acc: 0.8816 - val_loss: 0.3391 - val_acc: 0.8841\n",
      "Epoch 3/1000\n",
      " - 14s - loss: 0.2607 - acc: 0.9035 - val_loss: 0.3535 - val_acc: 0.8785\n",
      "Epoch 4/1000\n",
      " - 14s - loss: 0.2203 - acc: 0.9179 - val_loss: 0.3567 - val_acc: 0.8851\n",
      "Epoch 5/1000\n",
      " - 14s - loss: 0.1993 - acc: 0.9268 - val_loss: 0.3249 - val_acc: 0.8935\n",
      "Epoch 6/1000\n",
      " - 14s - loss: 0.1800 - acc: 0.9332 - val_loss: 0.3649 - val_acc: 0.8875\n",
      "Epoch 7/1000\n",
      " - 14s - loss: 0.1601 - acc: 0.9406 - val_loss: 0.3693 - val_acc: 0.8906\n",
      "Epoch 8/1000\n",
      " - 14s - loss: 0.1488 - acc: 0.9456 - val_loss: 0.5685 - val_acc: 0.8780\n",
      "Epoch 9/1000\n",
      " - 14s - loss: 0.1323 - acc: 0.9513 - val_loss: 0.3571 - val_acc: 0.8871\n",
      "Epoch 10/1000\n",
      " - 14s - loss: 0.1197 - acc: 0.9568 - val_loss: 0.3584 - val_acc: 0.8989\n",
      "Epoch 11/1000\n",
      " - 14s - loss: 0.1146 - acc: 0.9581 - val_loss: 0.3580 - val_acc: 0.8965\n",
      "Epoch 12/1000\n",
      " - 14s - loss: 0.1000 - acc: 0.9632 - val_loss: 0.3646 - val_acc: 0.8966\n",
      "Epoch 13/1000\n",
      " - 14s - loss: 0.0911 - acc: 0.9663 - val_loss: 0.3477 - val_acc: 0.9012\n",
      "Epoch 14/1000\n",
      " - 14s - loss: 0.0868 - acc: 0.9684 - val_loss: 0.4763 - val_acc: 0.8826\n",
      "Epoch 15/1000\n",
      " - 14s - loss: 0.0863 - acc: 0.9692 - val_loss: 0.3607 - val_acc: 0.8984\n",
      "Epoch 16/1000\n",
      " - 14s - loss: 0.0823 - acc: 0.9706 - val_loss: 0.4075 - val_acc: 0.8915\n",
      "Epoch 17/1000\n",
      " - 14s - loss: 0.0742 - acc: 0.9732 - val_loss: 0.3945 - val_acc: 0.8915\n",
      "Epoch 18/1000\n",
      " - 14s - loss: 0.0728 - acc: 0.9741 - val_loss: 0.3943 - val_acc: 0.8964\n",
      "Epoch 19/1000\n",
      " - 14s - loss: 0.0642 - acc: 0.9772 - val_loss: 0.3892 - val_acc: 0.9010\n",
      "Epoch 20/1000\n",
      " - 14s - loss: 0.0664 - acc: 0.9763 - val_loss: 0.4192 - val_acc: 0.8980\n",
      "Epoch 21/1000\n",
      " - 14s - loss: 0.0719 - acc: 0.9738 - val_loss: 0.4152 - val_acc: 0.8995\n",
      "Epoch 22/1000\n",
      " - 14s - loss: 0.0532 - acc: 0.9812 - val_loss: 0.4243 - val_acc: 0.9031\n",
      "Epoch 23/1000\n",
      " - 14s - loss: 0.0543 - acc: 0.9807 - val_loss: 0.3953 - val_acc: 0.8980\n",
      "Epoch 24/1000\n",
      " - 14s - loss: 0.0427 - acc: 0.9851 - val_loss: 0.3941 - val_acc: 0.9038\n",
      "Epoch 25/1000\n",
      " - 14s - loss: 0.0422 - acc: 0.9849 - val_loss: 0.4426 - val_acc: 0.8945\n",
      "Epoch 26/1000\n",
      " - 14s - loss: 0.0493 - acc: 0.9827 - val_loss: 0.4211 - val_acc: 0.8984\n",
      "Epoch 27/1000\n",
      " - 14s - loss: 0.0393 - acc: 0.9867 - val_loss: 0.4644 - val_acc: 0.8937\n",
      "Epoch 28/1000\n",
      " - 14s - loss: 0.0491 - acc: 0.9833 - val_loss: 0.9173 - val_acc: 0.8636\n",
      "Epoch 29/1000\n",
      " - 14s - loss: 0.0835 - acc: 0.9722 - val_loss: 0.5199 - val_acc: 0.8825\n",
      "Epoch 30/1000\n",
      " - 14s - loss: 0.0375 - acc: 0.9871 - val_loss: 0.4300 - val_acc: 0.9003\n",
      "Epoch 31/1000\n",
      " - 14s - loss: 0.0344 - acc: 0.9875 - val_loss: 0.4314 - val_acc: 0.9085\n",
      "Epoch 32/1000\n",
      " - 14s - loss: 0.0282 - acc: 0.9900 - val_loss: 0.4721 - val_acc: 0.9092\n",
      "Epoch 33/1000\n",
      " - 14s - loss: 0.0333 - acc: 0.9887 - val_loss: 0.4550 - val_acc: 0.9002\n",
      "Epoch 34/1000\n",
      " - 14s - loss: 0.0283 - acc: 0.9905 - val_loss: 0.4732 - val_acc: 0.8913\n",
      "Epoch 35/1000\n",
      " - 14s - loss: 0.0334 - acc: 0.9889 - val_loss: 0.4774 - val_acc: 0.9045\n",
      "Epoch 36/1000\n",
      " - 14s - loss: 0.0282 - acc: 0.9902 - val_loss: 0.4304 - val_acc: 0.9057\n",
      "Epoch 37/1000\n",
      " - 14s - loss: 0.0307 - acc: 0.9891 - val_loss: 0.4918 - val_acc: 0.8966\n",
      "Epoch 38/1000\n",
      " - 14s - loss: 0.0257 - acc: 0.9909 - val_loss: 0.4522 - val_acc: 0.9058\n",
      "Epoch 39/1000\n",
      " - 14s - loss: 0.0261 - acc: 0.9913 - val_loss: 0.4322 - val_acc: 0.9030\n",
      "Epoch 40/1000\n",
      " - 14s - loss: 0.0225 - acc: 0.9924 - val_loss: 0.5346 - val_acc: 0.8950\n",
      "Epoch 41/1000\n",
      " - 14s - loss: 0.0293 - acc: 0.9903 - val_loss: 0.4705 - val_acc: 0.9064\n",
      "Epoch 42/1000\n",
      " - 14s - loss: 0.0239 - acc: 0.9915 - val_loss: 0.5520 - val_acc: 0.8952\n",
      "Epoch 43/1000\n",
      " - 14s - loss: 0.0223 - acc: 0.9927 - val_loss: 0.4822 - val_acc: 0.9077\n",
      "Epoch 44/1000\n",
      " - 14s - loss: 0.0226 - acc: 0.9928 - val_loss: 0.5103 - val_acc: 0.9014\n",
      "Epoch 45/1000\n",
      " - 14s - loss: 0.0153 - acc: 0.9954 - val_loss: 0.5659 - val_acc: 0.8946\n",
      "Epoch 46/1000\n",
      " - 14s - loss: 0.0225 - acc: 0.9925 - val_loss: 0.4690 - val_acc: 0.9080\n",
      "Epoch 47/1000\n",
      " - 14s - loss: 0.0201 - acc: 0.9935 - val_loss: 0.4815 - val_acc: 0.9049\n",
      "Epoch 48/1000\n",
      " - 14s - loss: 0.0193 - acc: 0.9936 - val_loss: 0.5219 - val_acc: 0.9035\n",
      "Epoch 49/1000\n",
      " - 14s - loss: 0.0240 - acc: 0.9920 - val_loss: 0.4919 - val_acc: 0.9071\n",
      "Epoch 50/1000\n",
      " - 14s - loss: 0.0165 - acc: 0.9942 - val_loss: 0.5186 - val_acc: 0.8975\n",
      "Epoch 51/1000\n",
      " - 14s - loss: 0.0193 - acc: 0.9939 - val_loss: 0.5214 - val_acc: 0.9053\n",
      "Epoch 52/1000\n",
      " - 14s - loss: 0.0248 - acc: 0.9918 - val_loss: 0.4441 - val_acc: 0.9074\n",
      "Epoch 53/1000\n",
      " - 14s - loss: 0.0205 - acc: 0.9936 - val_loss: 0.4973 - val_acc: 0.9071\n",
      "Epoch 54/1000\n",
      " - 14s - loss: 0.0197 - acc: 0.9937 - val_loss: 0.5048 - val_acc: 0.9004\n",
      "Epoch 55/1000\n",
      " - 14s - loss: 0.0153 - acc: 0.9953 - val_loss: 0.4607 - val_acc: 0.9061\n",
      "Epoch 56/1000\n",
      " - 14s - loss: 0.0104 - acc: 0.9966 - val_loss: 0.5146 - val_acc: 0.9070\n",
      "Epoch 57/1000\n",
      " - 14s - loss: 0.0134 - acc: 0.9957 - val_loss: 0.4707 - val_acc: 0.9086\n",
      "Epoch 58/1000\n",
      " - 14s - loss: 0.0150 - acc: 0.9953 - val_loss: 0.5851 - val_acc: 0.9039\n",
      "Epoch 59/1000\n",
      " - 14s - loss: 0.0189 - acc: 0.9939 - val_loss: 0.4952 - val_acc: 0.9040\n",
      "Epoch 60/1000\n",
      " - 14s - loss: 0.0136 - acc: 0.9959 - val_loss: 0.5364 - val_acc: 0.9052\n",
      "Epoch 61/1000\n",
      " - 14s - loss: 0.0148 - acc: 0.9952 - val_loss: 0.5728 - val_acc: 0.8991\n",
      "Epoch 62/1000\n",
      " - 14s - loss: 0.0141 - acc: 0.9955 - val_loss: 0.5659 - val_acc: 0.8994\n",
      "Epoch 63/1000\n",
      " - 14s - loss: 0.0151 - acc: 0.9945 - val_loss: 0.5306 - val_acc: 0.9063\n",
      "Epoch 64/1000\n",
      " - 14s - loss: 0.0130 - acc: 0.9960 - val_loss: 0.5089 - val_acc: 0.9080\n",
      "Epoch 65/1000\n",
      " - 14s - loss: 0.0083 - acc: 0.9975 - val_loss: 0.5564 - val_acc: 0.9035\n",
      "Epoch 66/1000\n",
      " - 14s - loss: 0.0132 - acc: 0.9958 - val_loss: 0.6876 - val_acc: 0.8797\n",
      "Epoch 67/1000\n",
      " - 14s - loss: 0.0159 - acc: 0.9948 - val_loss: 0.5124 - val_acc: 0.9061\n",
      "Epoch 68/1000\n",
      " - 14s - loss: 0.0157 - acc: 0.9948 - val_loss: 0.5189 - val_acc: 0.9086\n",
      "Epoch 69/1000\n",
      " - 14s - loss: 0.0133 - acc: 0.9957 - val_loss: 0.5389 - val_acc: 0.9016\n",
      "Epoch 70/1000\n",
      " - 14s - loss: 0.0140 - acc: 0.9955 - val_loss: 0.5555 - val_acc: 0.9041\n",
      "Epoch 71/1000\n",
      " - 14s - loss: 0.0100 - acc: 0.9965 - val_loss: 0.5408 - val_acc: 0.9011\n",
      "Epoch 72/1000\n",
      " - 14s - loss: 0.0089 - acc: 0.9973 - val_loss: 0.5732 - val_acc: 0.9023\n",
      "Epoch 73/1000\n",
      " - 14s - loss: 0.0136 - acc: 0.9957 - val_loss: 0.5183 - val_acc: 0.9105\n",
      "Epoch 74/1000\n",
      " - 14s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.5295 - val_acc: 0.9037\n",
      "Epoch 75/1000\n",
      " - 14s - loss: 0.0139 - acc: 0.9955 - val_loss: 0.5382 - val_acc: 0.9071\n",
      "Epoch 76/1000\n",
      " - 14s - loss: 0.0084 - acc: 0.9972 - val_loss: 0.5374 - val_acc: 0.9111\n",
      "Epoch 77/1000\n",
      " - 14s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.5794 - val_acc: 0.8998\n",
      "Epoch 78/1000\n",
      " - 14s - loss: 0.0059 - acc: 0.9984 - val_loss: 0.5649 - val_acc: 0.9095\n",
      "Epoch 79/1000\n",
      " - 14s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.5455 - val_acc: 0.9077\n",
      "Epoch 80/1000\n",
      " - 14s - loss: 0.0150 - acc: 0.9948 - val_loss: 0.5670 - val_acc: 0.9023\n",
      "Epoch 81/1000\n",
      " - 14s - loss: 0.0125 - acc: 0.9960 - val_loss: 0.5581 - val_acc: 0.8956\n",
      "Epoch 82/1000\n",
      " - 14s - loss: 0.0110 - acc: 0.9964 - val_loss: 0.5515 - val_acc: 0.8983\n",
      "Epoch 83/1000\n",
      " - 14s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.5893 - val_acc: 0.9025\n",
      "Epoch 84/1000\n",
      " - 14s - loss: 0.0103 - acc: 0.9967 - val_loss: 0.5321 - val_acc: 0.9074\n",
      "Epoch 85/1000\n",
      " - 14s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.5755 - val_acc: 0.9056\n",
      "Epoch 86/1000\n",
      " - 14s - loss: 0.0070 - acc: 0.9978 - val_loss: 0.5140 - val_acc: 0.9104\n",
      "Epoch 87/1000\n",
      " - 14s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.5541 - val_acc: 0.9057\n",
      "Epoch 88/1000\n",
      " - 14s - loss: 0.0125 - acc: 0.9961 - val_loss: 0.5478 - val_acc: 0.9005\n",
      "Epoch 89/1000\n",
      " - 14s - loss: 0.0077 - acc: 0.9975 - val_loss: 0.5128 - val_acc: 0.9091\n",
      "Epoch 90/1000\n",
      " - 14s - loss: 0.0052 - acc: 0.9986 - val_loss: 0.5646 - val_acc: 0.9082\n",
      "Epoch 91/1000\n",
      " - 14s - loss: 0.0111 - acc: 0.9965 - val_loss: 0.5462 - val_acc: 0.9045\n",
      "Epoch 92/1000\n",
      " - 14s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.6318 - val_acc: 0.8985\n",
      "Epoch 93/1000\n",
      " - 14s - loss: 0.0060 - acc: 0.9983 - val_loss: 0.6298 - val_acc: 0.8958\n",
      "Epoch 94/1000\n",
      " - 14s - loss: 0.0035 - acc: 0.9988 - val_loss: 0.6109 - val_acc: 0.9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      " - 14s - loss: 0.0080 - acc: 0.9978 - val_loss: 0.6143 - val_acc: 0.8987\n",
      "Epoch 96/1000\n",
      " - 14s - loss: 0.0087 - acc: 0.9972 - val_loss: 0.5448 - val_acc: 0.9067\n",
      "Epoch 97/1000\n",
      " - 14s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.5644 - val_acc: 0.9050\n",
      "Epoch 98/1000\n",
      " - 14s - loss: 0.0101 - acc: 0.9968 - val_loss: 0.5266 - val_acc: 0.9063\n",
      "Epoch 99/1000\n",
      " - 14s - loss: 0.0111 - acc: 0.9965 - val_loss: 0.5177 - val_acc: 0.9069\n",
      "Epoch 100/1000\n",
      " - 14s - loss: 0.0090 - acc: 0.9971 - val_loss: 0.5038 - val_acc: 0.9065\n",
      "Epoch 101/1000\n",
      " - 14s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.5138 - val_acc: 0.9104\n",
      "Epoch 102/1000\n",
      " - 14s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.5638 - val_acc: 0.9092\n",
      "Epoch 103/1000\n",
      " - 14s - loss: 0.0101 - acc: 0.9963 - val_loss: 0.5284 - val_acc: 0.9053\n",
      "Epoch 104/1000\n",
      " - 14s - loss: 0.0050 - acc: 0.9984 - val_loss: 0.5743 - val_acc: 0.9117\n",
      "Epoch 105/1000\n",
      " - 14s - loss: 0.0035 - acc: 0.9991 - val_loss: 0.5846 - val_acc: 0.9048\n",
      "Epoch 106/1000\n",
      " - 14s - loss: 0.0082 - acc: 0.9976 - val_loss: 0.5388 - val_acc: 0.9069\n",
      "Epoch 107/1000\n",
      " - 14s - loss: 0.0059 - acc: 0.9982 - val_loss: 0.5284 - val_acc: 0.9090\n",
      "Epoch 108/1000\n",
      " - 14s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.5748 - val_acc: 0.9102\n",
      "Epoch 109/1000\n",
      " - 14s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.5991 - val_acc: 0.9044\n",
      "Epoch 110/1000\n",
      " - 14s - loss: 0.0087 - acc: 0.9973 - val_loss: 0.6200 - val_acc: 0.8986\n",
      "Epoch 111/1000\n",
      " - 14s - loss: 0.0134 - acc: 0.9959 - val_loss: 0.5307 - val_acc: 0.9006\n",
      "Epoch 112/1000\n",
      " - 14s - loss: 0.0099 - acc: 0.9966 - val_loss: 0.5165 - val_acc: 0.9127\n",
      "Epoch 113/1000\n",
      " - 14s - loss: 0.0062 - acc: 0.9978 - val_loss: 0.5719 - val_acc: 0.9058\n",
      "Epoch 114/1000\n",
      " - 14s - loss: 0.0039 - acc: 0.9989 - val_loss: 0.5651 - val_acc: 0.9075\n",
      "Epoch 115/1000\n",
      " - 14s - loss: 0.0023 - acc: 0.9994 - val_loss: 0.6024 - val_acc: 0.9093\n",
      "Epoch 116/1000\n",
      " - 14s - loss: 0.0016 - acc: 0.9995 - val_loss: 0.6466 - val_acc: 0.9081\n",
      "Epoch 117/1000\n",
      " - 14s - loss: 0.0074 - acc: 0.9974 - val_loss: 0.5968 - val_acc: 0.8993\n",
      "Epoch 118/1000\n",
      " - 14s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.5524 - val_acc: 0.9092\n",
      "Epoch 119/1000\n",
      " - 14s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.5713 - val_acc: 0.9030\n",
      "Epoch 120/1000\n",
      " - 14s - loss: 0.0048 - acc: 0.9982 - val_loss: 0.5914 - val_acc: 0.9049\n",
      "Epoch 121/1000\n",
      " - 14s - loss: 0.0079 - acc: 0.9977 - val_loss: 0.5643 - val_acc: 0.9011\n",
      "Epoch 122/1000\n",
      " - 14s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.5835 - val_acc: 0.9057\n",
      "Epoch 123/1000\n",
      " - 14s - loss: 0.0051 - acc: 0.9986 - val_loss: 0.5506 - val_acc: 0.9097\n",
      "Epoch 124/1000\n",
      " - 14s - loss: 0.0032 - acc: 0.9989 - val_loss: 0.5814 - val_acc: 0.9073\n",
      "Epoch 125/1000\n",
      " - 14s - loss: 0.0053 - acc: 0.9984 - val_loss: 0.5774 - val_acc: 0.9073\n",
      "Epoch 126/1000\n",
      " - 14s - loss: 0.0062 - acc: 0.9981 - val_loss: 0.5983 - val_acc: 0.9015\n",
      "Epoch 127/1000\n",
      " - 14s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.5888 - val_acc: 0.9037\n",
      "Epoch 128/1000\n",
      " - 14s - loss: 0.0067 - acc: 0.9980 - val_loss: 0.5780 - val_acc: 0.9093\n",
      "Epoch 129/1000\n",
      " - 14s - loss: 0.0059 - acc: 0.9982 - val_loss: 0.5781 - val_acc: 0.9063\n",
      "Epoch 130/1000\n",
      " - 14s - loss: 0.0027 - acc: 0.9992 - val_loss: 0.6052 - val_acc: 0.9105\n",
      "Epoch 131/1000\n",
      " - 14s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.5824 - val_acc: 0.9067\n",
      "Epoch 132/1000\n",
      " - 14s - loss: 0.0095 - acc: 0.9970 - val_loss: 0.5667 - val_acc: 0.9053\n",
      "Epoch 133/1000\n",
      " - 14s - loss: 0.0070 - acc: 0.9977 - val_loss: 0.5559 - val_acc: 0.9094\n",
      "Epoch 134/1000\n",
      " - 14s - loss: 0.0055 - acc: 0.9981 - val_loss: 0.5751 - val_acc: 0.9081\n",
      "Epoch 135/1000\n",
      " - 14s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.5620 - val_acc: 0.9077\n",
      "Epoch 136/1000\n",
      " - 14s - loss: 0.0032 - acc: 0.9990 - val_loss: 0.5987 - val_acc: 0.9104\n",
      "Epoch 137/1000\n",
      " - 14s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.6070 - val_acc: 0.9098\n",
      "Epoch 138/1000\n",
      " - 14s - loss: 0.0042 - acc: 0.9988 - val_loss: 0.5790 - val_acc: 0.9097\n",
      "Epoch 139/1000\n",
      " - 14s - loss: 0.0042 - acc: 0.9988 - val_loss: 0.5979 - val_acc: 0.9064\n",
      "Epoch 140/1000\n",
      " - 14s - loss: 0.0082 - acc: 0.9972 - val_loss: 0.6780 - val_acc: 0.8925\n",
      "Epoch 141/1000\n",
      " - 14s - loss: 0.0069 - acc: 0.9979 - val_loss: 0.5955 - val_acc: 0.9038\n",
      "Epoch 142/1000\n",
      " - 14s - loss: 0.0052 - acc: 0.9983 - val_loss: 0.6271 - val_acc: 0.9065\n",
      "Epoch 143/1000\n",
      " - 14s - loss: 0.0048 - acc: 0.9984 - val_loss: 0.5942 - val_acc: 0.9086\n",
      "Epoch 144/1000\n",
      " - 14s - loss: 0.0048 - acc: 0.9983 - val_loss: 0.6028 - val_acc: 0.9047\n",
      "Epoch 145/1000\n",
      " - 14s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.6299 - val_acc: 0.9075\n",
      "Epoch 146/1000\n",
      " - 14s - loss: 0.0026 - acc: 0.9991 - val_loss: 0.6716 - val_acc: 0.9044\n",
      "Epoch 147/1000\n",
      " - 14s - loss: 0.0056 - acc: 0.9985 - val_loss: 0.5821 - val_acc: 0.9055\n",
      "Epoch 148/1000\n",
      " - 14s - loss: 0.0037 - acc: 0.9986 - val_loss: 0.5677 - val_acc: 0.9105\n",
      "Epoch 149/1000\n",
      " - 14s - loss: 0.0023 - acc: 0.9993 - val_loss: 0.6303 - val_acc: 0.8994\n",
      "Epoch 150/1000\n",
      " - 14s - loss: 0.0021 - acc: 0.9994 - val_loss: 0.6219 - val_acc: 0.9098\n",
      "Epoch 151/1000\n",
      " - 14s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.6284 - val_acc: 0.9068\n",
      "Epoch 152/1000\n",
      " - 14s - loss: 0.0062 - acc: 0.9980 - val_loss: 0.5750 - val_acc: 0.9107\n",
      "Epoch 153/1000\n",
      " - 14s - loss: 0.0066 - acc: 0.9978 - val_loss: 0.6626 - val_acc: 0.8983\n",
      "Epoch 154/1000\n",
      " - 14s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.6009 - val_acc: 0.9100\n",
      "Epoch 155/1000\n",
      " - 14s - loss: 0.0025 - acc: 0.9993 - val_loss: 0.6234 - val_acc: 0.9111\n",
      "Epoch 156/1000\n",
      " - 14s - loss: 0.0050 - acc: 0.9985 - val_loss: 0.6467 - val_acc: 0.9035\n",
      "Epoch 157/1000\n",
      " - 14s - loss: 0.0037 - acc: 0.9989 - val_loss: 0.6216 - val_acc: 0.9085\n",
      "Epoch 158/1000\n",
      " - 14s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.6156 - val_acc: 0.9075\n",
      "Epoch 159/1000\n",
      " - 14s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.5670 - val_acc: 0.9073\n",
      "Epoch 160/1000\n",
      " - 14s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.6076 - val_acc: 0.9084\n",
      "Epoch 161/1000\n",
      " - 14s - loss: 0.0021 - acc: 0.9994 - val_loss: 0.6211 - val_acc: 0.9115\n",
      "Epoch 162/1000\n",
      " - 14s - loss: 8.3649e-04 - acc: 0.9998 - val_loss: 0.6623 - val_acc: 0.9066\n",
      "Epoch 00162: early stopping\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "Res34Model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = Res34Model1.fit(x=trainimg28281,y=train_label,validation_split=0.2, epochs=1000, batch_size=200,verbose=2,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 312us/step\n",
      "Test accuracy: 0.9048\n",
      "Test loss: 0.6681126592134359\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = Res34Model1.evaluate(testimg28281, test_label)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 T-shirt/top\n",
      "1 Trouser\n",
      "2 Pullover\n",
      "3 Dress\n",
      "4 Coat\n",
      "5 Sandal\n",
      "6 Shirt\n",
      "7 Sneaker\n",
      "8 Bag\n",
      "9 Ankle boot\n",
      "\n",
      "\n",
      "bag.jpeg\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1\n",
      "sneaker.jpeg\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1\n",
      "coat.jpeg\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1\n",
      "dress.png\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1\n",
      "dress2.png\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1\n",
      "\n",
      "\n",
      "9\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEPBJREFUeJzt3W+MleWZx/HfJQww4BBBBoL/FlSoMZioHNRYsumiNlYbsW9M1TQYTacmJVmTvlh1X6wvjbFtTNzU0JUUN13bTVoiL0xXVzchJKtxMOMfal2UTBWCMkD5/2dgvPbFPJpR51z3cZ5zznNm7u8nIcyca5451xz4zTkz1/Pct7m7AOTnnKobAFANwg9kivADmSL8QKYIP5Apwg9kivADmSL8QKYIP5Cp6e28swULFviSJUvaeZdZiM7SHBwcDI89depUWDezsD5z5sywvnTp0rCO5hocHNT+/fvjf7RCqfCb2a2SnpI0TdK/ufvj0ccvWbJE/f39Ze4S4zhz5kzd2n333Rceu3PnzrB+zjnxi8Ply5eH9U2bNtWtpb6x4Jur1WoNf+yEX/ab2TRJ/yrpe5KulHS3mV050c8HoL3K/Mx/naQP3H2Xuw9L+p2ktc1pC0CrlQn/hZI+HvP+7uK2LzGzPjPrN7P+oaGhEncHoJla/tt+d9/g7jV3r/X29rb67gA0qEz490i6eMz7FxW3AZgEyoT/DUnLzGypmc2Q9ENJW5rTFoBWm/Coz93Pmtl6Sf+l0VHfRnff0bTO8IWRkZGw/uCDD9atbd++PTy2q6srrKfGca+99lpYj3p75plnSt03yik153f3FyW92KReALQRp/cCmSL8QKYIP5Apwg9kivADmSL8QKbaej1/ro4cORLWn3zyybC+a9eusB5dU3/27Nnw2NScP7WjU6p++vTpurV77703PHbVqlVhPTqHQJK6u7vDeu545gcyRfiBTBF+IFOEH8gU4QcyRfiBTDHqa4LUuGvdunVhPTWS2r9/f1ifO3du3drRo0fDY2fMmBHWp02bFtajUZ4UjxpTx27dujWsDwwMhPVo5WDwzA9ki/ADmSL8QKYIP5Apwg9kivADmSL8QKaY8zfBZ599FtaPHz8e1lOz9NQ22tE23GvXxtsnvv7662E9Zc2aNWF927ZtdWvR+QmSdMEFF4T1jz/+OKxH5xhMn85/fZ75gUwRfiBThB/IFOEHMkX4gUwRfiBThB/IVKlhp5kNSjoqaUTSWXevNaOpyWbLli1h/cyZM2H9xIkTYT01D4+Uud5eSveeOofh0KFDdWuXXXZZeGzZ3o8dO1a3dt5554XH5qAZZzr8g7vHq00A6Di87AcyVTb8LuklM9tuZn3NaAhAe5R92b/a3feY2UJJL5vZX9z9SwuvFd8U+iTpkksuKXl3AJql1DO/u+8p/t4nabOk68b5mA3uXnP3Wm9vb5m7A9BEEw6/mc0xs57P35b0XUnvNqsxAK1V5mX/Ikmbzezzz/Mf7v6npnQFoOUsteZ8M9VqNe/v72/b/bXL9ddfH9ZTa+Onri1PHT88PFy3tnDhwvDY2bNnh/WTJ0+G9dR5AMWTw7hSc/zUfgXR1uRS/Li99NJL4bGTVa1WU39/f/0HfQxGfUCmCD+QKcIPZIrwA5ki/ECmCD+QKdYvboLUyOqcc+LvsalLU6NxmSStWLGibi21vHVqVJf62lLLjkfjunPPPTc8NrUkeuq+Dxw4ENZzxzM/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZYs7fBqk5/sjISFhPXfIbbbOdWvY79bl7enrC+t69e8P6rFmz6tZSS5anzm9I1RHjmR/IFOEHMkX4gUwRfiBThB/IFOEHMkX4gUwx529QtMR5alaemkenrpkvM4tPLc2+b9++sH7q1KmwnlpWPKqnPneq9zLX+6c+dw7nEPDMD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxAppJzfjPbKOn7kva5+4ritvmSfi9piaRBSXe5+99a1+bkllq3/9VXXw3rt99+e1iP1gtIrW1//vnnh/XUeQCpefi8efPq1lJ7BqxatSqs79ixI6xHawmk1ljo6uoK61NBI8/8v5F061due1jSK+6+TNIrxfsAJpFk+N19q6SDX7l5raRNxdubJN3Z5L4AtNhEf+Zf5O6fr9/0iaRFTeoHQJuU/oWfj54kXfdEaTPrM7N+M+sfGhoqe3cAmmSi4f/UzBZLUvF33d8KufsGd6+5e623t3eCdweg2SYa/i2S1hVvr5P0QnPaAdAuyfCb2fOS/lfSt8xst5k9IOlxSbeY2U5JNxfvA5hEknN+d7+7TummJvfS0aJ5dmomnJq1p+qpefjJkyfr1nbv3h0ee9VVV4X17u7usL59+/awfuONN4b1yNNPPx3Wb7755rAezfJTayTkgDP8gEwRfiBThB/IFOEHMkX4gUwRfiBTzDsaFC2vnRrVpS7pnT9/flhPXTYbbfF9+eWXh8emxoippblTojHk4cOHw2NTS3OXreeOZ34gU4QfyBThBzJF+IFMEX4gU4QfyBThBzLFnL9B0ay97FbSqTl+qj5z5sy6tdQ5CMePHw/rJ06cCOtr1qwJ68eOHatbmzt3bnhs6utOLb8dYYtunvmBbBF+IFOEH8gU4QcyRfiBTBF+IFOEH8gUc/4GRdfkp655T82jUzPnjz76KKxfeumldWupcwxSc/yenp6wnur91KlTdWupryu1DsLw8HBYj85/SB0bbe89VfDMD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxAppJzfjPbKOn7kva5+4ritsck/VjSUPFhj7r7i61qshPcf//9dWupOX4065bSs/hrrrkmrEfr9qeumT9y5EhY37VrV1i/6KKLwnp0nsDBgwfDY1PnIKSuuY/OQUjtZ5Da2nwqaOSZ/zeSbh3n9l+6+9XFnykdfGAqSobf3bdKir9FA5h0yvzMv97M3jazjWY2r2kdAWiLiYb/V5Iuk3S1pL2Sfl7vA82sz8z6zax/aGio3ocBaLMJhd/dP3X3EXf/TNKvJV0XfOwGd6+5e623t3eifQJosgmF38wWj3n3B5LebU47ANqlkVHf85K+I2mBme2W9C+SvmNmV0tySYOSftLCHgG0QDL87n73ODc/24JeKpW6Lv3DDz+sW0vNm6M96iVp5cqVYX327NlhPbpuPVo3X0qvRbBs2bKwnjpHIdo34JZbbgmPvemmm8J66jyBhQsX1q2lfgTNYV1/zvADMkX4gUwRfiBThB/IFOEHMkX4gUyxdHeDTp8+XbfW3d0dHhuN4qT0NtqpsVO0xPX06eX+iVPHp0Ze0Sjw8OHD4bGpMWTqvqPHJTWiLDPCnCx45gcyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFPM+QupmXG0/HZXV1d47IEDB8L6ggULwnpKdB5Aal5dZk4vpWfxx48fn/CxZ86cCeupZeGix7Xs182cH8CkRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFPM+RsUXRuemhn39fWF9SeeeCKsL1++PKxHtm3bFtZXr14d1lPLY6fWGoi2CI8eU0l66623StXvueeeurXUOgWp3qaCqf8VAhgX4QcyRfiBTBF+IFOEH8gU4QcyRfiBTCXn/GZ2saTnJC2S5JI2uPtTZjZf0u8lLZE0KOkud/9b61ptrdS8etasWXVrqZnxQw89FNY3b94c1lMz5+ja8xtuuCE8NtX7vHnzwnqqt9Q1+ZErrrgirA8ODob16Jr71PX4zPlHnZX0M3e/UtINkn5qZldKeljSK+6+TNIrxfsAJolk+N19r7u/Wbx9VNJ7ki6UtFbSpuLDNkm6s1VNAmi+b/TaxsyWSLpG0uuSFrn73qL0iUZ/LAAwSTQcfjM7V9IfJD3k7kfG1nz0B+Zxf2g2sz4z6zez/tSaawDap6Hwm1mXRoP/W3f/Y3Hzp2a2uKgvlrRvvGPdfYO719y91tvb24yeATRBMvw2esnas5Lec/dfjCltkbSueHudpBea3x6AVmnkkt5vS/qRpHfMbKC47VFJj0v6TzN7QNJfJd3VmhbbI3VZbnRpbGpstHLlyrBedivqaNRXdnns1H2fPXu21PFljl2/fn1YHxgYqFtji+4Gwu/u2yTV+1e4qbntAGiXqX8mA4BxEX4gU4QfyBThBzJF+IFMEX4gUyzd3aDUvLyM1Dy7zKw8Na8uK9Xb6dOn69ZSW5unzJw5M6xHl+VOhTl9WTzzA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QKeb8TZBa9jt1zXx3d3dYT83So/tP9dZq0XkGqd5SX3cOy2u3Eo8ekCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZYs7fAcpezx/N0lPX86dm5WXPEzhx4kTdWpnr8aX0ngFR72XWSJgqeOYHMkX4gUwRfiBThB/IFOEHMkX4gUwRfiBTyTm/mV0s6TlJiyS5pA3u/pSZPSbpx5KGig991N1fbFWjnazVa+OXkZrTp3ovOw+P1u0vez0/a++X08hJPmcl/czd3zSzHknbzezlovZLd3+yde0BaJVk+N19r6S9xdtHzew9SRe2ujEArfWNfuY3syWSrpH0enHTejN728w2mtm8Osf0mVm/mfUPDQ2N9yEAKtBw+M3sXEl/kPSQux+R9CtJl0m6WqOvDH4+3nHuvsHda+5e6+3tbULLAJqhofCbWZdGg/9bd/+jJLn7p+4+4u6fSfq1pOta1yaAZkuG30Z/5fqspPfc/Rdjbl885sN+IOnd5rcHoFUa+W3/tyX9SNI7ZjZQ3PaopLvN7GqNjv8GJf2kJR1OAqmR1PDwcKnPX2akNTIyEtanTy93VXeqt56enrq1spcyp0aF0dfOst+N/bZ/m6Tx/hWynOkDUwXf/oBMEX4gU4QfyBThBzJF+IFMEX4gUyzd3QSpmfH7778f1q+99tqwPmfOnLBeZunu1PLXM2bMCOvRJbuSdOjQobq11OP2yCOPhPU77rgjrCPGMz+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5myslswf6M7MxuS9NcxNy2QtL9tDXwzndpbp/Yl0dtENbO3v3P3htbLa2v4v3bnZv3uXqusgUCn9tapfUn0NlFV9cbLfiBThB/IVNXh31Dx/Uc6tbdO7Uuit4mqpLdKf+YHUJ2qn/kBVKSS8JvZrWb2vpl9YGYPV9FDPWY2aGbvmNmAmfVX3MtGM9tnZu+OuW2+mb1sZjuLv8fdJq2i3h4zsz3FYzdgZrdV1NvFZvY/ZvZnM9thZv9Y3F7pYxf0Vcnj1vaX/WY2TdL/SbpF0m5Jb0i6293/3NZG6jCzQUk1d698Jmxmfy/pmKTn3H1FcdsTkg66++PFN8557v5PHdLbY5KOVb1zc7GhzOKxO0tLulPSfarwsQv6uksVPG5VPPNfJ+kDd9/l7sOSfidpbQV9dDx33yrp4FduXitpU/H2Jo3+52m7Or11BHff6+5vFm8flfT5ztKVPnZBX5WoIvwXSvp4zPu71Vlbfrukl8xsu5n1Vd3MOBYV26ZL0ieSFlXZzDiSOze301d2lu6Yx24iO143G7/w+7rV7n6tpO9J+mnx8rYj+ejPbJ00rmlo5+Z2GWdn6S9U+dhNdMfrZqsi/HskXTzm/YuK2zqCu+8p/t4nabM6b/fhTz/fJLX4e1/F/Xyhk3ZuHm9naXXAY9dJO15XEf43JC0zs6VmNkPSDyVtqaCPrzGzOcUvYmRmcyR9V523+/AWSeuKt9dJeqHCXr6kU3ZurreztCp+7Dpux2t3b/sfSbdp9Df+H0r65yp6qNPXpZLeKv7sqLo3Sc9r9GXgGY3+buQBSedLekXSTkn/LWl+B/X275LekfS2RoO2uKLeVmv0Jf3bkgaKP7dV/dgFfVXyuHGGH5ApfuEHZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+Qqf8HzQCyn36XEX4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(label_dict)):\n",
    "    print(i,label_dict[i])\n",
    "print('\\n')\n",
    "\n",
    "for root,dirs,files in os.walk('./fashion_test/'):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        img = image.load_img(os.path.join(root,file), target_size=(28, 28))\n",
    "        #img_rgb = image.img_to_array(img)\n",
    "        #img_gray = np.mean(img_rgb, axis=2)\n",
    "        #img_gray = img_gray.reshape(1,32,32,1).astype('float32')\n",
    "        #print(img_gray.shape)\n",
    "        predictgray(Res34Model1, img)\n",
    "\n",
    "print('\\n')\n",
    "print(np.argmax(Res34Model1.predict(testimg28281[0].reshape(1,28,28,1).astype('float32'))))\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Customized ResNet ( Only 1 Add )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 28, 28, 32)   320         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 28, 28, 32)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 28, 28, 3)    867         activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 28, 28, 3)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 28, 28, 3)    0           input_8[0][0]                    \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2352)         0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          1204736     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 512)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512)          0           activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           5130        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 10)           0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,211,053\n",
      "Trainable params: 1,211,053\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "input_tensor=Input(shape=trainimg28281.shape[1:])\n",
    "cov1 = Conv2D(32, (3, 3), padding='same')(input_tensor)\n",
    "act1 = Activation('relu')(cov1)\n",
    "\n",
    "# max_pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n",
    "# drop1 = Dropout(0.25)(max_pool1)\n",
    "\n",
    "cov2 = Conv2D(3, (3, 3), padding='same')(act1)\n",
    "act2 = Activation('relu')(cov2)\n",
    "\n",
    "# max_pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n",
    "# drop2 = Dropout(0.25)(max_pool2)\n",
    "\n",
    "add = Add()([input_tensor, act2])\n",
    "\n",
    "flat = Flatten()(add)\n",
    "\n",
    "dense1 = Dense(512)(flat)\n",
    "act3 = Activation('relu')(dense1)\n",
    "drop3 = Dropout(0.5)(act3)\n",
    "\n",
    "dense2 = Dense(10)(drop3)\n",
    "outputs = Activation('softmax')(dense2)\n",
    "\n",
    "CustomResModel = Model(input=input_tensor, output=outputs)\n",
    "CustomResModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 0.6382 - acc: 0.7756 - val_loss: 0.4406 - val_acc: 0.8404\n",
      "Epoch 2/1000\n",
      " - 2s - loss: 0.4431 - acc: 0.8377 - val_loss: 0.3645 - val_acc: 0.8688\n",
      "Epoch 3/1000\n",
      " - 2s - loss: 0.3959 - acc: 0.8543 - val_loss: 0.3486 - val_acc: 0.8695\n",
      "Epoch 4/1000\n",
      " - 2s - loss: 0.3674 - acc: 0.8651 - val_loss: 0.3293 - val_acc: 0.8790\n",
      "Epoch 5/1000\n",
      " - 2s - loss: 0.3462 - acc: 0.8735 - val_loss: 0.3307 - val_acc: 0.8784\n",
      "Epoch 6/1000\n",
      " - 2s - loss: 0.3311 - acc: 0.8763 - val_loss: 0.3228 - val_acc: 0.8834\n",
      "Epoch 7/1000\n",
      " - 2s - loss: 0.3169 - acc: 0.8811 - val_loss: 0.3070 - val_acc: 0.8887\n",
      "Epoch 8/1000\n",
      " - 2s - loss: 0.3082 - acc: 0.8854 - val_loss: 0.3099 - val_acc: 0.8870\n",
      "Epoch 9/1000\n",
      " - 2s - loss: 0.2931 - acc: 0.8883 - val_loss: 0.2959 - val_acc: 0.8926\n",
      "Epoch 10/1000\n",
      " - 2s - loss: 0.2853 - acc: 0.8922 - val_loss: 0.2933 - val_acc: 0.8928\n",
      "Epoch 11/1000\n",
      " - 2s - loss: 0.2744 - acc: 0.8955 - val_loss: 0.2941 - val_acc: 0.8915\n",
      "Epoch 12/1000\n",
      " - 2s - loss: 0.2629 - acc: 0.9000 - val_loss: 0.2984 - val_acc: 0.8929\n",
      "Epoch 13/1000\n",
      " - 2s - loss: 0.2565 - acc: 0.9021 - val_loss: 0.2932 - val_acc: 0.8939\n",
      "Epoch 14/1000\n",
      " - 2s - loss: 0.2487 - acc: 0.9051 - val_loss: 0.2848 - val_acc: 0.8993\n",
      "Epoch 15/1000\n",
      " - 2s - loss: 0.2447 - acc: 0.9072 - val_loss: 0.2917 - val_acc: 0.8986\n",
      "Epoch 16/1000\n",
      " - 2s - loss: 0.2354 - acc: 0.9097 - val_loss: 0.2893 - val_acc: 0.8966\n",
      "Epoch 17/1000\n",
      " - 2s - loss: 0.2312 - acc: 0.9134 - val_loss: 0.2814 - val_acc: 0.8973\n",
      "Epoch 18/1000\n",
      " - 2s - loss: 0.2200 - acc: 0.9157 - val_loss: 0.2868 - val_acc: 0.9003\n",
      "Epoch 19/1000\n",
      " - 2s - loss: 0.2143 - acc: 0.9187 - val_loss: 0.2904 - val_acc: 0.9018\n",
      "Epoch 20/1000\n",
      " - 2s - loss: 0.2102 - acc: 0.9194 - val_loss: 0.2900 - val_acc: 0.8972\n",
      "Epoch 21/1000\n",
      " - 2s - loss: 0.2012 - acc: 0.9227 - val_loss: 0.2963 - val_acc: 0.9033\n",
      "Epoch 22/1000\n",
      " - 2s - loss: 0.1939 - acc: 0.9235 - val_loss: 0.2946 - val_acc: 0.9014\n",
      "Epoch 23/1000\n",
      " - 2s - loss: 0.1899 - acc: 0.9262 - val_loss: 0.2989 - val_acc: 0.9005\n",
      "Epoch 24/1000\n",
      " - 2s - loss: 0.1856 - acc: 0.9295 - val_loss: 0.3066 - val_acc: 0.8979\n",
      "Epoch 25/1000\n",
      " - 2s - loss: 0.1805 - acc: 0.9304 - val_loss: 0.3045 - val_acc: 0.9055\n",
      "Epoch 26/1000\n",
      " - 2s - loss: 0.1733 - acc: 0.9344 - val_loss: 0.3017 - val_acc: 0.9021\n",
      "Epoch 27/1000\n",
      " - 2s - loss: 0.1694 - acc: 0.9348 - val_loss: 0.2969 - val_acc: 0.9051\n",
      "Epoch 28/1000\n",
      " - 2s - loss: 0.1670 - acc: 0.9359 - val_loss: 0.3141 - val_acc: 0.9037\n",
      "Epoch 29/1000\n",
      " - 2s - loss: 0.1632 - acc: 0.9370 - val_loss: 0.2976 - val_acc: 0.9070\n",
      "Epoch 30/1000\n",
      " - 2s - loss: 0.1592 - acc: 0.9385 - val_loss: 0.3070 - val_acc: 0.9035\n",
      "Epoch 31/1000\n",
      " - 2s - loss: 0.1483 - acc: 0.9427 - val_loss: 0.3060 - val_acc: 0.9076\n",
      "Epoch 32/1000\n",
      " - 2s - loss: 0.1513 - acc: 0.9400 - val_loss: 0.3295 - val_acc: 0.9018\n",
      "Epoch 33/1000\n",
      " - 2s - loss: 0.1425 - acc: 0.9437 - val_loss: 0.3349 - val_acc: 0.9080\n",
      "Epoch 34/1000\n",
      " - 2s - loss: 0.1425 - acc: 0.9448 - val_loss: 0.3405 - val_acc: 0.9077\n",
      "Epoch 35/1000\n",
      " - 2s - loss: 0.1399 - acc: 0.9449 - val_loss: 0.3223 - val_acc: 0.9105\n",
      "Epoch 36/1000\n",
      " - 2s - loss: 0.1297 - acc: 0.9489 - val_loss: 0.3357 - val_acc: 0.9112\n",
      "Epoch 37/1000\n",
      " - 2s - loss: 0.1287 - acc: 0.9490 - val_loss: 0.3347 - val_acc: 0.9111\n",
      "Epoch 38/1000\n",
      " - 2s - loss: 0.1240 - acc: 0.9515 - val_loss: 0.3520 - val_acc: 0.9077\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.1236 - acc: 0.9518 - val_loss: 0.3519 - val_acc: 0.9097\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.1192 - acc: 0.9532 - val_loss: 0.3439 - val_acc: 0.9083\n",
      "Epoch 41/1000\n",
      " - 2s - loss: 0.1172 - acc: 0.9539 - val_loss: 0.3553 - val_acc: 0.9089\n",
      "Epoch 42/1000\n",
      " - 2s - loss: 0.1143 - acc: 0.9552 - val_loss: 0.3562 - val_acc: 0.9069\n",
      "Epoch 43/1000\n",
      " - 2s - loss: 0.1060 - acc: 0.9589 - val_loss: 0.3621 - val_acc: 0.9098\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.1057 - acc: 0.9602 - val_loss: 0.3577 - val_acc: 0.9079\n",
      "Epoch 45/1000\n",
      " - 2s - loss: 0.1081 - acc: 0.9579 - val_loss: 0.3742 - val_acc: 0.9058\n",
      "Epoch 46/1000\n",
      " - 2s - loss: 0.1038 - acc: 0.9589 - val_loss: 0.3989 - val_acc: 0.9059\n",
      "Epoch 47/1000\n",
      " - 2s - loss: 0.1023 - acc: 0.9608 - val_loss: 0.3915 - val_acc: 0.9075\n",
      "Epoch 48/1000\n",
      " - 2s - loss: 0.1002 - acc: 0.9614 - val_loss: 0.3853 - val_acc: 0.9085\n",
      "Epoch 49/1000\n",
      " - 2s - loss: 0.0966 - acc: 0.9631 - val_loss: 0.3790 - val_acc: 0.9075\n",
      "Epoch 50/1000\n",
      " - 2s - loss: 0.0961 - acc: 0.9625 - val_loss: 0.3875 - val_acc: 0.9089\n",
      "Epoch 51/1000\n",
      " - 2s - loss: 0.0924 - acc: 0.9641 - val_loss: 0.4085 - val_acc: 0.9069\n",
      "Epoch 52/1000\n",
      " - 2s - loss: 0.0901 - acc: 0.9650 - val_loss: 0.4499 - val_acc: 0.9046\n",
      "Epoch 53/1000\n",
      " - 2s - loss: 0.0903 - acc: 0.9658 - val_loss: 0.4135 - val_acc: 0.9102\n",
      "Epoch 54/1000\n",
      " - 2s - loss: 0.0886 - acc: 0.9657 - val_loss: 0.4164 - val_acc: 0.9056\n",
      "Epoch 55/1000\n",
      " - 2s - loss: 0.0845 - acc: 0.9668 - val_loss: 0.4424 - val_acc: 0.9064\n",
      "Epoch 56/1000\n",
      " - 2s - loss: 0.0849 - acc: 0.9670 - val_loss: 0.4075 - val_acc: 0.9056\n",
      "Epoch 57/1000\n",
      " - 2s - loss: 0.0820 - acc: 0.9685 - val_loss: 0.4405 - val_acc: 0.9082\n",
      "Epoch 58/1000\n",
      " - 2s - loss: 0.0794 - acc: 0.9694 - val_loss: 0.4428 - val_acc: 0.9062\n",
      "Epoch 59/1000\n",
      " - 2s - loss: 0.0791 - acc: 0.9691 - val_loss: 0.4368 - val_acc: 0.9039\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 0.0819 - acc: 0.9683 - val_loss: 0.4422 - val_acc: 0.9073\n",
      "Epoch 61/1000\n",
      " - 2s - loss: 0.0775 - acc: 0.9701 - val_loss: 0.4665 - val_acc: 0.9068\n",
      "Epoch 62/1000\n",
      " - 2s - loss: 0.0761 - acc: 0.9703 - val_loss: 0.4551 - val_acc: 0.9040\n",
      "Epoch 63/1000\n",
      " - 2s - loss: 0.0727 - acc: 0.9722 - val_loss: 0.4466 - val_acc: 0.9086\n",
      "Epoch 64/1000\n",
      " - 2s - loss: 0.0731 - acc: 0.9722 - val_loss: 0.4302 - val_acc: 0.9097\n",
      "Epoch 65/1000\n",
      " - 2s - loss: 0.0722 - acc: 0.9718 - val_loss: 0.4697 - val_acc: 0.9071\n",
      "Epoch 66/1000\n",
      " - 2s - loss: 0.0725 - acc: 0.9721 - val_loss: 0.5011 - val_acc: 0.9067\n",
      "Epoch 67/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9725 - val_loss: 0.4536 - val_acc: 0.9090\n",
      "Epoch 68/1000\n",
      " - 2s - loss: 0.0654 - acc: 0.9747 - val_loss: 0.4644 - val_acc: 0.9075\n",
      "Epoch 69/1000\n",
      " - 2s - loss: 0.0662 - acc: 0.9745 - val_loss: 0.4614 - val_acc: 0.9097\n",
      "Epoch 70/1000\n",
      " - 2s - loss: 0.0659 - acc: 0.9750 - val_loss: 0.4931 - val_acc: 0.9078\n",
      "Epoch 71/1000\n",
      " - 2s - loss: 0.0660 - acc: 0.9748 - val_loss: 0.4903 - val_acc: 0.9087\n",
      "Epoch 72/1000\n",
      " - 2s - loss: 0.0653 - acc: 0.9751 - val_loss: 0.4957 - val_acc: 0.9075\n",
      "Epoch 73/1000\n",
      " - 2s - loss: 0.0681 - acc: 0.9746 - val_loss: 0.4822 - val_acc: 0.9084\n",
      "Epoch 74/1000\n",
      " - 2s - loss: 0.0637 - acc: 0.9750 - val_loss: 0.4949 - val_acc: 0.9108\n",
      "Epoch 75/1000\n",
      " - 2s - loss: 0.0641 - acc: 0.9753 - val_loss: 0.5036 - val_acc: 0.9090\n",
      "Epoch 76/1000\n",
      " - 2s - loss: 0.0618 - acc: 0.9768 - val_loss: 0.5062 - val_acc: 0.9085\n",
      "Epoch 77/1000\n",
      " - 2s - loss: 0.0618 - acc: 0.9771 - val_loss: 0.5044 - val_acc: 0.9077\n",
      "Epoch 78/1000\n",
      " - 2s - loss: 0.0627 - acc: 0.9765 - val_loss: 0.5038 - val_acc: 0.9068\n",
      "Epoch 79/1000\n",
      " - 2s - loss: 0.0597 - acc: 0.9776 - val_loss: 0.5190 - val_acc: 0.9090\n",
      "Epoch 80/1000\n",
      " - 2s - loss: 0.0599 - acc: 0.9771 - val_loss: 0.5047 - val_acc: 0.9090\n",
      "Epoch 81/1000\n",
      " - 2s - loss: 0.0576 - acc: 0.9780 - val_loss: 0.5209 - val_acc: 0.9093\n",
      "Epoch 82/1000\n",
      " - 2s - loss: 0.0559 - acc: 0.9789 - val_loss: 0.5342 - val_acc: 0.9057\n",
      "Epoch 83/1000\n",
      " - 2s - loss: 0.0554 - acc: 0.9787 - val_loss: 0.5196 - val_acc: 0.9078\n",
      "Epoch 84/1000\n",
      " - 2s - loss: 0.0540 - acc: 0.9792 - val_loss: 0.5572 - val_acc: 0.9083\n",
      "Epoch 85/1000\n",
      " - 2s - loss: 0.0553 - acc: 0.9802 - val_loss: 0.5250 - val_acc: 0.9073\n",
      "Epoch 86/1000\n",
      " - 2s - loss: 0.0575 - acc: 0.9779 - val_loss: 0.5416 - val_acc: 0.9076\n",
      "Epoch 00086: early stopping\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_acc',mode='max',verbose=1,patience=50)\n",
    "CustomResModel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = CustomResModel.fit(x=trainimg28281,y=train_label,validation_split=0.2, epochs=1000, batch_size=200,verbose=2,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/step\n",
      "Test accuracy: 0.9049\n",
      "Test loss: 0.5856658678524196\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = CustomResModel.evaluate(testimg28281, test_label)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 T-shirt/top\n",
      "1 Trouser\n",
      "2 Pullover\n",
      "3 Dress\n",
      "4 Coat\n",
      "5 Sandal\n",
      "6 Shirt\n",
      "7 Sneaker\n",
      "8 Bag\n",
      "9 Ankle boot\n",
      "\n",
      "\n",
      "bag.jpeg\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "sneaker.jpeg\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "coat.jpeg\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "dress.png\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "dress2.png\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n",
      "\n",
      "\n",
      "9\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(label_dict)):\n",
    "    print(i,label_dict[i])\n",
    "print('\\n')\n",
    "\n",
    "for root,dirs,files in os.walk('./fashion_test/'):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        img = image.load_img(os.path.join(root,file), target_size=(28, 28))\n",
    "        #img_rgb = image.img_to_array(img)\n",
    "        #img_gray = np.mean(img_rgb, axis=2)\n",
    "        #img_gray = img_gray.reshape(1,32,32,1).astype('float32')\n",
    "        #print(img_gray.shape)\n",
    "        predictgray(CustomResModel, img)\n",
    "\n",
    "print('\\n')\n",
    "print(np.argmax(CustomResModel.predict(testimg28281[0].reshape(1,28,28,1).astype('float32'))))\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3 shape minimum needs to be (75,75,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 75, 75)\n",
      "(55000, 75, 75, 1)\n",
      "(10000, 75, 75)\n",
      "(10000, 75, 75, 1)\n"
     ]
    }
   ],
   "source": [
    "trainimg7575 = []\n",
    "for i in range(train_img.shape[0]):\n",
    "    newarray = np.pad(train_img[i],(0,47),mode='constant',constant_values=0)\n",
    "    trainimg7575.append(newarray)\n",
    "    \n",
    "trainimg7575 = np.asarray(trainimg7575,dtype=np.float32)\n",
    "trainimg75751 = trainimg7575.reshape(trainimg7575.shape[0],75,75,1)\n",
    "print(trainimg7575.shape)\n",
    "print(trainimg75751.shape)\n",
    "\n",
    "testimg7575 = []\n",
    "for i in range(test_img.shape[0]):\n",
    "    newarray = np.pad(test_img[i],(0,47),mode='constant',constant_values=0)\n",
    "    testimg7575.append(newarray)\n",
    "    \n",
    "testimg7575 = np.asarray(testimg7575,dtype=np.float32)\n",
    "testimg75751 = testimg7575.reshape(testimg7575.shape[0],75,75,1)\n",
    "print(testimg7575.shape)\n",
    "print(testimg75751.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 75, 75, 3)\n",
      "(10000, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "#afterpadtrainimg75new = afterpadtrainimg75[0][:, :, None] * np.ones(3, dtype='float32')[None, None, :]\n",
    "trainimg75753 = np.stack((trainimg7575,)*3, axis=-1)\n",
    "testimg75753 = np.stack((testimg7575,)*3, axis=-1)\n",
    "print(trainimg75753.shape)\n",
    "print(testimg75753.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_image_label_prediction(images, labels, prediction,idx,num=10):\n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(12,12)\n",
    "    if num>25: num=25\n",
    "    for i in range(0, num):\n",
    "        ax = plt.subplot(5,5, 1+i)\n",
    "        ax.imshow(images[idx],cmap='binary')\n",
    "        \n",
    "        title=label_dict[labels[i]]\n",
    "        if(len(prediction)>0):\n",
    "            title+='->'+label_dict[prediction[i]]\n",
    "        ax.set_title(title,fontsize=10)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        idx+=1\n",
    "    plt.show()\n",
    "    \n",
    "plot_image_label_prediction(trainimg75753,train_label,[],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "myowninputsetting (InputLayer)  (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 37, 37, 32)   864         myowninputsetting[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 37, 37, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 37, 37, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   9216        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 64)   18432       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 64)   192         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 35, 35, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 64)   0           activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 80)   240         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 17, 17, 80)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 15, 15, 192)  138240      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 15, 15, 192)  576         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 15, 15, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 64)     12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 64)     192         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 48)     9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 96)     55296       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 48)     144         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 96)     288         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 48)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 7, 7, 96)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 7, 7, 192)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 64)     12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 64)     76800       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 96)     82944       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 64)     192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 64)     192         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 96)     288         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 32)     96          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 64)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 96)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 32)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_161[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 64)     192         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 7, 7, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 96)     55296       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 48)     144         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 96)     288         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 7, 7, 48)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 7, 7, 96)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 64)     76800       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 96)     82944       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 64)     192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 64)     192         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 96)     288         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 64)     192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 64)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 7, 7, 64)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 7, 7, 96)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 7, 7, 64)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_168[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 64)     192         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 7, 7, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 96)     55296       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 48)     144         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 96)     288         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 7, 7, 48)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 7, 7, 96)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 64)     76800       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 96)     82944       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 64)     192         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 64)     192         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 96)     288         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 64)     192         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 7, 7, 64)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 7, 7, 64)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 7, 7, 96)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 7, 7, 64)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_175[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "                                                                 activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 64)     192         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 7, 7, 64)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 96)     55296       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 96)     288         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 7, 7, 96)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 96)     82944       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 3, 3, 384)    1152        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 3, 3, 96)     288         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 96)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_182[0][0]             \n",
      "                                                                 activation_185[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 128)    384         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 3, 3, 128)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 128)    114688      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 3, 3, 128)    384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 3, 3, 128)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 128)    114688      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 3, 3, 128)    384         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 3, 3, 128)    384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 128)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 3, 3, 128)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 128)    114688      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 128)    114688      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 3, 3, 128)    384         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 3, 3, 128)    384         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 128)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 3, 3, 128)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    172032      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 192)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_186[0][0]             \n",
      "                                                                 activation_189[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 160)    480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 3, 3, 160)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 160)    179200      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 160)    480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 3, 3, 160)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 160)    179200      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 160)    480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 160)    480         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 3, 3, 160)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 3, 3, 160)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 160)    179200      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 160)    179200      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 160)    480         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 160)    480         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 3, 3, 160)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 3, 3, 160)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 192)    215040      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 192)    215040      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 192)    576         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 192)    576         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 192)    576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 3, 3, 192)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 3, 3, 192)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 3, 3, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 3, 3, 192)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 160)    480         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 3, 3, 160)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 3, 3, 160)    179200      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 160)    480         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 3, 3, 160)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 3, 3, 160)    179200      activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 160)    480         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 160)    480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 3, 3, 160)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 3, 3, 160)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 160)    179200      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 3, 3, 160)    179200      activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 160)    480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 3, 3, 160)    480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 3, 3, 160)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 3, 3, 160)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 3, 3, 192)    215040      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 3, 3, 192)    215040      activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 192)    576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 192)    576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 3, 3, 192)    576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 3, 3, 192)    576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 3, 3, 192)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 3, 3, 192)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 3, 3, 192)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 3, 3, 192)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_206[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 3, 3, 192)    576         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 3, 3, 192)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 3, 3, 192)    258048      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 3, 3, 192)    576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 3, 3, 192)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 3, 3, 192)    258048      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 3, 3, 192)    576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 3, 3, 192)    576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 3, 3, 192)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 3, 3, 192)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 3, 3, 192)    258048      activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 3, 3, 192)    258048      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 3, 3, 192)    576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 3, 3, 192)    576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 3, 3, 192)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 3, 3, 192)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 3, 3, 192)    258048      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 3, 3, 192)    258048      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 3, 3, 192)    576         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 3, 3, 192)    576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 3, 3, 192)    576         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 3, 3, 192)    576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 3, 3, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 3, 3, 192)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 3, 3, 192)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 3, 3, 192)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_216[0][0]             \n",
      "                                                                 activation_219[0][0]             \n",
      "                                                                 activation_224[0][0]             \n",
      "                                                                 activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 3, 3, 192)    576         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 3, 3, 192)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 3, 3, 192)    258048      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 3, 3, 192)    576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 3, 3, 192)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 3, 3, 192)    258048      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 3, 3, 192)    576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 3, 3, 192)    576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 3, 3, 192)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 3, 3, 192)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 1, 1, 320)    552960      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 1, 1, 192)    331776      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 1, 1, 320)    960         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 1, 1, 192)    576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 1, 1, 320)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 1, 1, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_227[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 1, 1, 448)    1344        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 1, 1, 448)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 1, 1, 384)    1548288     activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 1, 1, 384)    1152        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 1, 1, 384)    1152        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 1, 1, 384)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 1, 1, 384)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 1, 1, 384)    442368      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 1, 1, 384)    442368      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 1, 1, 384)    442368      activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 1, 1, 384)    442368      activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 1, 1, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 1, 1, 384)    1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 1, 1, 384)    1152        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 1, 1, 384)    1152        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 1, 1, 320)    960         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 1, 1, 384)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 1, 1, 384)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 1, 1, 384)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 1, 1, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 1, 1, 192)    576         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 1, 1, 320)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_234[0][0]             \n",
      "                                                                 activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 1, 1, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_232[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 1, 1, 448)    1344        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 1, 1, 448)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 1, 1, 384)    1548288     activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 1, 1, 384)    1152        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 1, 1, 384)    1152        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 1, 1, 384)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 1, 1, 384)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 1, 1, 384)    442368      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 1, 1, 384)    442368      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 1, 1, 384)    442368      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 1, 1, 384)    442368      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 1, 1, 384)    1152        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 1, 1, 384)    1152        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 1, 1, 384)    1152        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 1, 1, 384)    1152        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 1, 1, 320)    960         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 1, 1, 384)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 1, 1, 384)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 1, 1, 384)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 1, 1, 384)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 1, 1, 192)    576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 1, 1, 320)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_243[0][0]             \n",
      "                                                                 activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_247[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 1, 1, 192)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_241[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_249[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "myowninputsetting (InputLayer)  (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 37, 37, 32)   864         myowninputsetting[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 37, 37, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 37, 37, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   9216        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 64)   18432       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 64)   192         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 35, 35, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 64)   0           activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 80)   240         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 17, 17, 80)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 15, 15, 192)  138240      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 15, 15, 192)  576         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 15, 15, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 64)     12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 64)     192         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 48)     9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 96)     55296       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 48)     144         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 96)     288         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 48)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 7, 7, 96)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 7, 7, 192)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 64)     12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 64)     76800       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 96)     82944       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 64)     192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 64)     192         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 96)     288         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 32)     96          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 64)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 96)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 32)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_161[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 64)     192         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 7, 7, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 96)     55296       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 48)     144         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 96)     288         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 7, 7, 48)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 7, 7, 96)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 64)     76800       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 96)     82944       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 64)     192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 64)     192         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 96)     288         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 64)     192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 64)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 7, 7, 64)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 7, 7, 96)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 7, 7, 64)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_168[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 64)     192         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 7, 7, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 96)     55296       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 48)     144         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 96)     288         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 7, 7, 48)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 7, 7, 96)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 64)     76800       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 96)     82944       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 64)     192         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 64)     192         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 96)     288         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 64)     192         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 7, 7, 64)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 7, 7, 64)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 7, 7, 96)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 7, 7, 64)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_175[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "                                                                 activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 64)     192         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 7, 7, 64)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 96)     55296       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 96)     288         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 7, 7, 96)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 96)     82944       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 3, 3, 384)    1152        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 3, 3, 96)     288         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 96)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_182[0][0]             \n",
      "                                                                 activation_185[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 128)    384         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 3, 3, 128)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 128)    114688      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 3, 3, 128)    384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 3, 3, 128)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 128)    114688      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 3, 3, 128)    384         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 3, 3, 128)    384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 128)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 3, 3, 128)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 128)    114688      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 128)    114688      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 3, 3, 128)    384         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 3, 3, 128)    384         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 128)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 3, 3, 128)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    172032      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 192)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_186[0][0]             \n",
      "                                                                 activation_189[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 160)    480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 3, 3, 160)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 160)    179200      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 160)    480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 3, 3, 160)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 160)    179200      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 160)    480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 160)    480         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 3, 3, 160)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 3, 3, 160)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 160)    179200      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 160)    179200      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 160)    480         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 160)    480         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 3, 3, 160)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 3, 3, 160)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 192)    215040      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 192)    215040      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 192)    576         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 192)    576         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 192)    576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 3, 3, 192)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 3, 3, 192)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 3, 3, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 3, 3, 192)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 160)    480         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 3, 3, 160)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 3, 3, 160)    179200      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 160)    480         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 3, 3, 160)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 3, 3, 160)    179200      activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 160)    480         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 160)    480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 3, 3, 160)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 3, 3, 160)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 160)    179200      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 3, 3, 160)    179200      activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 160)    480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 3, 3, 160)    480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 3, 3, 160)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 3, 3, 160)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 3, 3, 192)    215040      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 3, 3, 192)    215040      activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 192)    576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 192)    576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 3, 3, 192)    576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 3, 3, 192)    576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 3, 3, 192)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 3, 3, 192)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 3, 3, 192)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 3, 3, 192)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_206[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 3, 3, 192)    576         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 3, 3, 192)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 3, 3, 192)    258048      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 3, 3, 192)    576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 3, 3, 192)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 3, 3, 192)    258048      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 3, 3, 192)    576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 3, 3, 192)    576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 3, 3, 192)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 3, 3, 192)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 3, 3, 192)    258048      activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 3, 3, 192)    258048      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 3, 3, 192)    576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 3, 3, 192)    576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 3, 3, 192)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 3, 3, 192)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 3, 3, 192)    258048      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 3, 3, 192)    258048      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 3, 3, 192)    576         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 3, 3, 192)    576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 3, 3, 192)    576         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 3, 3, 192)    576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 3, 3, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 3, 3, 192)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 3, 3, 192)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 3, 3, 192)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_216[0][0]             \n",
      "                                                                 activation_219[0][0]             \n",
      "                                                                 activation_224[0][0]             \n",
      "                                                                 activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 3, 3, 192)    576         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 3, 3, 192)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 3, 3, 192)    258048      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 3, 3, 192)    576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 3, 3, 192)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 3, 3, 192)    258048      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 3, 3, 192)    576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 3, 3, 192)    576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 3, 3, 192)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 3, 3, 192)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 1, 1, 320)    552960      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 1, 1, 192)    331776      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 1, 1, 320)    960         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 1, 1, 192)    576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 1, 1, 320)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 1, 1, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_227[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 1, 1, 448)    1344        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 1, 1, 448)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 1, 1, 384)    1548288     activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 1, 1, 384)    1152        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 1, 1, 384)    1152        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 1, 1, 384)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 1, 1, 384)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 1, 1, 384)    442368      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 1, 1, 384)    442368      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 1, 1, 384)    442368      activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 1, 1, 384)    442368      activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 1, 1, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 1, 1, 384)    1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 1, 1, 384)    1152        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 1, 1, 384)    1152        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 1, 1, 320)    960         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 1, 1, 384)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 1, 1, 384)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 1, 1, 384)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 1, 1, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 1, 1, 192)    576         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 1, 1, 320)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_234[0][0]             \n",
      "                                                                 activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 1, 1, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_232[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 1, 1, 448)    1344        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 1, 1, 448)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 1, 1, 384)    1548288     activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 1, 1, 384)    1152        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 1, 1, 384)    1152        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 1, 1, 384)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 1, 1, 384)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 1, 1, 384)    442368      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 1, 1, 384)    442368      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 1, 1, 384)    442368      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 1, 1, 384)    442368      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 1, 1, 384)    1152        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 1, 1, 384)    1152        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 1, 1, 384)    1152        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 1, 1, 384)    1152        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 1, 1, 320)    960         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 1, 1, 384)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 1, 1, 384)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 1, 1, 384)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 1, 1, 384)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 1, 1, 192)    576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 1, 1, 320)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_243[0][0]             \n",
      "                                                                 activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_247[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 1, 1, 192)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_241[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "myFlatten (Flatten)             (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "myfirstDense (Dense)            (None, 1024)         2098176     myFlatten[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1024)         0           myfirstDense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mysecondDense (Dense)           (None, 512)          524800      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           mysecondDense[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "myprediction (Dense)            (None, 10)           5130        dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,430,890\n",
      "Trainable params: 2,628,106\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras_applications import inception_v3\n",
    "from tensorflow.keras_applications.inception_v3 import preprocess_input,InceptionV3\n",
    "input_tensor = Input(shape=(75,75,3),name='myowninputsetting')\n",
    "base_model = inception_v3.InceptionV3(weights=None,input_tensor=input_tensor,include_top=False,backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "base_model.summary()\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = base_model.output\n",
    "x = Flatten(name='myFlatten')(x)\n",
    "x = Dense(1024,activation='relu',name='myfirstDense')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,activation='relu',name='mysecondDense')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10,activation='softmax',name='myprediction')(x)\n",
    "incepv3model1 = Model(inputs=base_model.input,outputs=x)\n",
    "incepv3model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/1000\n",
      " - 18s - loss: 2.0772 - acc: 0.2470 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 2/1000\n",
      " - 11s - loss: 1.8024 - acc: 0.3497 - val_loss: 2.3029 - val_acc: 0.1010\n",
      "Epoch 3/1000\n",
      " - 11s - loss: 1.7369 - acc: 0.3794 - val_loss: 2.3033 - val_acc: 0.1008\n",
      "Epoch 4/1000\n",
      " - 11s - loss: 1.6933 - acc: 0.3973 - val_loss: 2.3039 - val_acc: 0.1008\n",
      "Epoch 5/1000\n",
      " - 11s - loss: 1.6617 - acc: 0.4070 - val_loss: 2.3045 - val_acc: 0.0970\n",
      "Epoch 6/1000\n",
      " - 11s - loss: 1.6414 - acc: 0.4129 - val_loss: 2.3064 - val_acc: 0.0970\n",
      "Epoch 7/1000\n",
      " - 11s - loss: 1.6212 - acc: 0.4211 - val_loss: 2.3085 - val_acc: 0.0970\n",
      "Epoch 8/1000\n",
      " - 11s - loss: 1.6080 - acc: 0.4280 - val_loss: 2.3106 - val_acc: 0.0970\n",
      "Epoch 9/1000\n",
      " - 11s - loss: 1.6035 - acc: 0.4280 - val_loss: 2.3153 - val_acc: 0.0970\n",
      "Epoch 10/1000\n",
      " - 11s - loss: 1.5894 - acc: 0.4317 - val_loss: 2.3197 - val_acc: 0.0970\n",
      "Epoch 11/1000\n",
      " - 11s - loss: 1.5819 - acc: 0.4373 - val_loss: 2.3242 - val_acc: 0.0970\n",
      "Epoch 12/1000\n",
      " - 11s - loss: 1.5782 - acc: 0.4381 - val_loss: 2.3293 - val_acc: 0.0970\n",
      "Epoch 13/1000\n",
      " - 11s - loss: 1.5590 - acc: 0.4437 - val_loss: 2.3326 - val_acc: 0.0970\n",
      "Epoch 14/1000\n",
      " - 11s - loss: 1.5565 - acc: 0.4463 - val_loss: 2.3422 - val_acc: 0.0970\n",
      "Epoch 15/1000\n",
      " - 11s - loss: 1.5459 - acc: 0.4494 - val_loss: 2.3435 - val_acc: 0.0970\n",
      "Epoch 16/1000\n",
      " - 11s - loss: 1.5468 - acc: 0.4490 - val_loss: 2.3571 - val_acc: 0.0970\n",
      "Epoch 17/1000\n",
      " - 11s - loss: 1.5391 - acc: 0.4459 - val_loss: 2.3542 - val_acc: 0.0970\n",
      "Epoch 18/1000\n",
      " - 11s - loss: 1.5361 - acc: 0.4524 - val_loss: 2.3583 - val_acc: 0.0966\n",
      "Epoch 19/1000\n",
      " - 11s - loss: 1.5355 - acc: 0.4523 - val_loss: 2.3659 - val_acc: 0.0970\n",
      "Epoch 20/1000\n",
      " - 11s - loss: 1.5303 - acc: 0.4565 - val_loss: 2.3709 - val_acc: 0.0970\n",
      "Epoch 21/1000\n",
      " - 11s - loss: 1.5287 - acc: 0.4540 - val_loss: 2.3675 - val_acc: 0.0970\n",
      "Epoch 22/1000\n",
      " - 11s - loss: 1.5196 - acc: 0.4578 - val_loss: 2.3740 - val_acc: 0.0970\n",
      "Epoch 23/1000\n",
      " - 11s - loss: 1.5207 - acc: 0.4602 - val_loss: 2.3767 - val_acc: 0.0970\n",
      "Epoch 24/1000\n",
      " - 11s - loss: 1.5144 - acc: 0.4634 - val_loss: 2.3761 - val_acc: 0.0970\n",
      "Epoch 25/1000\n",
      " - 11s - loss: 1.5134 - acc: 0.4599 - val_loss: 2.3796 - val_acc: 0.0970\n",
      "Epoch 26/1000\n",
      " - 11s - loss: 1.5129 - acc: 0.4620 - val_loss: 2.3829 - val_acc: 0.0970\n",
      "Epoch 27/1000\n",
      " - 11s - loss: 1.5050 - acc: 0.4625 - val_loss: 2.3832 - val_acc: 0.0970\n",
      "Epoch 28/1000\n",
      " - 11s - loss: 1.5057 - acc: 0.4650 - val_loss: 2.3834 - val_acc: 0.0970\n",
      "Epoch 29/1000\n",
      " - 11s - loss: 1.5052 - acc: 0.4631 - val_loss: 2.3877 - val_acc: 0.0970\n",
      "Epoch 30/1000\n",
      " - 11s - loss: 1.5033 - acc: 0.4633 - val_loss: 2.3842 - val_acc: 0.0970\n",
      "Epoch 31/1000\n",
      " - 11s - loss: 1.5000 - acc: 0.4634 - val_loss: 2.3873 - val_acc: 0.0970\n",
      "Epoch 32/1000\n",
      " - 11s - loss: 1.4942 - acc: 0.4656 - val_loss: 2.3895 - val_acc: 0.0970\n",
      "Epoch 33/1000\n",
      " - 11s - loss: 1.4919 - acc: 0.4705 - val_loss: 2.3890 - val_acc: 0.0970\n",
      "Epoch 34/1000\n",
      " - 11s - loss: 1.4908 - acc: 0.4687 - val_loss: 2.3861 - val_acc: 0.0970\n",
      "Epoch 35/1000\n",
      " - 11s - loss: 1.4800 - acc: 0.4720 - val_loss: 2.3977 - val_acc: 0.0970\n",
      "Epoch 36/1000\n",
      " - 11s - loss: 1.4874 - acc: 0.4727 - val_loss: 2.3944 - val_acc: 0.0970\n",
      "Epoch 37/1000\n",
      " - 11s - loss: 1.4862 - acc: 0.4719 - val_loss: 2.3895 - val_acc: 0.0970\n",
      "Epoch 38/1000\n",
      " - 11s - loss: 1.4849 - acc: 0.4728 - val_loss: 2.3915 - val_acc: 0.0970\n",
      "Epoch 39/1000\n",
      " - 11s - loss: 1.4776 - acc: 0.4735 - val_loss: 2.3914 - val_acc: 0.0970\n",
      "Epoch 40/1000\n",
      " - 11s - loss: 1.4846 - acc: 0.4707 - val_loss: 2.4005 - val_acc: 0.0970\n",
      "Epoch 41/1000\n",
      " - 11s - loss: 1.4758 - acc: 0.4716 - val_loss: 2.3900 - val_acc: 0.0970\n",
      "Epoch 42/1000\n",
      " - 11s - loss: 1.4776 - acc: 0.4720 - val_loss: 2.3969 - val_acc: 0.0970\n",
      "Epoch 43/1000\n",
      " - 11s - loss: 1.4750 - acc: 0.4760 - val_loss: 2.3833 - val_acc: 0.0970\n",
      "Epoch 44/1000\n",
      " - 11s - loss: 1.4757 - acc: 0.4751 - val_loss: 2.3893 - val_acc: 0.0827\n",
      "Epoch 45/1000\n",
      " - 11s - loss: 1.4721 - acc: 0.4755 - val_loss: 2.3887 - val_acc: 0.0970\n",
      "Epoch 46/1000\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=50)\n",
    "incepv3model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = incepv3model1.fit(x=trainimg75753,y=train_label,validation_split=0.2, epochs=1000, batch_size=200,verbose=2,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Customized Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(inputs,filters,kernel_size,strides=(1,1),padding='same'):\n",
    "    x = Conv2D(filters,kernel_size=kernel_size,strides=strides,padding=padding)(inputs)\n",
    "    x = BatchNormalization(axis=3,scale=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def dimension_reduction_inception(inputs):\n",
    "    from keras.layers import AveragePooling2D\n",
    "    x = conv2d_bn(inputs, 32, kernel_size = (3, 3), strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, kernel_size = (3, 3), padding='valid')\n",
    "    x = conv2d_bn(x, 64, kernel_size = (3, 3))\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, kernel_size=(1, 1), padding='valid')\n",
    "    x = conv2d_bn(x, 192, kernel_size=(3, 3), padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    tower_one = MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    tower_one = conv2d_bn(tower_one, 64, kernel_size = (1,1))\n",
    "\n",
    "    tower_two = conv2d_bn(x, 64, kernel_size = (1,1))\n",
    "    tower_two = conv2d_bn(tower_two, 64, kernel_size = (3,3))\n",
    "\n",
    "    tower_three = conv2d_bn(x, 64, kernel_size = (1,1))\n",
    "    tower_three = conv2d_bn(tower_three, 64, kernel_size = (5,5))\n",
    "    x = concatenate([tower_one, tower_two, tower_three], axis=3)\n",
    "    \n",
    "    # mixed 0: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64,kernel_size=(1, 1),strides=(1,1))\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, kernel_size=(1, 1),strides=(1,1))\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, kernel_size=(5, 5),strides=(1,1))\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, kernel_size=(1, 1))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3, 3))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3,3))\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32,kernel_size=(1, 1))\n",
    "    x = concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed0')\n",
    "    \n",
    "    # mixed 1: 35 x 35 x 288\n",
    "    branch1x1 = conv2d_bn(x, 64, kernel_size=(1, 1))\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48,kernel_size=(1, 1))\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, kernel_size=(5,5))\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, kernel_size=(1, 1))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3,3))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3,3))\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3),strides=(1, 1),padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, kernel_size=(1, 1))\n",
    "    x = concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],axis=3,name='mixed1')\n",
    "\n",
    "    #mixed 2: 35 x 35 x 288\n",
    "    branch1x1 = conv2d_bn(x, 64, kernel_size=(1, 1))\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, kernel_size=(1, 1))\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, kernel_size=(5,5))\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, kernel_size=(1, 1))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3, 3))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3, 3))\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, kernel_size=(1, 1))\n",
    "    x = concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed2')\n",
    "\n",
    "    #mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, kernel_size=(3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, kernel_size=(1, 1))\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, kernel_size=(3, 3))\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "    branch3x3dbl, 96, kernel_size=(3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = concatenate([branch3x3, branch3x3dbl, branch_pool],axis=3,name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, kernel_size=(1, 1))\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, kernel_size=(1, 1))\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, kernel_size=(1, 7))\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, kernel_size=(7, 1))\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, kernel_size=(1, 1))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, kernel_size=(7, 1))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, kernel_size=(1, 7))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, kernel_size=(7, 1))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, kernel_size=(1, 7))\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, kernel_size=(1, 1))\n",
    "    x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],axis=3,name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, kernel_size=(1, 1))\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, kernel_size=(1, 1))\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, kernel_size=(1, 7))\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, kernel_size=(7, 1))\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, kernel_size=(1, 1))\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, kernel_size=(7, 1))\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, kernel_size=(1, 7))\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, kernel_size=(7, 1))\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, kernel_size=(1, 7))\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, kernel_size=(1, 1))\n",
    "        x = concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=3,\n",
    "            name='mixed' + str(5 + i))\n",
    "\n",
    "    #mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, kernel_size=(1, 1))\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, kernel_size=(1, 1))\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, kernel_size=(1, 7))\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, kernel_size=(7, 1))\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 192,kernel_size=(1, 1))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, kernel_size=(7, 1))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, kernel_size=(1, 7))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, kernel_size=(7, 1))\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, kernel_size=(1, 7))\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3),strides=(1, 1),padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, kernel_size=(1, 1))\n",
    "    x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],axis=3,name='mixed7')\n",
    "\n",
    "    #mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, kernel_size=(1, 1))\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, kernel_size=(3, 3),strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, kernel_size=(1, 1))\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, kernel_size=(1, 7))\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, kernel_size=(7, 1))\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, kernel_size=(3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = concatenate([branch3x3, branch7x7x3, branch_pool],axis=3,name='mixed8')\n",
    "\n",
    "#mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, kernel_size=(1, 1))\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, kernel_size=(1, 1))\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, kernel_size=(1, 3))\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, kernel_size=(3, 1))\n",
    "        branch3x3 = concatenate([branch3x3_1, branch3x3_2],axis=3,name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, kernel_size=(1, 1))\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, kernel_size=(3, 3))\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, kernel_size=(1, 3))\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, kernel_size=(3, 1))\n",
    "        branch3x3dbl = concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=3)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, kernel_size=(1, 1))\n",
    "        x = concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool],axis=3,name='mixed' + str(9 + i))\n",
    "        return x\n",
    "\n",
    "def dimension_reduction_model(x_train):\n",
    "\n",
    "    inputs = Input(x_train)\n",
    "\n",
    "    x = dimension_reduction_inception(inputs)\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(64, activation='relu')(x)\n",
    "    \n",
    "    #Using AveragePooling replace flatten\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "    #predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input=inputs, output=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 13, 13, 32)   320         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 13, 13, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 13, 13, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 11, 11, 32)   9248        activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 11, 11, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 11, 11, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 11, 11, 64)   18496       activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 11, 11, 64)   192         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 11, 11, 64)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 5, 5, 64)     0           activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 5, 5, 80)     5200        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 5, 5, 80)     240         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 5, 5, 80)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 3, 3, 192)    138432      activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 3, 3, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 3, 3, 192)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 1, 1, 192)    0           activation_461[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 1, 1, 64)     12352       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1, 1, 64)     192         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 1, 1, 64)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 1, 1, 48)     9264        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 1, 1, 96)     55392       activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1, 1, 48)     144         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1, 1, 96)     288         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 1, 1, 48)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 1, 1, 96)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 192)    0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 1, 1, 64)     12352       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 1, 1, 64)     76864       activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 1, 1, 96)     83040       activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 1, 1, 32)     6176        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1, 1, 64)     192         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1, 1, 64)     192         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1, 1, 96)     288         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1, 1, 32)     96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 1, 1, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 1, 1, 64)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 1, 1, 96)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 1, 1, 32)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 1, 1, 256)    0           activation_462[0][0]             \n",
      "                                                                 activation_464[0][0]             \n",
      "                                                                 activation_467[0][0]             \n",
      "                                                                 activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 1, 1, 64)     16448       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1, 1, 64)     192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_472 (Activation)     (None, 1, 1, 64)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 1, 1, 48)     12336       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 1, 1, 96)     55392       activation_472[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1, 1, 48)     144         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1, 1, 96)     288         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_470 (Activation)     (None, 1, 1, 48)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_473 (Activation)     (None, 1, 1, 96)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 1, 1, 64)     16448       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 1, 1, 64)     76864       activation_470[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 1, 1, 96)     83040       activation_473[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 1, 1, 64)     16448       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1, 1, 64)     192         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1, 1, 64)     192         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1, 1, 96)     288         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1, 1, 64)     192         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, 1, 1, 64)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_471 (Activation)     (None, 1, 1, 64)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_474 (Activation)     (None, 1, 1, 96)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_475 (Activation)     (None, 1, 1, 64)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 1, 1, 288)    0           activation_469[0][0]             \n",
      "                                                                 activation_471[0][0]             \n",
      "                                                                 activation_474[0][0]             \n",
      "                                                                 activation_475[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 1, 1, 64)     18496       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1, 1, 64)     192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_479 (Activation)     (None, 1, 1, 64)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 1, 1, 48)     13872       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 1, 1, 96)     55392       activation_479[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1, 1, 48)     144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1, 1, 96)     288         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_477 (Activation)     (None, 1, 1, 48)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_480 (Activation)     (None, 1, 1, 96)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 288)    0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 1, 1, 64)     18496       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 1, 1, 64)     76864       activation_477[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 1, 1, 96)     83040       activation_480[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 1, 1, 64)     18496       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1, 1, 64)     192         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1, 1, 64)     192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1, 1, 96)     288         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1, 1, 64)     192         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_476 (Activation)     (None, 1, 1, 64)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_478 (Activation)     (None, 1, 1, 64)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_481 (Activation)     (None, 1, 1, 96)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_482 (Activation)     (None, 1, 1, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 1, 1, 288)    0           activation_476[0][0]             \n",
      "                                                                 activation_478[0][0]             \n",
      "                                                                 activation_481[0][0]             \n",
      "                                                                 activation_482[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 128)    36992       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1, 1, 128)    384         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, 1, 1, 128)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 128)    114816      activation_487[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 128)    384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 1, 1, 128)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 128)    36992       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 128)    114816      activation_488[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1, 1, 128)    384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 128)    384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_484 (Activation)     (None, 1, 1, 128)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 1, 1, 128)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 128)    114816      activation_484[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 128)    114816      activation_489[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1, 1, 128)    384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 128)    384         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, 1, 1, 128)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, 1, 1, 128)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 192)    55488       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 192)    172224      activation_485[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 1, 1, 192)    172224      activation_490[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 1, 1, 192)    55488       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1, 1, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1, 1, 192)    576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_483 (Activation)     (None, 1, 1, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, 1, 1, 192)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, 1, 1, 192)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, 1, 1, 192)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 1, 1, 768)    0           activation_483[0][0]             \n",
      "                                                                 activation_486[0][0]             \n",
      "                                                                 activation_491[0][0]             \n",
      "                                                                 activation_492[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 1, 1, 160)    123040      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1, 1, 160)    480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_497 (Activation)     (None, 1, 1, 160)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 1, 1, 160)    179360      activation_497[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 1, 1, 160)    480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_498 (Activation)     (None, 1, 1, 160)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 1, 1, 160)    123040      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 1, 1, 160)    179360      activation_498[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1, 1, 160)    480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1, 1, 160)    480         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_494 (Activation)     (None, 1, 1, 160)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_499 (Activation)     (None, 1, 1, 160)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 1, 1, 160)    179360      activation_494[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 1, 1, 160)    179360      activation_499[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1, 1, 160)    480         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 1, 1, 160)    480         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_495 (Activation)     (None, 1, 1, 160)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_500 (Activation)     (None, 1, 1, 160)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 1, 1, 192)    147648      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 1, 1, 192)    215232      activation_495[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 1, 1, 192)    215232      activation_500[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 1, 1, 192)    147648      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 192)    576         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1, 1, 192)    576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1, 1, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1, 1, 192)    576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_493 (Activation)     (None, 1, 1, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_496 (Activation)     (None, 1, 1, 192)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_501 (Activation)     (None, 1, 1, 192)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_502 (Activation)     (None, 1, 1, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 1, 1, 768)    0           activation_493[0][0]             \n",
      "                                                                 activation_496[0][0]             \n",
      "                                                                 activation_501[0][0]             \n",
      "                                                                 activation_502[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 1, 1, 160)    123040      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 1, 1, 160)    480         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_507 (Activation)     (None, 1, 1, 160)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 1, 1, 160)    179360      activation_507[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 1, 1, 160)    480         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_508 (Activation)     (None, 1, 1, 160)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 1, 1, 160)    123040      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 1, 1, 160)    179360      activation_508[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 1, 1, 160)    480         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 1, 1, 160)    480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_504 (Activation)     (None, 1, 1, 160)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_509 (Activation)     (None, 1, 1, 160)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 1, 1, 160)    179360      activation_504[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 1, 1, 160)    179360      activation_509[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 1, 1, 160)    480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 1, 1, 160)    480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_505 (Activation)     (None, 1, 1, 160)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_510 (Activation)     (None, 1, 1, 160)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 1, 1, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 1, 1, 192)    147648      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 1, 1, 192)    215232      activation_505[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 1, 1, 192)    215232      activation_510[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 1, 1, 192)    147648      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1, 1, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 1, 1, 192)    576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 1, 1, 192)    576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 1, 1, 192)    576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_503 (Activation)     (None, 1, 1, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_506 (Activation)     (None, 1, 1, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_511 (Activation)     (None, 1, 1, 192)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_512 (Activation)     (None, 1, 1, 192)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 1, 1, 768)    0           activation_503[0][0]             \n",
      "                                                                 activation_506[0][0]             \n",
      "                                                                 activation_511[0][0]             \n",
      "                                                                 activation_512[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 768)          0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           7690        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 5,384,234\n",
      "Trainable params: 5,370,538\n",
      "Non-trainable params: 13,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:218: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "modelB = dimension_reduction_model(train_img.shape[1:])\n",
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/1000\n",
      " - 25s - loss: 0.7912 - acc: 0.7081 - val_loss: 0.6814 - val_acc: 0.7599\n",
      "Epoch 2/1000\n",
      " - 8s - loss: 0.4592 - acc: 0.8288 - val_loss: 0.4768 - val_acc: 0.8333\n",
      "Epoch 3/1000\n",
      " - 8s - loss: 0.3690 - acc: 0.8641 - val_loss: 0.4222 - val_acc: 0.8456\n",
      "Epoch 4/1000\n",
      " - 8s - loss: 0.3172 - acc: 0.8831 - val_loss: 0.4712 - val_acc: 0.8295\n",
      "Epoch 5/1000\n",
      " - 8s - loss: 0.2762 - acc: 0.8992 - val_loss: 0.3585 - val_acc: 0.8709\n",
      "Epoch 6/1000\n",
      " - 8s - loss: 0.2483 - acc: 0.9092 - val_loss: 0.3934 - val_acc: 0.8700\n",
      "Epoch 7/1000\n",
      " - 8s - loss: 0.2277 - acc: 0.9161 - val_loss: 0.4334 - val_acc: 0.8557\n",
      "Epoch 8/1000\n",
      " - 8s - loss: 0.2035 - acc: 0.9250 - val_loss: 0.4412 - val_acc: 0.8673\n",
      "Epoch 9/1000\n",
      " - 8s - loss: 0.1903 - acc: 0.9300 - val_loss: 0.4643 - val_acc: 0.8527\n",
      "Epoch 10/1000\n",
      " - 8s - loss: 0.1790 - acc: 0.9334 - val_loss: 0.3982 - val_acc: 0.8757\n",
      "Epoch 11/1000\n",
      " - 8s - loss: 0.1624 - acc: 0.9411 - val_loss: 0.3984 - val_acc: 0.8787\n",
      "Epoch 12/1000\n",
      " - 8s - loss: 0.1512 - acc: 0.9452 - val_loss: 0.4136 - val_acc: 0.8736\n",
      "Epoch 13/1000\n",
      " - 8s - loss: 0.1411 - acc: 0.9481 - val_loss: 0.4268 - val_acc: 0.8665\n",
      "Epoch 14/1000\n",
      " - 8s - loss: 0.1400 - acc: 0.9491 - val_loss: 0.4234 - val_acc: 0.8783\n",
      "Epoch 15/1000\n",
      " - 8s - loss: 0.1285 - acc: 0.9536 - val_loss: 0.5717 - val_acc: 0.8532\n",
      "Epoch 16/1000\n",
      " - 8s - loss: 0.1208 - acc: 0.9561 - val_loss: 0.4663 - val_acc: 0.8610\n",
      "Epoch 17/1000\n",
      " - 8s - loss: 0.1097 - acc: 0.9600 - val_loss: 0.4099 - val_acc: 0.8851\n",
      "Epoch 18/1000\n",
      " - 8s - loss: 0.1055 - acc: 0.9619 - val_loss: 0.4169 - val_acc: 0.8896\n",
      "Epoch 19/1000\n",
      " - 8s - loss: 0.0991 - acc: 0.9641 - val_loss: 0.4382 - val_acc: 0.8818\n",
      "Epoch 20/1000\n",
      " - 8s - loss: 0.0967 - acc: 0.9648 - val_loss: 0.4321 - val_acc: 0.8867\n",
      "Epoch 21/1000\n",
      " - 8s - loss: 0.0907 - acc: 0.9672 - val_loss: 0.4578 - val_acc: 0.8867\n",
      "Epoch 22/1000\n",
      " - 8s - loss: 0.0874 - acc: 0.9678 - val_loss: 0.4812 - val_acc: 0.8785\n",
      "Epoch 23/1000\n",
      " - 8s - loss: 0.0840 - acc: 0.9697 - val_loss: 0.4358 - val_acc: 0.8884\n",
      "Epoch 24/1000\n",
      " - 8s - loss: 0.0796 - acc: 0.9723 - val_loss: 0.4665 - val_acc: 0.8825\n",
      "Epoch 25/1000\n",
      " - 8s - loss: 0.0723 - acc: 0.9740 - val_loss: 0.4623 - val_acc: 0.8846\n",
      "Epoch 26/1000\n",
      " - 8s - loss: 0.0669 - acc: 0.9762 - val_loss: 0.5087 - val_acc: 0.8776\n",
      "Epoch 27/1000\n",
      " - 8s - loss: 0.0619 - acc: 0.9774 - val_loss: 0.5207 - val_acc: 0.8761\n",
      "Epoch 28/1000\n",
      " - 8s - loss: 0.0691 - acc: 0.9746 - val_loss: 1.2437 - val_acc: 0.8220\n",
      "Epoch 29/1000\n",
      " - 8s - loss: 0.0643 - acc: 0.9776 - val_loss: 0.4801 - val_acc: 0.8877\n",
      "Epoch 30/1000\n",
      " - 8s - loss: 0.0534 - acc: 0.9808 - val_loss: 0.5312 - val_acc: 0.8829\n",
      "Epoch 31/1000\n",
      " - 8s - loss: 0.0544 - acc: 0.9807 - val_loss: 0.5445 - val_acc: 0.8746\n",
      "Epoch 32/1000\n",
      " - 8s - loss: 0.0507 - acc: 0.9817 - val_loss: 0.4816 - val_acc: 0.8866\n",
      "Epoch 33/1000\n",
      " - 8s - loss: 0.0456 - acc: 0.9844 - val_loss: 0.5315 - val_acc: 0.8794\n",
      "Epoch 34/1000\n",
      " - 8s - loss: 0.0479 - acc: 0.9831 - val_loss: 0.5398 - val_acc: 0.8772\n",
      "Epoch 35/1000\n",
      " - 8s - loss: 0.0512 - acc: 0.9818 - val_loss: 0.4545 - val_acc: 0.8877\n",
      "Epoch 36/1000\n",
      " - 8s - loss: 0.0447 - acc: 0.9836 - val_loss: 0.4964 - val_acc: 0.8923\n",
      "Epoch 37/1000\n",
      " - 8s - loss: 0.0434 - acc: 0.9848 - val_loss: 0.6130 - val_acc: 0.8682\n",
      "Epoch 38/1000\n",
      " - 8s - loss: 0.0396 - acc: 0.9864 - val_loss: 0.5126 - val_acc: 0.8887\n",
      "Epoch 39/1000\n",
      " - 8s - loss: 0.0342 - acc: 0.9880 - val_loss: 0.5099 - val_acc: 0.8837\n",
      "Epoch 40/1000\n",
      " - 8s - loss: 0.0398 - acc: 0.9861 - val_loss: 0.6651 - val_acc: 0.8744\n",
      "Epoch 41/1000\n",
      " - 8s - loss: 0.0362 - acc: 0.9875 - val_loss: 1.5226 - val_acc: 0.8200\n",
      "Epoch 42/1000\n",
      " - 8s - loss: 0.0357 - acc: 0.9877 - val_loss: 0.5510 - val_acc: 0.8915\n",
      "Epoch 43/1000\n",
      " - 8s - loss: 0.0358 - acc: 0.9874 - val_loss: 0.5771 - val_acc: 0.8828\n",
      "Epoch 44/1000\n",
      " - 8s - loss: 0.0340 - acc: 0.9880 - val_loss: 0.5349 - val_acc: 0.8912\n",
      "Epoch 45/1000\n",
      " - 8s - loss: 0.0345 - acc: 0.9885 - val_loss: 0.5513 - val_acc: 0.8795\n",
      "Epoch 46/1000\n",
      " - 8s - loss: 0.0343 - acc: 0.9881 - val_loss: 0.5073 - val_acc: 0.8928\n",
      "Epoch 47/1000\n",
      " - 8s - loss: 0.0300 - acc: 0.9894 - val_loss: 0.5833 - val_acc: 0.8838\n",
      "Epoch 48/1000\n",
      " - 8s - loss: 0.0333 - acc: 0.9881 - val_loss: 0.5457 - val_acc: 0.8892\n",
      "Epoch 49/1000\n",
      " - 8s - loss: 0.0268 - acc: 0.9910 - val_loss: 0.5513 - val_acc: 0.8885\n",
      "Epoch 50/1000\n",
      " - 9s - loss: 0.0299 - acc: 0.9895 - val_loss: 0.5164 - val_acc: 0.8966\n",
      "Epoch 51/1000\n",
      " - 9s - loss: 0.0293 - acc: 0.9899 - val_loss: 0.5423 - val_acc: 0.8924\n",
      "Epoch 52/1000\n",
      " - 9s - loss: 0.0283 - acc: 0.9907 - val_loss: 0.5367 - val_acc: 0.8903\n",
      "Epoch 53/1000\n",
      " - 9s - loss: 0.0255 - acc: 0.9910 - val_loss: 0.5925 - val_acc: 0.8872\n",
      "Epoch 54/1000\n",
      " - 9s - loss: 0.0257 - acc: 0.9909 - val_loss: 0.5599 - val_acc: 0.8875\n",
      "Epoch 55/1000\n",
      " - 9s - loss: 0.0262 - acc: 0.9916 - val_loss: 0.5756 - val_acc: 0.8905\n",
      "Epoch 00055: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=50)\n",
    "modelB.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = modelB.fit(x=train_img,y=train_label,validation_split=0.2, epochs=1000, batch_size=250,verbose=2,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 335us/step\n",
      "Test accuracy: 0.8873\n",
      "Test loss: 0.608408523106575\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelB.evaluate(test_img, test_label)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 05:56:40.013798 139674573018880 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 33, 33, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 16, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "myFlatten (GlobalAveragePool (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "myprediction (Dense)         (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,238,538\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 3,228,288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input,MobileNet\n",
    "base_model = MobileNet(weights=None,input_shape=(32,32,1),include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='myFlatten')(x)\n",
    "x = Dense(10,activation='softmax',name='myprediction')(x)\n",
    "mobilemodel = Model(inputs=base_model.input,outputs=x)\n",
    "mobilemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/500\n",
      "44000/44000 - 12s - loss: 2.2838 - acc: 0.1768 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 2/500\n",
      "44000/44000 - 12s - loss: 2.1092 - acc: 0.2423 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 3/500\n",
      "44000/44000 - 11s - loss: 2.0582 - acc: 0.2626 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 4/500\n",
      "44000/44000 - 11s - loss: 2.0325 - acc: 0.2691 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 5/500\n",
      "44000/44000 - 11s - loss: 2.0167 - acc: 0.2794 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 6/500\n",
      "44000/44000 - 11s - loss: 2.0053 - acc: 0.2825 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 7/500\n",
      "44000/44000 - 12s - loss: 1.9984 - acc: 0.2841 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 8/500\n",
      "44000/44000 - 12s - loss: 1.9960 - acc: 0.2882 - val_loss: 2.3026 - val_acc: 0.1010\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
    "mobilemodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "train_history = mobilemodel.fit(x=trainimg32321,y=train_label,validation_split=0.2, epochs=500, batch_size=300,verbose=2,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
