{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# db to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sqlite3\n",
    "ly = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '/p3/metadata.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "DEGREE_CLASS_LIST = []\n",
    "c.execute('''\n",
    "    select distinct degree from metadata \n",
    "    where label = 'OK'\n",
    "    and (component = 'AluCap' or component = 'ElecCap')\n",
    "    and (degree = '0' or degree = '270')\n",
    "    and width is not NULL\n",
    "''')\n",
    "\n",
    "for i, in c.fetchall():\n",
    "    print(i)\n",
    "    DEGREE_CLASS_LIST.append(f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "c.execute('''\n",
    "    select distinct degree from metadata \n",
    "    where label = 'NG-InversePolarity' and\n",
    "    component = 'AluCap'\n",
    "    and degree >= 0 \n",
    "''')\n",
    "for i, in c.fetchall():\n",
    "    d = str((int(i) + 180) % 360)\n",
    "    print(d)\n",
    "    DEGREE_CLASS_LIST.append(f'{d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '180', '270', '90']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEGREE_CLASS_LIST = sorted(DEGREE_CLASS_LIST)\n",
    "DEGREE_CLASS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OK_DEGREE_INDEX_LOOKUP = tf.constant(list(range(len(DEGREE_CLASS_LIST))), dtype=tf.int64)\n",
    "NG_DEGREE_INDEX_LOOKUP = tf.constant([1, 0, 3, 2], dtype=tf.int64)\n",
    "DEGREE_NUM = len(DEGREE_CLASS_LIST)\n",
    "ok_lookup = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(DEGREE_CLASS_LIST, OK_DEGREE_INDEX_LOOKUP), -1)\n",
    "ng_lookup = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(DEGREE_CLASS_LIST, NG_DEGREE_INDEX_LOOKUP), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=3>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_lookup.lookup(tf.constant('270'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265834\n"
     ]
    }
   ],
   "source": [
    "ok_num = c.execute('''\n",
    "        select count(*) from metadata\n",
    "        where (label = 'OK')\n",
    "        and (component = 'AluCap' or component = 'ElecCap')\n",
    "        and (degree = '0' or degree = '270')\n",
    "        and width is not NULL\n",
    "        ''').fetchone()[0]\n",
    "print(ok_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985\n"
     ]
    }
   ],
   "source": [
    "ng_num = c.execute('''\n",
    "        select count(*) from metadata\n",
    "        where (label = 'NG-InversePolarity')\n",
    "        and (component = 'AluCap' or component = 'ElecCap')\n",
    "        and (degree = '0' or degree = '270')\n",
    "        and width is not NULL\n",
    "        ''').fetchone()[0]\n",
    "print(ng_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 125, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_wh = c.execute('''\n",
    "        select distinct width, height from metadata\n",
    "        where (label = 'OK' or label = 'NG-InversePolarity')\n",
    "        and (component = 'AluCap' or component = 'ElecCap')\n",
    "        and (degree = '0' or degree = '270')\n",
    "        and width is not NULL\n",
    "        ''').fetchall()\n",
    "biggest_size = 0\n",
    "for w, h in biggest_wh:\n",
    "    try:\n",
    "        if int(h) > biggest_size:\n",
    "            biggest_size = int(h)\n",
    "        if int(w) > biggest_size:\n",
    "            biggest_size = int(w)\n",
    "    except:\n",
    "        print(w, h)\n",
    "target_shape = (biggest_size, biggest_size, 3)\n",
    "target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "valid_size = int(ok_num * 0.2)\n",
    "train_size = ok_num - valid_size\n",
    "train_step = int(train_size / batch_size)\n",
    "valid_step = int(valid_size / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_ds = tf.data.experimental.SqlDataset(\n",
    "    'sqlite', db_path,\n",
    "    '''\n",
    "        select path, degree from metadata\n",
    "        where (label = 'OK')\n",
    "        and (component = 'AluCap' or component = 'ElecCap')\n",
    "        and (degree = '0' or degree = '270')\n",
    "        and width is not NULL\n",
    "        ''', \n",
    "    (tf.string, tf.string)\n",
    ")\n",
    "\n",
    "ng_ds = tf.data.experimental.SqlDataset(\n",
    "    'sqlite', db_path,\n",
    "    '''\n",
    "        select path, degree from metadata\n",
    "        where (label = 'NG-InversePolarity')\n",
    "        and (component = 'AluCap' or component = 'ElecCap')\n",
    "        and (degree = '0' or degree = '270')\n",
    "        and width is not NULL\n",
    "        ''', \n",
    "    (tf.string, tf.string)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/data/aoi-wzs-p3-dip-prewave-saiap/Phase2-Cap/0904/AluCapacitor/Model-2/OK/270/CN01W26NWS20099302YBA00_PT4701_90_NA_NA.png', shape=(), dtype=string) tf.Tensor(b'270', shape=(), dtype=string)\n",
      "tf.Tensor(b'/data/aoi-wzs-p3-dip-prewave-saiap/Phase2-Cap/0904/AluCapacitor/Model-2/NG/0/CN01W26NWS20099302GLA00_PT5101_39.bmp', shape=(), dtype=string) tf.Tensor(b'0', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for p, d in ok_ds.take(1):\n",
    "    print(p, d)\n",
    "for p, d in ng_ds.take(1):\n",
    "    print(p, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ok(path, degree):\n",
    "    byte_string_img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(byte_string_img, channels=target_shape[-1], dtype=tf.dtypes.float32)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, target_shape[1], target_shape[0])\n",
    "    deg = ok_lookup.lookup(degree)\n",
    "    return img, deg\n",
    "\n",
    "def process_ng(path, degree):\n",
    "    byte_string_img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(byte_string_img, channels=target_shape[-1], dtype=tf.dtypes.float32)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, target_shape[1], target_shape[0])\n",
    "    deg = ng_lookup.lookup(degree)\n",
    "    return img, deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_ok_ds = ok_ds.shuffle(20000).map(process_ok, tf.data.experimental.AUTOTUNE)\n",
    "pro_ng_ds = ng_ds.shuffle(ng_num).map(process_ng, tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 125, 3) tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i, d in pro_ng_ds.take(1):\n",
    "    print(i.shape, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_ds = tf.data.experimental.sample_from_datasets([pro_ok_ds.repeat(), pro_ng_ds.repeat()], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pro_ds.skip(valid_size).cache().repeat().batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "valid_ds = pro_ds.take(valid_size).cache().repeat().batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simpleConv(conv_count, first_filter, kernel_size, strides, input_shape, degree_num, maxbool=False):\n",
    "  input_image = tf.keras.Input(input_shape, name='image')\n",
    "  x = input_image\n",
    "  for i in range(conv_count):\n",
    "    x = ly.Conv2D(first_filter*(i+1), kernel_size, (strides, strides), \n",
    "                  padding='same', name='conv'+str(i+1), activation=tf.nn.relu)(x)\n",
    "    x = ly.BatchNormalization()(x)\n",
    "    if maxbool:\n",
    "        x = ly.MaxPool2D()(x)\n",
    "  x = ly.GlobalAveragePooling2D(name='GAP')(x)\n",
    "  x = ly.Dense(degree_num, name='dense_logits')(x)\n",
    "  x = ly.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "  return tf.keras.Model(inputs=input_image, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 125, 125, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 63, 63, 8)         224       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 63, 63, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 24)        3480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 8, 8, 32)          6944      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "GAP (GlobalAveragePooling2D) (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_logits (Dense)         (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 12,268\n",
      "Trainable params: 12,108\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = model_simpleConv(4, 8, 3, 2, target_shape, DEGREE_NUM)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile('adam', 'sparse_categorical_crossentropy', ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 830 steps, validate for 207 steps\n",
      "Epoch 1/10\n",
      "830/830 [==============================] - 94s 113ms/step - loss: 0.0691 - acc: 0.9863 - val_loss: 0.0422 - val_acc: 0.9851\n",
      "Epoch 2/10\n",
      "830/830 [==============================] - 73s 87ms/step - loss: 0.0124 - acc: 0.9968 - val_loss: 0.0423 - val_acc: 0.9887\n",
      "Epoch 3/10\n",
      "830/830 [==============================] - 69s 83ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 9.3961e-04 - val_acc: 0.9998\n",
      "Epoch 4/10\n",
      "830/830 [==============================] - 68s 81ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 9.2989e-04 - val_acc: 0.9999\n",
      "Epoch 5/10\n",
      "830/830 [==============================] - 69s 84ms/step - loss: 0.0057 - acc: 0.9986 - val_loss: 8.7855e-04 - val_acc: 0.9998\n",
      "Epoch 6/10\n",
      "830/830 [==============================] - 66s 80ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0091 - val_acc: 0.9968\n",
      "Epoch 7/10\n",
      "830/830 [==============================] - 65s 78ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0447 - val_acc: 0.9792\n",
      "Epoch 8/10\n",
      "495/830 [================>.............] - ETA: 19s - loss: 0.0017 - acc: 0.9997"
     ]
    }
   ],
   "source": [
    "# epochs = 10, 8/10 kernel restarting\n",
    "m.fit(train_ds, epochs=10, validation_data=valid_ds, \n",
    "    steps_per_epoch=train_step, validation_steps=valid_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
